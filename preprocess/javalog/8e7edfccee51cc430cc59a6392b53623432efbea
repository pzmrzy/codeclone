commit 8e7edfccee51cc430cc59a6392b53623432efbea
Author:     Sam Harwell <sam@tunnelvisionlabs.com>
AuthorDate: Tue Feb 21 23:07:01 2012 -0600
Commit:     Sam Harwell <sam@tunnelvisionlabs.com>
CommitDate: Wed Feb 22 12:25:40 2012 -0600

Specify generic type arguments for generic collections

diff --git a/runtime/Java/src/main/java/org/antlr/runtime/ANTLRStringStream.java b/runtime/Java/src/main/java/org/antlr/runtime/ANTLRStringStream.java
index 82e3c25..78f5148 100644
--- a/runtime/Java/src/main/java/org/antlr/runtime/ANTLRStringStream.java
+++ b/runtime/Java/src/main/java/org/antlr/runtime/ANTLRStringStream.java
@@ -58,7 +58,7 @@ public class ANTLRStringStream implements CharStream {
*  move through the input stream.  Indexed from 1..markDepth.
*  A null is kept @ index 0.  Create upon first call to mark().
*/
-	protected List markers;
+	protected List<CharStreamState> markers;

/** Track the last mark() call result value for use in rewind(). */
protected int lastMarker;
@@ -155,7 +155,7 @@ public class ANTLRStringStream implements CharStream {
@Override
public int mark() {
if ( markers==null ) {
-            markers = new ArrayList();
+            markers = new ArrayList<CharStreamState>();
markers.add(null); // depth 0 means no backtracking, leave blank
}
markDepth++;
diff --git a/runtime/Java/src/main/java/org/antlr/runtime/BaseRecognizer.java b/runtime/Java/src/main/java/org/antlr/runtime/BaseRecognizer.java
index 4292e96..84daecd 100644
--- a/runtime/Java/src/main/java/org/antlr/runtime/BaseRecognizer.java
+++ b/runtime/Java/src/main/java/org/antlr/runtime/BaseRecognizer.java
@@ -710,7 +710,7 @@ public abstract class BaseRecognizer {
*  This is very useful for error messages and for context-sensitive
*  error recovery.
*/
-	public List getRuleInvocationStack() {
+	public List<String> getRuleInvocationStack() {
String parserClassName = getClass().getName();
return getRuleInvocationStack(new Throwable(), parserClassName);
}
@@ -722,10 +722,10 @@ public abstract class BaseRecognizer {
*
*  TODO: move to a utility class or something; weird having lexer call this
*/
-	public static List getRuleInvocationStack(Throwable e,
+	public static List<String> getRuleInvocationStack(Throwable e,
String recognizerClassName)
{
-		List rules = new ArrayList();
+		List<String> rules = new ArrayList<String>();
StackTraceElement[] stack = e.getStackTrace();
int i;
for (i=stack.length-1; i>=0; i--) {
@@ -771,9 +771,9 @@ public abstract class BaseRecognizer {
/** A convenience method for use most often with template rewrites.
*  Convert a List<Token> to List<String>
*/
-	public List toStrings(List tokens) {
+	public List<String> toStrings(List<? extends Token> tokens) {
if ( tokens==null ) return null;
-		List strings = new ArrayList(tokens.size());
+		List<String> strings = new ArrayList<String>(tokens.size());
for (int i=0; i<tokens.size(); i++) {
strings.add(((Token)tokens.get(i)).getText());
}
@@ -792,7 +792,7 @@ public abstract class BaseRecognizer {
*/
public int getRuleMemoization(int ruleIndex, int ruleStartIndex) {
if ( state.ruleMemo[ruleIndex]==null ) {
-			state.ruleMemo[ruleIndex] = new HashMap();
+			state.ruleMemo[ruleIndex] = new HashMap<Integer, Integer>();
}
Integer stopIndexI =
(Integer)state.ruleMemo[ruleIndex].get(new Integer(ruleStartIndex));
@@ -854,7 +854,7 @@ public abstract class BaseRecognizer {
public int getRuleMemoizationCacheSize() {
int n = 0;
for (int i = 0; state.ruleMemo!=null && i < state.ruleMemo.length; i++) {
-			Map ruleMap = state.ruleMemo[i];
+			Map<Integer, Integer> ruleMap = state.ruleMemo[i];
if ( ruleMap!=null ) {
n += ruleMap.size(); // how many input indexes are recorded?
}
diff --git a/runtime/Java/src/main/java/org/antlr/runtime/BitSet.java b/runtime/Java/src/main/java/org/antlr/runtime/BitSet.java
index a309b82..5eff39d 100644
--- a/runtime/Java/src/main/java/org/antlr/runtime/BitSet.java
+++ b/runtime/Java/src/main/java/org/antlr/runtime/BitSet.java
@@ -58,7 +58,7 @@ public class BitSet implements Cloneable {
}

/** Construction from a list of integers */
-	public BitSet(List items) {
+	public BitSet(List<Integer> items) {
this();
for (int i = 0; i < items.size(); i++) {
Integer v = (Integer) items.get(i);
diff --git a/runtime/Java/src/main/java/org/antlr/runtime/BufferedTokenStream.java b/runtime/Java/src/main/java/org/antlr/runtime/BufferedTokenStream.java
index 86c4282..77974be 100644
--- a/runtime/Java/src/main/java/org/antlr/runtime/BufferedTokenStream.java
+++ b/runtime/Java/src/main/java/org/antlr/runtime/BufferedTokenStream.java
@@ -157,10 +157,10 @@ public class BufferedTokenStream implements TokenStream {
}

/** Get all tokens from start..stop inclusively */
-	public List get(int start, int stop) {
+	public List<? extends Token> get(int start, int stop) {
if ( start<0 || stop<0 ) return null;
if ( p == -1 ) setup();
-		List subset = new ArrayList();
+		List<Token> subset = new ArrayList<Token>();
if ( stop>=tokens.size() ) stop = tokens.size()-1;
for (int i = start; i <= stop; i++) {
Token t = tokens.get(i);
@@ -203,9 +203,9 @@ public class BufferedTokenStream implements TokenStream {
p = -1;
}

-    public List getTokens() { return tokens; }
+    public List<? extends Token> getTokens() { return tokens; }

-    public List getTokens(int start, int stop) {
+    public List<? extends Token> getTokens(int start, int stop) {
return getTokens(start, stop, (BitSet)null);
}

@@ -213,7 +213,7 @@ public class BufferedTokenStream implements TokenStream {
*  the token type BitSet.  Return null if no tokens were found.  This
*  method looks at both on and off channel tokens.
*/
-    public List getTokens(int start, int stop, BitSet types) {
+    public List<? extends Token> getTokens(int start, int stop, BitSet types) {
if ( p == -1 ) setup();
if ( stop>=tokens.size() ) stop=tokens.size()-1;
if ( start<0 ) start=0;
@@ -233,11 +233,11 @@ public class BufferedTokenStream implements TokenStream {
return filteredTokens;
}

-    public List getTokens(int start, int stop, List types) {
+    public List<? extends Token> getTokens(int start, int stop, List<Integer> types) {
return getTokens(start,stop,new BitSet(types));
}

-    public List getTokens(int start, int stop, int ttype) {
+    public List<? extends Token> getTokens(int start, int stop, int ttype) {
return getTokens(start,stop,BitSet.of(ttype));
}

diff --git a/runtime/Java/src/main/java/org/antlr/runtime/LegacyCommonTokenStream.java b/runtime/Java/src/main/java/org/antlr/runtime/LegacyCommonTokenStream.java
index 1dc916f..eab2333 100644
--- a/runtime/Java/src/main/java/org/antlr/runtime/LegacyCommonTokenStream.java
+++ b/runtime/Java/src/main/java/org/antlr/runtime/LegacyCommonTokenStream.java
@@ -42,13 +42,13 @@ public class LegacyCommonTokenStream implements TokenStream {
/** Record every single token pulled from the source so we can reproduce
*  chunks of it later.
*/
-	protected List tokens;
+	protected List<Token> tokens;

/** Map<tokentype, channel> to override some Tokens' channel numbers */
-	protected Map channelOverrideMap;
+	protected Map<Integer, Integer> channelOverrideMap;

/** Set<tokentype>; discard any tokens with this type */
-	protected Set discardSet;
+	protected Set<Integer> discardSet;

/** Skip tokens on any channel but this one; this is how we skip whitespace... */
protected int channel = Token.DEFAULT_CHANNEL;
@@ -67,7 +67,7 @@ public class LegacyCommonTokenStream implements TokenStream {
protected int p = -1;

public LegacyCommonTokenStream() {
-		tokens = new ArrayList(500);
+		tokens = new ArrayList<Token>(500);
}

public LegacyCommonTokenStream(TokenSource tokenSource) {
@@ -166,14 +166,14 @@ public class LegacyCommonTokenStream implements TokenStream {
*/
public void setTokenTypeChannel(int ttype, int channel) {
if ( channelOverrideMap==null ) {
-			channelOverrideMap = new HashMap();
+			channelOverrideMap = new HashMap<Integer, Integer>();
}
channelOverrideMap.put(new Integer(ttype), new Integer(channel));
}

public void discardTokenType(int ttype) {
if ( discardSet==null ) {
-			discardSet = new HashSet();
+			discardSet = new HashSet<Integer>();
}
discardSet.add(new Integer(ttype));
}
@@ -182,14 +182,14 @@ public class LegacyCommonTokenStream implements TokenStream {
this.discardOffChannelTokens = discardOffChannelTokens;
}

-	public List getTokens() {
+	public List<? extends Token> getTokens() {
if ( p == -1 ) {
fillBuffer();
}
return tokens;
}

-	public List getTokens(int start, int stop) {
+	public List<? extends Token> getTokens(int start, int stop) {
return getTokens(start, stop, (BitSet)null);
}

@@ -197,7 +197,7 @@ public class LegacyCommonTokenStream implements TokenStream {
*  the token type BitSet.  Return null if no tokens were found.  This
*  method looks at both on and off channel tokens.
*/
-	public List getTokens(int start, int stop, BitSet types) {
+	public List<? extends Token> getTokens(int start, int stop, BitSet types) {
if ( p == -1 ) {
fillBuffer();
}
@@ -212,7 +212,7 @@ public class LegacyCommonTokenStream implements TokenStream {
}

// list = tokens[start:stop]:{Token t, t.getType() in types}
-		List filteredTokens = new ArrayList();
+		List<Token> filteredTokens = new ArrayList<Token>();
for (int i=start; i<=stop; i++) {
Token t = (Token)tokens.get(i);
if ( types==null || types.member(t.getType()) ) {
@@ -225,11 +225,11 @@ public class LegacyCommonTokenStream implements TokenStream {
return filteredTokens;
}

-	public List getTokens(int start, int stop, List types) {
+	public List<? extends Token> getTokens(int start, int stop, List<Integer> types) {
return getTokens(start,stop,new BitSet(types));
}

-	public List getTokens(int start, int stop, int ttype) {
+	public List<? extends Token> getTokens(int start, int stop, int ttype) {
return getTokens(start,stop,BitSet.of(ttype));
}

@@ -304,7 +304,7 @@ public class LegacyCommonTokenStream implements TokenStream {
}

/** Get all tokens from start..stop inclusively */
-	public List get(int start, int stop) {
+	public List<? extends Token> get(int start, int stop) {
if ( p == -1 ) fillBuffer();
if ( start<0 || stop<0 ) return null;
return tokens.subList(start, stop);
diff --git a/runtime/Java/src/main/java/org/antlr/runtime/RecognizerSharedState.java b/runtime/Java/src/main/java/org/antlr/runtime/RecognizerSharedState.java
index 068ac3b..ef46cea 100644
--- a/runtime/Java/src/main/java/org/antlr/runtime/RecognizerSharedState.java
+++ b/runtime/Java/src/main/java/org/antlr/runtime/RecognizerSharedState.java
@@ -77,7 +77,7 @@ public class RecognizerSharedState {
*
*  This is only used if rule memoization is on (which it is by default).
*/
-	public Map[] ruleMemo;
+	public Map<Integer, Integer>[] ruleMemo;


// LEXER FIELDS (must be in same state object to avoid casting
diff --git a/runtime/Java/src/main/java/org/antlr/runtime/SerializedGrammar.java b/runtime/Java/src/main/java/org/antlr/runtime/SerializedGrammar.java
index bb1bd9d..bee6f46 100644
--- a/runtime/Java/src/main/java/org/antlr/runtime/SerializedGrammar.java
+++ b/runtime/Java/src/main/java/org/antlr/runtime/SerializedGrammar.java
@@ -42,7 +42,7 @@ public class SerializedGrammar {

public String name;
public char type; // in {l, p, t, c}
-    public List rules;
+    public List<? extends Rule> rules;

class Rule {
String name;
@@ -113,8 +113,8 @@ public class SerializedGrammar {
rules = readRules(in, numRules);
}

-    protected List readRules(DataInputStream in, int numRules) throws IOException {
-        List rules = new ArrayList();
+    protected List<? extends Rule> readRules(DataInputStream in, int numRules) throws IOException {
+        List<Rule> rules = new ArrayList<Rule>();
for (int i=0; i<numRules; i++) {
Rule r = readRule(in);
rules.add(r);
diff --git a/runtime/Java/src/main/java/org/antlr/runtime/TokenRewriteStream.java b/runtime/Java/src/main/java/org/antlr/runtime/TokenRewriteStream.java
index a3ecdfb..7ca99ae 100644
--- a/runtime/Java/src/main/java/org/antlr/runtime/TokenRewriteStream.java
+++ b/runtime/Java/src/main/java/org/antlr/runtime/TokenRewriteStream.java
@@ -163,19 +163,19 @@ public class TokenRewriteStream extends CommonTokenStream {
*  I'm calling these things "programs."
*  Maps String (name) -> rewrite (List)
*/
-	protected Map programs = null;
+	protected Map<String, List<RewriteOperation>> programs = null;

/** Map String (program name) -> Integer index */
-	protected Map lastRewriteTokenIndexes = null;
+	protected Map<String, Integer> lastRewriteTokenIndexes = null;

public TokenRewriteStream() {
init();
}

protected void init() {
-		programs = new HashMap();
-		programs.put(DEFAULT_PROGRAM_NAME, new ArrayList(PROGRAM_INIT_SIZE));
-		lastRewriteTokenIndexes = new HashMap();
+		programs = new HashMap<String, List<RewriteOperation>>();
+		programs.put(DEFAULT_PROGRAM_NAME, new ArrayList<RewriteOperation>(PROGRAM_INIT_SIZE));
+		lastRewriteTokenIndexes = new HashMap<String, Integer>();
}

public TokenRewriteStream(TokenSource tokenSource) {
@@ -197,7 +197,7 @@ public class TokenRewriteStream extends CommonTokenStream {
*  longer in the stream.  UNTESTED!
*/
public void rollback(String programName, int instructionIndex) {
-		List is = (List)programs.get(programName);
+		List<RewriteOperation> is = programs.get(programName);
if ( is!=null ) {
programs.put(programName, is.subList(MIN_TOKEN_INDEX,instructionIndex));
}
@@ -243,7 +243,7 @@ public class TokenRewriteStream extends CommonTokenStream {

public void insertBefore(String programName, int index, Object text) {
RewriteOperation op = new InsertBeforeOp(index,text);
-		List rewrites = getProgram(programName);
+		List<? super RewriteOperation> rewrites = getProgram(programName);
op.instructionIndex = rewrites.size();
rewrites.add(op);
}
@@ -269,7 +269,7 @@ public class TokenRewriteStream extends CommonTokenStream {
throw new IllegalArgumentException("replace: range invalid: "+from+".."+to+"(size="+tokens.size()+")");
}
RewriteOperation op = new ReplaceOp(from, to, text);
-		List rewrites = getProgram(programName);
+		List<? super RewriteOperation> rewrites = getProgram(programName);
op.instructionIndex = rewrites.size();
rewrites.add(op);
}
@@ -321,16 +321,16 @@ public class TokenRewriteStream extends CommonTokenStream {
lastRewriteTokenIndexes.put(programName, new Integer(i));
}

-	protected List getProgram(String name) {
-		List is = (List)programs.get(name);
+	protected List<RewriteOperation> getProgram(String name) {
+		List<RewriteOperation> is = programs.get(name);
if ( is==null ) {
is = initializeProgram(name);
}
return is;
}

-	private List initializeProgram(String name) {
-		List is = new ArrayList(PROGRAM_INIT_SIZE);
+	private List<RewriteOperation> initializeProgram(String name) {
+		List<RewriteOperation> is = new ArrayList<RewriteOperation>(PROGRAM_INIT_SIZE);
programs.put(name, is);
return is;
}
@@ -365,7 +365,7 @@ public class TokenRewriteStream extends CommonTokenStream {
}

public String toString(String programName, int start, int end) {
-		List rewrites = (List)programs.get(programName);
+		List<RewriteOperation> rewrites = programs.get(programName);

// ensure start/end are in range
if ( end>tokens.size()-1 ) end = tokens.size()-1;
@@ -377,7 +377,7 @@ public class TokenRewriteStream extends CommonTokenStream {
StringBuffer buf = new StringBuffer();

// First, optimize instruction stream
-		Map indexToOp = reduceToSingleOperationPerIndex(rewrites);
+		Map<Integer, ? extends RewriteOperation> indexToOp = reduceToSingleOperationPerIndex(rewrites);

// Walk buffer, executing instructions and emitting tokens
int i = start;
@@ -401,7 +401,7 @@ public class TokenRewriteStream extends CommonTokenStream {
if ( end==tokens.size()-1 ) {
// Scan any remaining operations after last token
// should be included (they will be inserts).
-            Iterator it = indexToOp.values().iterator();
+            Iterator<? extends RewriteOperation> it = indexToOp.values().iterator();
while (it.hasNext()) {
RewriteOperation op = (RewriteOperation)it.next();
if ( op.index >= tokens.size()-1 ) buf.append(op.text);
@@ -459,7 +459,7 @@ public class TokenRewriteStream extends CommonTokenStream {
*
*  Return a map from token index to operation.
*/
-	protected Map reduceToSingleOperationPerIndex(List rewrites) {
+	protected Map<Integer, ? extends RewriteOperation> reduceToSingleOperationPerIndex(List<? extends RewriteOperation> rewrites) {
//		System.out.println("rewrites="+rewrites);

// WALK REPLACES
@@ -469,7 +469,7 @@ public class TokenRewriteStream extends CommonTokenStream {
if ( !(op instanceof ReplaceOp) ) continue;
ReplaceOp rop = (ReplaceOp)rewrites.get(i);
// Wipe prior inserts within range
-			List inserts = getKindOfOps(rewrites, InsertBeforeOp.class, i);
+			List<? extends InsertBeforeOp> inserts = getKindOfOps(rewrites, InsertBeforeOp.class, i);
for (int j = 0; j < inserts.size(); j++) {
InsertBeforeOp iop = (InsertBeforeOp) inserts.get(j);
if ( iop.index == rop.index ) {
@@ -484,7 +484,7 @@ public class TokenRewriteStream extends CommonTokenStream {
}
}
// Drop any prior replaces contained within
-			List prevReplaces = getKindOfOps(rewrites, ReplaceOp.class, i);
+			List<? extends ReplaceOp> prevReplaces = getKindOfOps(rewrites, ReplaceOp.class, i);
for (int j = 0; j < prevReplaces.size(); j++) {
ReplaceOp prevRop = (ReplaceOp) prevReplaces.get(j);
if ( prevRop.index>=rop.index && prevRop.lastIndex <= rop.lastIndex ) {
@@ -520,7 +520,7 @@ public class TokenRewriteStream extends CommonTokenStream {
if ( !(op instanceof InsertBeforeOp) ) continue;
InsertBeforeOp iop = (InsertBeforeOp)rewrites.get(i);
// combine current insert with prior if any at same index
-			List prevInserts = getKindOfOps(rewrites, InsertBeforeOp.class, i);
+			List<? extends InsertBeforeOp> prevInserts = getKindOfOps(rewrites, InsertBeforeOp.class, i);
for (int j = 0; j < prevInserts.size(); j++) {
InsertBeforeOp prevIop = (InsertBeforeOp) prevInserts.get(j);
if ( prevIop.index == iop.index ) { // combine objects
@@ -532,7 +532,7 @@ public class TokenRewriteStream extends CommonTokenStream {
}
}
// look for replaces where iop.index is in range; error
-			List prevReplaces = getKindOfOps(rewrites, ReplaceOp.class, i);
+			List<? extends ReplaceOp> prevReplaces = getKindOfOps(rewrites, ReplaceOp.class, i);
for (int j = 0; j < prevReplaces.size(); j++) {
ReplaceOp rop = (ReplaceOp) prevReplaces.get(j);
if ( iop.index == rop.index ) {
@@ -547,7 +547,7 @@ public class TokenRewriteStream extends CommonTokenStream {
}
}
// System.out.println("rewrites after="+rewrites);
-		Map m = new HashMap();
+		Map<Integer, RewriteOperation> m = new HashMap<Integer, RewriteOperation>();
for (int i = 0; i < rewrites.size(); i++) {
RewriteOperation op = (RewriteOperation)rewrites.get(i);
if ( op==null ) continue; // ignore deleted ops
@@ -567,17 +567,17 @@ public class TokenRewriteStream extends CommonTokenStream {
if ( b!=null ) y = b.toString();
return x+y;
}
-	protected List getKindOfOps(List rewrites, Class kind) {
+	protected <T extends RewriteOperation> List<? extends T> getKindOfOps(List<? extends RewriteOperation> rewrites, Class<T> kind) {
return getKindOfOps(rewrites, kind, rewrites.size());
}

/** Get all operations before an index of a particular kind */
-    protected List getKindOfOps(List rewrites, Class kind, int before) {
-		List ops = new ArrayList();
+    protected <T extends RewriteOperation> List<? extends T> getKindOfOps(List<? extends RewriteOperation> rewrites, Class<T> kind, int before) {
+		List<T> ops = new ArrayList<T>();
for (int i=0; i<before && i<rewrites.size(); i++) {
RewriteOperation op = (RewriteOperation)rewrites.get(i);
if ( op==null ) continue; // ignore deleted
-			if ( op.getClass() == kind ) ops.add(op);
+			if ( kind.isInstance(op) ) ops.add(kind.cast(op));
}
return ops;
}
diff --git a/runtime/Java/src/main/java/org/antlr/runtime/debug/DebugEventHub.java b/runtime/Java/src/main/java/org/antlr/runtime/debug/DebugEventHub.java
index 8cbb4bf..7e072ec 100644
--- a/runtime/Java/src/main/java/org/antlr/runtime/debug/DebugEventHub.java
+++ b/runtime/Java/src/main/java/org/antlr/runtime/debug/DebugEventHub.java
@@ -40,7 +40,7 @@ import java.util.ArrayList;
*  @see also DebugEventRepeater
*/
public class DebugEventHub implements DebugEventListener {
-	protected List listeners = new ArrayList();
+	protected List<DebugEventListener> listeners = new ArrayList<DebugEventListener>();

public DebugEventHub(DebugEventListener listener) {
listeners.add(listener);
diff --git a/runtime/Java/src/main/java/org/antlr/runtime/debug/ParseTreeBuilder.java b/runtime/Java/src/main/java/org/antlr/runtime/debug/ParseTreeBuilder.java
index 85b890a..6c4f609 100644
--- a/runtime/Java/src/main/java/org/antlr/runtime/debug/ParseTreeBuilder.java
+++ b/runtime/Java/src/main/java/org/antlr/runtime/debug/ParseTreeBuilder.java
@@ -41,8 +41,8 @@ import java.util.List;
public class ParseTreeBuilder extends BlankDebugEventListener {
public static final String EPSILON_PAYLOAD = "<epsilon>";

-	Stack callStack = new Stack();
-	List hiddenTokens = new ArrayList();
+	Stack<ParseTree> callStack = new Stack<ParseTree>();
+	List<Token> hiddenTokens = new ArrayList<Token>();
int backtracking = 0;

public ParseTreeBuilder(String grammarName) {
@@ -96,7 +96,7 @@ public class ParseTreeBuilder extends BlankDebugEventListener {
ParseTree ruleNode = (ParseTree)callStack.peek();
ParseTree elementNode = create(token);
elementNode.hiddenTokens = this.hiddenTokens;
-		this.hiddenTokens = new ArrayList();
+		this.hiddenTokens = new ArrayList<Token>();
ruleNode.addChild(elementNode);
}

diff --git a/runtime/Java/src/main/java/org/antlr/runtime/debug/Profiler.java b/runtime/Java/src/main/java/org/antlr/runtime/debug/Profiler.java
index 48da886..c6c5af5 100644
--- a/runtime/Java/src/main/java/org/antlr/runtime/debug/Profiler.java
+++ b/runtime/Java/src/main/java/org/antlr/runtime/debug/Profiler.java
@@ -127,10 +127,10 @@ public class Profiler extends BlankDebugEventListener {
//protected int decisionLevel = 0;
protected Token lastRealTokenTouchedInDecision;
protected Set<String> uniqueRules = new HashSet<String>();
-	protected Stack<String> currentGrammarFileName = new Stack();
-	protected Stack<String> currentRuleName = new Stack();
-	protected Stack<Integer> currentLine = new Stack();
-	protected Stack<Integer> currentPos = new Stack();
+	protected Stack<String> currentGrammarFileName = new Stack<String>();
+	protected Stack<String> currentRuleName = new Stack<String>();
+	protected Stack<Integer> currentLine = new Stack<Integer>();
+	protected Stack<Integer> currentPos = new Stack<Integer>();

// Vector<DecisionStats>
//protected Vector decisions = new Vector(200); // need setSize
@@ -531,11 +531,11 @@ public class Profiler extends BlankDebugEventListener {
return stats;
}

-	public DoubleKeyMap getDecisionStats() {
+	public DoubleKeyMap<String, Integer, DecisionDescriptor> getDecisionStats() {
return decisions;
}

-	public List getDecisionEvents() {
+	public List<DecisionEvent> getDecisionEvents() {
return decisionEvents;
}

@@ -711,7 +711,7 @@ public class Profiler extends BlankDebugEventListener {
return X;
}

-	protected int[] toArray(List a) {
+	protected int[] toArray(List<Integer> a) {
int[] x = new int[a.size()];
for (int i = 0; i < a.size(); i++) {
Integer I = (Integer) a.get(i);
diff --git a/runtime/Java/src/main/java/org/antlr/runtime/tree/BaseTree.java b/runtime/Java/src/main/java/org/antlr/runtime/tree/BaseTree.java
index 0be3179..174cc42 100644
--- a/runtime/Java/src/main/java/org/antlr/runtime/tree/BaseTree.java
+++ b/runtime/Java/src/main/java/org/antlr/runtime/tree/BaseTree.java
@@ -37,7 +37,7 @@ import java.util.List;
*  non-null node is called "nil".
*/
public abstract class BaseTree implements Tree {
-	protected List children;
+	protected List<Object> children;

public BaseTree() {
}
@@ -60,7 +60,7 @@ public abstract class BaseTree implements Tree {
/** Get the children internal List; note that if you directly mess with
*  the list, do so at your own risk.
*/
-	public List getChildren() {
+	public List<? extends Object> getChildren() {
return children;
}

@@ -132,7 +132,7 @@ public abstract class BaseTree implements Tree {
}

/** Add all elements of kids list as children of this node */
-	public void addChildren(List kids) {
+	public void addChildren(List<? extends Tree> kids) {
for (int i = 0; i < kids.size(); i++) {
Tree t = (Tree) kids.get(i);
addChild(t);
@@ -199,13 +199,13 @@ public abstract class BaseTree implements Tree {
int replacingHowMany = stopChildIndex - startChildIndex + 1;
int replacingWithHowMany;
BaseTree newTree = (BaseTree)t;
-		List newChildren;
+		List<Object> newChildren;
// normalize to a list of children to add: newChildren
if ( newTree.isNil() ) {
newChildren = newTree.children;
}
else {
-			newChildren = new ArrayList(1);
+			newChildren = new ArrayList<Object>(1);
newChildren.add(newTree);
}
replacingWithHowMany = newChildren.size();
@@ -249,8 +249,8 @@ public abstract class BaseTree implements Tree {
}

/** Override in a subclass to change the impl of children list */
-	protected List createChildrenList() {
-		return new ArrayList();
+	protected List<Object> createChildrenList() {
+		return new ArrayList<Object>();
}

@Override
@@ -344,9 +344,9 @@ public abstract class BaseTree implements Tree {
*  list is the root and the last is the parent of this node.
*/
@Override
-    public List getAncestors() {
+    public List<? extends Tree> getAncestors() {
if ( getParent()==null ) return null;
-        List ancestors = new ArrayList();
+        List<Tree> ancestors = new ArrayList<Tree>();
Tree t = this;
t = t.getParent();
while ( t!=null ) {
diff --git a/runtime/Java/src/main/java/org/antlr/runtime/tree/BaseTreeAdaptor.java b/runtime/Java/src/main/java/org/antlr/runtime/tree/BaseTreeAdaptor.java
index ce5c5cf..6a76841 100644
--- a/runtime/Java/src/main/java/org/antlr/runtime/tree/BaseTreeAdaptor.java
+++ b/runtime/Java/src/main/java/org/antlr/runtime/tree/BaseTreeAdaptor.java
@@ -40,7 +40,7 @@ public abstract class BaseTreeAdaptor implements TreeAdaptor {
*  track ourselves.  That's ok, it's only for debugging, though it's
*  expensive: we have to create a hashtable with all tree nodes in it.
*/
-	protected Map treeToUniqueIDMap;
+	protected Map<Object, Integer> treeToUniqueIDMap;
protected int uniqueNodeID = 1;

@Override
@@ -256,7 +256,7 @@ public abstract class BaseTreeAdaptor implements TreeAdaptor {
@Override
public int getUniqueID(Object node) {
if ( treeToUniqueIDMap==null ) {
-			 treeToUniqueIDMap = new HashMap();
+			 treeToUniqueIDMap = new HashMap<Object, Integer>();
}
Integer prevID = (Integer)treeToUniqueIDMap.get(node);
if ( prevID!=null ) {
diff --git a/runtime/Java/src/main/java/org/antlr/runtime/tree/BufferedTreeNodeStream.java b/runtime/Java/src/main/java/org/antlr/runtime/tree/BufferedTreeNodeStream.java
index 242e407..b8f1394 100644
--- a/runtime/Java/src/main/java/org/antlr/runtime/tree/BufferedTreeNodeStream.java
+++ b/runtime/Java/src/main/java/org/antlr/runtime/tree/BufferedTreeNodeStream.java
@@ -58,7 +58,7 @@ public class BufferedTreeNodeStream implements TreeNodeStream {
public static final int DEFAULT_INITIAL_BUFFER_SIZE = 100;
public static final int INITIAL_CALL_STACK_SIZE = 10;

-    protected class StreamIterator implements Iterator {
+    protected class StreamIterator implements Iterator<Object> {
int i = 0;
@Override
public boolean hasNext() {
@@ -97,7 +97,7 @@ public class BufferedTreeNodeStream implements TreeNodeStream {
*  of interest for reverseIndexing.  Slows us down a wee bit to
*  do all of the if p==-1 testing everywhere though.
*/
-	protected List nodes;
+	protected List<Object> nodes;

/** Pull nodes from which tree? */
protected Object root;
@@ -133,7 +133,7 @@ public class BufferedTreeNodeStream implements TreeNodeStream {
public BufferedTreeNodeStream(TreeAdaptor adaptor, Object tree, int initialBufferSize) {
this.root = tree;
this.adaptor = adaptor;
-		nodes = new ArrayList(initialBufferSize);
+		nodes = new ArrayList<Object>(initialBufferSize);
down = adaptor.create(Token.DOWN, "DOWN");
up = adaptor.create(Token.UP, "UP");
eof = adaptor.create(Token.EOF, "EOF");
@@ -392,7 +392,7 @@ public class BufferedTreeNodeStream implements TreeNodeStream {
return nodes.size();
}

-	public Iterator iterator() {
+	public Iterator<Object> iterator() {
if ( p==-1 ) {
fillBuffer();
}
diff --git a/runtime/Java/src/main/java/org/antlr/runtime/tree/DOTTreeGenerator.java b/runtime/Java/src/main/java/org/antlr/runtime/tree/DOTTreeGenerator.java
index 6c519d1..0cac04a 100644
--- a/runtime/Java/src/main/java/org/antlr/runtime/tree/DOTTreeGenerator.java
+++ b/runtime/Java/src/main/java/org/antlr/runtime/tree/DOTTreeGenerator.java
@@ -71,7 +71,7 @@ public class DOTTreeGenerator {
new StringTemplate("$parent$ -> $child$ // \"$parentText$\" -> \"$childText$\"\n");

/** Track node to number mapping so we can get proper node name back */
-	HashMap nodeToNumberMap = new HashMap();
+	HashMap<Object, Integer> nodeToNumberMap = new HashMap<Object, Integer>();

/** Track node number so we can get unique node names */
int nodeNumber = 0;
diff --git a/runtime/Java/src/main/java/org/antlr/runtime/tree/ParseTree.java b/runtime/Java/src/main/java/org/antlr/runtime/tree/ParseTree.java
index 72aad56..a60d96c 100644
--- a/runtime/Java/src/main/java/org/antlr/runtime/tree/ParseTree.java
+++ b/runtime/Java/src/main/java/org/antlr/runtime/tree/ParseTree.java
@@ -38,7 +38,7 @@ import java.util.List;
*/
public class ParseTree extends BaseTree {
public Object payload;
-	public List hiddenTokens;
+	public List<Token> hiddenTokens;

public ParseTree(Object label) {
this.payload = label;
diff --git a/runtime/Java/src/main/java/org/antlr/runtime/tree/RewriteRuleElementStream.java b/runtime/Java/src/main/java/org/antlr/runtime/tree/RewriteRuleElementStream.java
index 61f1860..da858c7 100644
--- a/runtime/Java/src/main/java/org/antlr/runtime/tree/RewriteRuleElementStream.java
+++ b/runtime/Java/src/main/java/org/antlr/runtime/tree/RewriteRuleElementStream.java
@@ -53,7 +53,7 @@ public abstract class RewriteRuleElementStream {
protected Object singleElement;

/** The list of tokens or subtrees we are tracking */
-	protected List elements;
+	protected List<Object> elements;

/** Once a node / subtree has been used in a stream, it must be dup'd
*  from then on.  Streams are reset after subrules so that the streams
@@ -91,7 +91,7 @@ public abstract class RewriteRuleElementStream {
/** Create a stream, but feed off an existing list */
public RewriteRuleElementStream(TreeAdaptor adaptor,
String elementDescription,
-									List elements)
+									List<Object> elements)
{
this(adaptor, elementDescription);
this.singleElement = null;
@@ -122,7 +122,7 @@ public abstract class RewriteRuleElementStream {
return;
}
// adding 2nd element, move to list
-		elements = new ArrayList(5);
+		elements = new ArrayList<Object>(5);
elements.add(singleElement);
singleElement = null;
elements.add(el);
diff --git a/runtime/Java/src/main/java/org/antlr/runtime/tree/RewriteRuleNodeStream.java b/runtime/Java/src/main/java/org/antlr/runtime/tree/RewriteRuleNodeStream.java
index 5bbf4ad..1bfdab4 100644
--- a/runtime/Java/src/main/java/org/antlr/runtime/tree/RewriteRuleNodeStream.java
+++ b/runtime/Java/src/main/java/org/antlr/runtime/tree/RewriteRuleNodeStream.java
@@ -49,7 +49,7 @@ public class RewriteRuleNodeStream extends RewriteRuleElementStream {
/** Create a stream, but feed off an existing list */
public RewriteRuleNodeStream(TreeAdaptor adaptor,
String elementDescription,
-								 List elements)
+								 List<Object> elements)
{
super(adaptor, elementDescription, elements);
}
diff --git a/runtime/Java/src/main/java/org/antlr/runtime/tree/RewriteRuleSubtreeStream.java b/runtime/Java/src/main/java/org/antlr/runtime/tree/RewriteRuleSubtreeStream.java
index 32e5aee..2c8ac80 100644
--- a/runtime/Java/src/main/java/org/antlr/runtime/tree/RewriteRuleSubtreeStream.java
+++ b/runtime/Java/src/main/java/org/antlr/runtime/tree/RewriteRuleSubtreeStream.java
@@ -46,7 +46,7 @@ public class RewriteRuleSubtreeStream extends RewriteRuleElementStream {
/** Create a stream, but feed off an existing list */
public RewriteRuleSubtreeStream(TreeAdaptor adaptor,
String elementDescription,
-									List elements)
+									List<Object> elements)
{
super(adaptor, elementDescription, elements);
}
diff --git a/runtime/Java/src/main/java/org/antlr/runtime/tree/RewriteRuleTokenStream.java b/runtime/Java/src/main/java/org/antlr/runtime/tree/RewriteRuleTokenStream.java
index c59304f..41ce04b 100644
--- a/runtime/Java/src/main/java/org/antlr/runtime/tree/RewriteRuleTokenStream.java
+++ b/runtime/Java/src/main/java/org/antlr/runtime/tree/RewriteRuleTokenStream.java
@@ -48,7 +48,7 @@ public class RewriteRuleTokenStream extends RewriteRuleElementStream {
/** Create a stream, but feed off an existing list */
public RewriteRuleTokenStream(TreeAdaptor adaptor,
String elementDescription,
-								  List elements)
+								  List<Object> elements)
{
super(adaptor, elementDescription, elements);
}
diff --git a/runtime/Java/src/main/java/org/antlr/runtime/tree/Tree.java b/runtime/Java/src/main/java/org/antlr/runtime/tree/Tree.java
index 860c22e..a79283d 100644
--- a/runtime/Java/src/main/java/org/antlr/runtime/tree/Tree.java
+++ b/runtime/Java/src/main/java/org/antlr/runtime/tree/Tree.java
@@ -63,7 +63,7 @@ public interface Tree {
/** Return a list of all ancestors of this node.  The first node of
*  list is the root and the last is the parent of this node.
*/
-    public List getAncestors();
+    public List<?> getAncestors();

/** This node is what child index? 0..n-1 */
public int getChildIndex();
diff --git a/runtime/Java/src/main/java/org/antlr/runtime/tree/TreeIterator.java b/runtime/Java/src/main/java/org/antlr/runtime/tree/TreeIterator.java
index f7162b5..4c5d0cc 100644
--- a/runtime/Java/src/main/java/org/antlr/runtime/tree/TreeIterator.java
+++ b/runtime/Java/src/main/java/org/antlr/runtime/tree/TreeIterator.java
@@ -38,7 +38,7 @@ import java.util.Iterator;
*
*  Emit navigation nodes (DOWN, UP, and EOF) to let show tree structure.
*/
-public class TreeIterator implements Iterator {
+public class TreeIterator implements Iterator<Object> {
protected TreeAdaptor adaptor;
protected Object root;
protected Object tree;
@@ -52,7 +52,7 @@ public class TreeIterator implements Iterator {
/** If we emit UP/DOWN nodes, we need to spit out multiple nodes per
*  next() call.
*/
-    protected FastQueue nodes;
+    protected FastQueue<Object> nodes;

public TreeIterator(Object tree) {
this(new CommonTreeAdaptor(),tree);
@@ -62,7 +62,7 @@ public class TreeIterator implements Iterator {
this.adaptor = adaptor;
this.tree = tree;
this.root = tree;
-        nodes = new FastQueue();
+        nodes = new FastQueue<Object>();
down = adaptor.create(Token.DOWN, "DOWN");
up = adaptor.create(Token.UP, "UP");
eof = adaptor.create(Token.EOF, "EOF");
diff --git a/runtime/Java/src/main/java/org/antlr/runtime/tree/TreeWizard.java b/runtime/Java/src/main/java/org/antlr/runtime/tree/TreeWizard.java
index 201b45f..2eabf25 100644
--- a/runtime/Java/src/main/java/org/antlr/runtime/tree/TreeWizard.java
+++ b/runtime/Java/src/main/java/org/antlr/runtime/tree/TreeWizard.java
@@ -52,16 +52,16 @@ import java.util.Map;
*/
public class TreeWizard {
protected TreeAdaptor adaptor;
-	protected Map tokenNameToTypeMap;
+	protected Map<String, Integer> tokenNameToTypeMap;

public interface ContextVisitor {
// TODO: should this be called visit or something else?
-		public void visit(Object t, Object parent, int childIndex, Map labels);
+		public void visit(Object t, Object parent, int childIndex, Map<String, Object> labels);
}

public static abstract class Visitor implements ContextVisitor {
@Override
-		public void visit(Object t, Object parent, int childIndex, Map labels) {
+		public void visit(Object t, Object parent, int childIndex, Map<String, Object> labels) {
visit(t);
}
public abstract void visit(Object t);
@@ -126,7 +126,7 @@ public class TreeWizard {
this.adaptor = adaptor;
}

-	public TreeWizard(TreeAdaptor adaptor, Map tokenNameToTypeMap) {
+	public TreeWizard(TreeAdaptor adaptor, Map<String, Integer> tokenNameToTypeMap) {
this.adaptor = adaptor;
this.tokenNameToTypeMap = tokenNameToTypeMap;
}
@@ -143,8 +143,8 @@ public class TreeWizard {
/** Compute a Map<String, Integer> that is an inverted index of
*  tokenNames (which maps int token types to names).
*/
-	public Map computeTokenTypes(String[] tokenNames) {
-		Map m = new HashMap();
+	public Map<String, Integer> computeTokenTypes(String[] tokenNames) {
+		Map<String, Integer> m = new HashMap<String, Integer>();
if ( tokenNames==null ) {
return m;
}
@@ -174,21 +174,21 @@ public class TreeWizard {
*
*  TODO: save this index so that find and visit are faster
*/
-	public Map index(Object t) {
-		Map m = new HashMap();
+	public Map<Integer, List<Object>> index(Object t) {
+		Map<Integer, List<Object>> m = new HashMap<Integer, List<Object>>();
_index(t, m);
return m;
}

/** Do the work for index */
-	protected void _index(Object t, Map m) {
+	protected void _index(Object t, Map<Integer, List<Object>> m) {
if ( t==null ) {
return;
}
int ttype = adaptor.getType(t);
-		List elements = (List)m.get(new Integer(ttype));
+		List<Object> elements = m.get(new Integer(ttype));
if ( elements==null ) {
-			elements = new ArrayList();
+			elements = new ArrayList<Object>();
m.put(new Integer(ttype), elements);
}
elements.add(t);
@@ -200,8 +200,8 @@ public class TreeWizard {
}

/** Return a List of tree nodes with token type ttype */
-	public List find(Object t, int ttype) {
-		final List nodes = new ArrayList();
+	public List<? extends Object> find(Object t, int ttype) {
+		final List<Object> nodes = new ArrayList<Object>();
visit(t, ttype, new TreeWizard.Visitor() {
@Override
public void visit(Object t) {
@@ -212,8 +212,8 @@ public class TreeWizard {
}

/** Return a List of subtrees matching pattern. */
-	public List find(Object t, String pattern) {
-		final List subtrees = new ArrayList();
+	public List<? extends Object> find(Object t, String pattern) {
+		final List<Object> subtrees = new ArrayList<Object>();
// Create a TreePattern from the pattern
TreePatternLexer tokenizer = new TreePatternLexer(pattern);
TreePatternParser parser =
@@ -288,11 +288,11 @@ public class TreeWizard {
{
return;
}
-		final Map labels = new HashMap(); // reused for each _parse
+		final Map<String, Object> labels = new HashMap<String, Object>(); // reused for each _parse
int rootTokenType = tpattern.getType();
visit(t, rootTokenType, new TreeWizard.ContextVisitor() {
@Override
-			public void visit(Object t, Object parent, int childIndex, Map unusedlabels) {
+			public void visit(Object t, Object parent, int childIndex, Map<String, Object> unusedlabels) {
// the unusedlabels arg is null as visit on token type doesn't set.
labels.clear();
if ( _parse(t, tpattern, labels) ) {
@@ -313,7 +313,7 @@ public class TreeWizard {
*
*  TODO: what's a better way to indicate bad pattern? Exceptions are a hassle
*/
-	public boolean parse(Object t, String pattern, Map labels) {
+	public boolean parse(Object t, String pattern, Map<String, Object> labels) {
TreePatternLexer tokenizer = new TreePatternLexer(pattern);
TreePatternParser parser =
new TreePatternParser(tokenizer, this, new TreePatternTreeAdaptor());
@@ -335,7 +335,7 @@ public class TreeWizard {
*  text arguments on nodes.  Fill labels map with pointers to nodes
*  in tree matched against nodes in pattern with labels.
*/
-	protected boolean _parse(Object t1, TreePattern tpattern, Map labels) {
+	protected boolean _parse(Object t1, TreePattern tpattern, Map<String, Object> labels) {
// make sure both are non-null
if ( t1==null || tpattern==null ) {
return false;
diff --git a/tool/src/main/antlr3/org/antlr/grammar/v3/ActionTranslator.g b/tool/src/main/antlr3/org/antlr/grammar/v3/ActionTranslator.g
index ec1b744..713cef0 100644
--- a/tool/src/main/antlr3/org/antlr/grammar/v3/ActionTranslator.g
+++ b/tool/src/main/antlr3/org/antlr/grammar/v3/ActionTranslator.g
@@ -47,7 +47,7 @@ import org.antlr.grammar.v3.ANTLRParser;
}

@members {
-public List chunks = new ArrayList();
+public List<Object> chunks = new ArrayList<Object>();
Rule enclosingRule;
int outerAltNum;
Grammar grammar;
@@ -82,7 +82,7 @@ Token actionToken;
/** Return a list of strings and ST objects that
*  represent the translated action.
*/
-public List translateToChunks() {
+public List<Object> translateToChunks() {
// System.out.println("###\naction="+action);
Token t;
do {
@@ -92,7 +92,7 @@ public List translateToChunks() {
}

public String translate() {
-	List theChunks = translateToChunks();
+	List<Object> theChunks = translateToChunks();
//System.out.println("chunks="+a.chunks);
StringBuffer buf = new StringBuffer();
for (int i = 0; i < theChunks.size(); i++) {
@@ -104,7 +104,7 @@ public String translate() {
return buf.toString();
}

-public List translateAction(String action) {
+public List<Object> translateAction(String action) {
String rname = null;
if ( enclosingRule!=null ) {
rname = enclosingRule.name;
@@ -127,7 +127,7 @@ public Grammar.LabelElementPair getElementLabel(String id) {
}

public void checkElementRefUniqueness(String ref, boolean isToken) {
-		List refs = null;
+		List<GrammarAST> refs = null;
if ( isToken ) {
refs = enclosingRule.getTokenRefsInAlt(ref, outerAltNum);
}
diff --git a/tool/src/main/antlr3/org/antlr/grammar/v3/CodeGenTreeWalker.g b/tool/src/main/antlr3/org/antlr/grammar/v3/CodeGenTreeWalker.g
index 7f3b397..54a5ffb 100644
--- a/tool/src/main/antlr3/org/antlr/grammar/v3/CodeGenTreeWalker.g
+++ b/tool/src/main/antlr3/org/antlr/grammar/v3/CodeGenTreeWalker.g
@@ -660,7 +660,7 @@ exceptionGroup[ST ruleST]
exceptionHandler[ST ruleST]
:	^('catch' ARG_ACTION ACTION)
{
-			List chunks = generator.translateAction(currentRuleName,$ACTION);
+			List<? extends Object> chunks = generator.translateAction(currentRuleName,$ACTION);
$ruleST.addAggr("exceptions.{decl,action}",$ARG_ACTION.text,chunks);
}
;
@@ -668,7 +668,7 @@ exceptionHandler[ST ruleST]
finallyClause[ST ruleST]
:	^('finally' ACTION)
{
-			List chunks = generator.translateAction(currentRuleName,$ACTION);
+			List<? extends Object> chunks = generator.translateAction(currentRuleName,$ACTION);
$ruleST.add("finally",chunks);
}
;
@@ -1002,7 +1002,7 @@ atom[GrammarAST scope, GrammarAST label, GrammarAST astSuffix]
}

if ( $rarg!=null ) {
-				List args = generator.translateAction(currentRuleName,$rarg);
+				List<? extends Object> args = generator.translateAction(currentRuleName,$rarg);
$code.add("args", args);
}
int i = ((CommonToken)r.getToken()).getTokenIndex();
@@ -1054,7 +1054,7 @@ atom[GrammarAST scope, GrammarAST label, GrammarAST astSuffix]
}
if ( $targ!=null )
{
-						List args = generator.translateAction(currentRuleName,$targ);
+						List<? extends Object> args = generator.translateAction(currentRuleName,$targ);
$code.add("args", args);
}
}
@@ -1240,7 +1240,7 @@ rewrite returns [ST code=null]
^( r=REWRITE (pred=SEMPRED)? alt=rewrite_alternative)
{
rewriteBlockNestingLevel = OUTER_REWRITE_NESTING_LEVEL;
-					List predChunks = null;
+					List<? extends Object> predChunks = null;
if ( $pred!=null )
{
//predText = #pred.getText();
@@ -1459,7 +1459,7 @@ rewrite_atom[boolean isRoot] returns [ST code=null]
$code.add("terminalOptions",term.terminalOptions);
if ( $arg!=null )
{
-				List args = generator.translateAction(currentRuleName,$arg);
+				List<? extends Object> args = generator.translateAction(currentRuleName,$arg);
$code.add("args", args);
}
$code.add("elementIndex", ((CommonToken)$start.getToken()).getTokenIndex());
@@ -1541,7 +1541,7 @@ rewrite_atom[boolean isRoot] returns [ST code=null]
{
// actions in rewrite rules yield a tree object
String actText = $ACTION.text;
-			List chunks = generator.translateAction(currentRuleName,$ACTION);
+			List<? extends Object> chunks = generator.translateAction(currentRuleName,$ACTION);
$code = templates.getInstanceOf("rewriteNodeAction"+(isRoot?"Root":""));
$code.add("action", chunks);
}
@@ -1564,7 +1564,7 @@ rewrite_template returns [ST code=null]
else if ( $ind!=null )
{ // must be \%({expr})(args)
$code = templates.getInstanceOf("rewriteIndirectTemplate");
-					List chunks=generator.translateAction(currentRuleName,$ind);
+					List<? extends Object> chunks=generator.translateAction(currentRuleName,$ind);
$code.add("expr", chunks);
}
}
@@ -1575,7 +1575,7 @@ rewrite_template returns [ST code=null]
// because actions like \%foo(name={\$ID.text}) aren't
// broken up yet into trees.
$a.outerAltNum = this.outerAltNum;
-						List chunks = generator.translateAction(currentRuleName,$a);
+						List<? extends Object> chunks = generator.translateAction(currentRuleName,$a);
$code.addAggr("args.{name,value}", $arg.text, chunks);
}
)
diff --git a/tool/src/main/antlr3/org/antlr/grammar/v3/DefineGrammarItemsWalker.g b/tool/src/main/antlr3/org/antlr/grammar/v3/DefineGrammarItemsWalker.g
index 36702c4..022320d 100644
--- a/tool/src/main/antlr3/org/antlr/grammar/v3/DefineGrammarItemsWalker.g
+++ b/tool/src/main/antlr3/org/antlr/grammar/v3/DefineGrammarItemsWalker.g
@@ -628,7 +628,7 @@ rewrite_atom
if ( state.backtracking == 0 )
{
Rule r = grammar.getRule(currentRuleName);
-		Set tokenRefsInAlt = r.getTokenRefsInAlt(outerAltNum);
+		Set<String> tokenRefsInAlt = r.getTokenRefsInAlt(outerAltNum);
boolean imaginary =
$start.getType()==TOKEN_REF &&
!tokenRefsInAlt.contains($start.getText());
diff --git a/tool/src/main/java/org/antlr/Tool.java b/tool/src/main/java/org/antlr/Tool.java
index 7aa776a..484339b 100644
--- a/tool/src/main/java/org/antlr/Tool.java
+++ b/tool/src/main/java/org/antlr/Tool.java
@@ -558,7 +558,7 @@ public class Tool {

public void sortGrammarFiles() throws IOException {
//System.out.println("Grammar names "+getGrammarFileNames());
-        Graph g = new Graph();
+        Graph<String> g = new Graph<String>();
List<String> missingFiles = new ArrayList<String>();
for (String gfile : grammarFileNames) {
try {
@@ -576,7 +576,7 @@ public class Tool {
missingFiles.add(gfile);
}
}
-        List<Object> sorted = g.sort();
+        List<String> sorted = g.sort();
//System.out.println("sorted="+sorted);
grammarFileNames.clear(); // wipe so we can give new ordered list
for (int i = 0; i < sorted.size(); i++) {
@@ -692,10 +692,10 @@ public class Tool {

protected void generateNFAs(Grammar g) {
DOTGenerator dotGenerator = new DOTGenerator(g);
-        Collection rules = g.getAllImportedRules();
+        Collection<Rule> rules = new HashSet<Rule>(g.getAllImportedRules());
rules.addAll(g.getRules());

-        for (Iterator itr = rules.iterator(); itr.hasNext();) {
+        for (Iterator<Rule> itr = rules.iterator(); itr.hasNext();) {
Rule r = (Rule) itr.next();
try {
String dot = dotGenerator.getDOT(r.startState);
diff --git a/tool/src/main/java/org/antlr/analysis/DFA.java b/tool/src/main/java/org/antlr/analysis/DFA.java
index 742869f..7a3fac1 100644
--- a/tool/src/main/java/org/antlr/analysis/DFA.java
+++ b/tool/src/main/java/org/antlr/analysis/DFA.java
@@ -183,7 +183,7 @@ public class DFA {
*     	  ...
*      };
*/
-	public Map edgeTransitionClassMap = new LinkedHashMap();
+	public Map<List<Integer>, Integer> edgeTransitionClassMap = new LinkedHashMap<List<Integer>, Integer>();

/** The unique edge transition class number; every time we see a new
*  set of edges emanating from a state, we number it so we can reuse
@@ -202,20 +202,20 @@ public class DFA {
*/

/** List of special DFAState objects */
-	public List specialStates;
+	public List<DFAState> specialStates;
/** List of ST for special states. */
-	public List specialStateSTs;
-	public Vector accept;
-	public Vector eot;
-	public Vector eof;
-	public Vector min;
-	public Vector max;
-	public Vector special;
-	public Vector transition;
+	public List<ST> specialStateSTs;
+	public Vector<Integer> accept;
+	public Vector<Integer> eot;
+	public Vector<Integer> eof;
+	public Vector<Integer> min;
+	public Vector<Integer> max;
+	public Vector<Integer> special;
+	public Vector<Vector<Integer>> transition;
/** just the Vector<Integer> indicating which unique edge table is at
*  position i.
*/
-	public Vector transitionEdgeTables; // not used by java yet
+	public Vector<Integer> transitionEdgeTables; // not used by java yet
protected int uniqueCompressedSpecialStateNum = 0;

/** Which generator to use if we're building state tables */
@@ -320,20 +320,20 @@ public class DFA {
// or even consistently formatted strings acceptable to java that
// I am forced to build the individual char elements here

-	public List getJavaCompressedAccept() { return getRunLengthEncoding(accept); }
-	public List getJavaCompressedEOT() { return getRunLengthEncoding(eot); }
-	public List getJavaCompressedEOF() { return getRunLengthEncoding(eof); }
-	public List getJavaCompressedMin() { return getRunLengthEncoding(min); }
-	public List getJavaCompressedMax() { return getRunLengthEncoding(max); }
-	public List getJavaCompressedSpecial() { return getRunLengthEncoding(special); }
-	public List getJavaCompressedTransition() {
+	public List<? extends String> getJavaCompressedAccept() { return getRunLengthEncoding(accept); }
+	public List<? extends String> getJavaCompressedEOT() { return getRunLengthEncoding(eot); }
+	public List<? extends String> getJavaCompressedEOF() { return getRunLengthEncoding(eof); }
+	public List<? extends String> getJavaCompressedMin() { return getRunLengthEncoding(min); }
+	public List<? extends String> getJavaCompressedMax() { return getRunLengthEncoding(max); }
+	public List<? extends String> getJavaCompressedSpecial() { return getRunLengthEncoding(special); }
+	public List<List<? extends String>> getJavaCompressedTransition() {
if ( transition==null || transition.isEmpty() ) {
return null;
}
-		List encoded = new ArrayList(transition.size());
+		List<List<? extends String>> encoded = new ArrayList<List<? extends String>>(transition.size());
// walk Vector<Vector<FormattedInteger>> which is the transition[][] table
for (int i = 0; i < transition.size(); i++) {
-			Vector transitionsForState = (Vector) transition.elementAt(i);
+			Vector<Integer> transitionsForState = transition.elementAt(i);
encoded.add(getRunLengthEncoding(transitionsForState));
}
return encoded;
@@ -349,16 +349,16 @@ public class DFA {
*  and \uFFFF for 16bit.  Hideous and specific to Java, but it is the
*  only target bad enough to need it.
*/
-	public List getRunLengthEncoding(List data) {
+	public List<? extends String> getRunLengthEncoding(List<Integer> data) {
if ( data==null || data.isEmpty() ) {
// for states with no transitions we want an empty string ""
// to hold its place in the transitions array.
-			List empty = new ArrayList();
+			List<String> empty = new ArrayList<String>();
empty.add("");
return empty;
}
int size = Math.max(2,data.size()/2);
-		List encoded = new ArrayList(size); // guess at size
+		List<String> encoded = new ArrayList<String>(size); // guess at size
// scan values looking for runs
int i = 0;
Integer emptyValue = Utils.integer(-1);
@@ -396,27 +396,27 @@ public class DFA {
generator.target.getTargetStringLiteralFromString(description);

// create all the tables
-		special = new Vector(this.getNumberOfStates()); // Vector<short>
+		special = new Vector<Integer>(this.getNumberOfStates()); // Vector<short>
special.setSize(this.getNumberOfStates());
-		specialStates = new ArrayList();				// List<DFAState>
-		specialStateSTs = new ArrayList();				// List<ST>
-		accept = new Vector(this.getNumberOfStates()); // Vector<int>
+		specialStates = new ArrayList<DFAState>();				// List<DFAState>
+		specialStateSTs = new ArrayList<ST>();				// List<ST>
+		accept = new Vector<Integer>(this.getNumberOfStates()); // Vector<int>
accept.setSize(this.getNumberOfStates());
-		eot = new Vector(this.getNumberOfStates()); // Vector<int>
+		eot = new Vector<Integer>(this.getNumberOfStates()); // Vector<int>
eot.setSize(this.getNumberOfStates());
-		eof = new Vector(this.getNumberOfStates()); // Vector<int>
+		eof = new Vector<Integer>(this.getNumberOfStates()); // Vector<int>
eof.setSize(this.getNumberOfStates());
-		min = new Vector(this.getNumberOfStates()); // Vector<int>
+		min = new Vector<Integer>(this.getNumberOfStates()); // Vector<int>
min.setSize(this.getNumberOfStates());
-		max = new Vector(this.getNumberOfStates()); // Vector<int>
+		max = new Vector<Integer>(this.getNumberOfStates()); // Vector<int>
max.setSize(this.getNumberOfStates());
-		transition = new Vector(this.getNumberOfStates()); // Vector<Vector<int>>
+		transition = new Vector<Vector<Integer>>(this.getNumberOfStates()); // Vector<Vector<int>>
transition.setSize(this.getNumberOfStates());
-		transitionEdgeTables = new Vector(this.getNumberOfStates()); // Vector<Vector<int>>
+		transitionEdgeTables = new Vector<Integer>(this.getNumberOfStates()); // Vector<int>
transitionEdgeTables.setSize(this.getNumberOfStates());

// for each state in the DFA, fill relevant tables.
-		Iterator it;
+		Iterator<DFAState> it;
if ( getUserMaxLookahead()>0 ) {
it = states.iterator();
}
@@ -548,7 +548,7 @@ public class DFA {
int smax = ((Integer)max.get(s.stateNumber)).intValue();
int smin = ((Integer)min.get(s.stateNumber)).intValue();

-		Vector stateTransitions = new Vector(smax-smin+1);
+		Vector<Integer> stateTransitions = new Vector<Integer>(smax-smin+1);
stateTransitions.setSize(smax-smin+1);
transition.set(s.stateNumber, stateTransitions);
for (int j = 0; j < s.getNumberOfTransitions(); j++) {
@@ -985,10 +985,10 @@ public class DFA {
DFAState a = getAcceptState(i);
//System.out.println("alt "+i+": "+a);
if ( a!=null ) {
-				Set synpreds = a.getGatedSyntacticPredicatesInNFAConfigurations();
+				Set<? extends SemanticContext> synpreds = a.getGatedSyntacticPredicatesInNFAConfigurations();
if ( synpreds!=null ) {
// add all the predicates we find (should be just one, right?)
-					for (Iterator it = synpreds.iterator(); it.hasNext();) {
+					for (Iterator<? extends SemanticContext> it = synpreds.iterator(); it.hasNext();) {
SemanticContext semctx = (SemanticContext) it.next();
// System.out.println("synpreds: "+semctx);
nfa.grammar.synPredUsedInDFA(this, semctx);
@@ -1095,7 +1095,7 @@ public class DFA {
//	}

protected void initAltRelatedInfo() {
-        unreachableAlts = new LinkedList();
+        unreachableAlts = new LinkedList<Integer>();
for (int i = 1; i <= nAlts; i++) {
unreachableAlts.add(Utils.integer(i));
}
diff --git a/tool/src/main/java/org/antlr/analysis/DFAOptimizer.java b/tool/src/main/java/org/antlr/analysis/DFAOptimizer.java
index d8e8291..aa40596 100644
--- a/tool/src/main/java/org/antlr/analysis/DFAOptimizer.java
+++ b/tool/src/main/java/org/antlr/analysis/DFAOptimizer.java
@@ -125,7 +125,7 @@ public class DFAOptimizer {
*  This is a side-effect of calling optimize; can't clear after use
*  because code gen needs it.
*/
-	protected Set visited = new HashSet();
+	protected Set<Integer> visited = new HashSet<Integer>();

protected Grammar grammar;

diff --git a/tool/src/main/java/org/antlr/analysis/DFAState.java b/tool/src/main/java/org/antlr/analysis/DFAState.java
index a9d256e..d16ffd2 100644
--- a/tool/src/main/java/org/antlr/analysis/DFAState.java
+++ b/tool/src/main/java/org/antlr/analysis/DFAState.java
@@ -380,7 +380,7 @@ public class DFAState extends State {
*/
}

-    public OrderedHashSet getReachableLabels() {
+    public OrderedHashSet<Label> getReachableLabels() {
return reachableLabels;
}

@@ -483,8 +483,8 @@ public class DFAState extends State {
*  DFA state, that alt is disabled.  There may be other accept states
*  for that alt.
*/
-	public Set getDisabledAlternatives() {
-		Set disabled = new LinkedHashSet();
+	public Set<Integer> getDisabledAlternatives() {
+		Set<Integer> disabled = new LinkedHashSet<Integer>();
int numConfigs = nfaConfigurations.size();
for (int i = 0; i < numConfigs; i++) {
NFAConfiguration configuration = (NFAConfiguration) nfaConfigurations.get(i);
@@ -495,7 +495,7 @@ public class DFAState extends State {
return disabled;
}

-	protected Set getNonDeterministicAlts() {
+	protected Set<Integer> getNonDeterministicAlts() {
int user_k = dfa.getUserMaxLookahead();
if ( user_k>0 && user_k==k ) {
// if fixed lookahead, then more than 1 alt is a nondeterminism
@@ -551,12 +551,12 @@ public class DFAState extends State {
stateToConfigListMap.map(stateI, configuration);
}
// potential conflicts are states with > 1 configuration and diff alts
-		Set states = stateToConfigListMap.keySet();
+		Set<Integer> states = stateToConfigListMap.keySet();
int numPotentialConflicts = 0;
-		for (Iterator it = states.iterator(); it.hasNext();) {
+		for (Iterator<Integer> it = states.iterator(); it.hasNext();) {
Integer stateI = (Integer) it.next();
boolean thisStateHasPotentialProblem = false;
-			List configsForState = (List)stateToConfigListMap.get(stateI);
+			List<NFAConfiguration> configsForState = stateToConfigListMap.get(stateI);
int alt=0;
int numConfigsForState = configsForState.size();
for (int i = 0; i < numConfigsForState && numConfigsForState>1 ; i++) {
@@ -613,9 +613,9 @@ public class DFAState extends State {
// Indeed a conflict exists as same state 3, same context [$], predicts
// alts 1 and 2.
// walk each state with potential conflicting configurations
-		for (Iterator it = states.iterator(); it.hasNext();) {
+		for (Iterator<Integer> it = states.iterator(); it.hasNext();) {
Integer stateI = (Integer) it.next();
-			List configsForState = (List)stateToConfigListMap.get(stateI);
+			List<NFAConfiguration> configsForState = stateToConfigListMap.get(stateI);
// compare each configuration pair s, t to ensure:
// s.ctx different than t.ctx if s.alt != t.alt
int numConfigsForState = 0;
@@ -646,9 +646,9 @@ public class DFAState extends State {
/** Get the set of all alts mentioned by all NFA configurations in this
*  DFA state.
*/
-	public Set getAltSet() {
+	public Set<Integer> getAltSet() {
int numConfigs = nfaConfigurations.size();
-		Set alts = new HashSet();
+		Set<Integer> alts = new HashSet<Integer>();
for (int i = 0; i < numConfigs; i++) {
NFAConfiguration configuration = (NFAConfiguration) nfaConfigurations.get(i);
alts.add(Utils.integer(configuration.alt));
@@ -659,7 +659,7 @@ public class DFAState extends State {
return alts;
}

-	public Set getGatedSyntacticPredicatesInNFAConfigurations() {
+	public Set<? extends SemanticContext> getGatedSyntacticPredicatesInNFAConfigurations() {
int numConfigs = nfaConfigurations.size();
Set<SemanticContext> synpreds = new HashSet<SemanticContext>();
for (int i = 0; i < numConfigs; i++) {
diff --git a/tool/src/main/java/org/antlr/analysis/DecisionProbe.java b/tool/src/main/java/org/antlr/analysis/DecisionProbe.java
index b420e85..8f95cc0 100644
--- a/tool/src/main/java/org/antlr/analysis/DecisionProbe.java
+++ b/tool/src/main/java/org/antlr/analysis/DecisionProbe.java
@@ -198,7 +198,7 @@ public class DecisionProbe {
}

if ( statesWithSyntacticallyAmbiguousAltsSet.size()>0 ) {
-			Iterator it =
+			Iterator<DFAState> it =
statesWithSyntacticallyAmbiguousAltsSet.iterator();
while (	it.hasNext() ) {
DFAState d = (DFAState) it.next();
@@ -246,23 +246,23 @@ public class DecisionProbe {
*  terminate early to avoid infinite recursion for example (due to
*  left recursion perhaps).
*/
-	public Set getDanglingStates() {
+	public Set<DFAState> getDanglingStates() {
return danglingStates;
}

-    public Set getNonDeterministicAlts() {
+    public Set<Integer> getNonDeterministicAlts() {
return altsWithProblem;
}

/** Return the sorted list of alts that conflict within a single state.
*  Note that predicates may resolve the conflict.
*/
-	public List getNonDeterministicAltsForState(DFAState targetState) {
-		Set nondetAlts = targetState.getNonDeterministicAlts();
+	public List<Integer> getNonDeterministicAltsForState(DFAState targetState) {
+		Set<Integer> nondetAlts = targetState.getNonDeterministicAlts();
if ( nondetAlts==null ) {
return null;
}
-		List sorted = new LinkedList();
+		List<Integer> sorted = new LinkedList<Integer>();
sorted.addAll(nondetAlts);
Collections.sort(sorted); // make sure it's 1, 2, ...
return sorted;
@@ -272,7 +272,7 @@ public class DecisionProbe {
*  conflict.  You must report a problem for each state in this set
*  because each state represents a different input sequence.
*/
-	public Set getDFAStatesWithSyntacticallyAmbiguousAlts() {
+	public Set<DFAState> getDFAStatesWithSyntacticallyAmbiguousAlts() {
return statesWithSyntacticallyAmbiguousAltsSet;
}

@@ -282,7 +282,7 @@ public class DecisionProbe {
*  that for this DFA state, that alt is disabled.  There may be other
*  accept states for that alt that make an alt reachable.
*/
-	public Set getDisabledAlternatives(DFAState d) {
+	public Set<Integer> getDisabledAlternatives(DFAState d) {
return d.getDisabledAlternatives();
}

@@ -299,7 +299,7 @@ public class DecisionProbe {
*  to have a problem).
*/
public List<Label> getSampleNonDeterministicInputSequence(DFAState targetState) {
-		Set dfaStates = getDFAPathStatesToTarget(targetState);
+		Set<DFAState> dfaStates = getDFAPathStatesToTarget(targetState);
statesVisitedDuringSampleSequence = new HashSet<Integer>();
List<Label> labels = new ArrayList<Label>(); // may access ith element; use array
if ( dfa==null || dfa.startState==null ) {
@@ -316,10 +316,10 @@ public class DecisionProbe {
*  of the associated input string.  One could show something different
*  for lexers and parsers, for example.
*/
-	public String getInputSequenceDisplay(List labels) {
+	public String getInputSequenceDisplay(List<? extends Label> labels) {
Grammar g = dfa.nfa.grammar;
StringBuffer buf = new StringBuffer();
-		for (Iterator it = labels.iterator(); it.hasNext();) {
+		for (Iterator<? extends Label> it = labels.iterator(); it.hasNext();) {
Label label = (Label) it.next();
buf.append(label.toString(g));
if ( it.hasNext() && g.type!=Grammar.LEXER ) {
@@ -356,12 +356,12 @@ public class DecisionProbe {
*  the extra state beginning each alt in my NFA structures).  Here,
*  firstAlt=1.
*/
-	public List getNFAPathStatesForAlt(int firstAlt,
+	public List<? extends NFAState> getNFAPathStatesForAlt(int firstAlt,
int alt,
-									   List labels)
+									   List<? extends Label> labels)
{
NFAState nfaStart = dfa.getNFADecisionStartState();
-		List path = new LinkedList();
+		List<NFAState> path = new LinkedList<NFAState>();
// first add all NFA states leading up to altStart state
for (int a=firstAlt; a<=alt; a++) {
NFAState s =
@@ -375,7 +375,7 @@ public class DecisionProbe {
path.add(isolatedAltStart);

// add the actual path now
-		statesVisitedAtInputDepth = new HashSet();
+		statesVisitedAtInputDepth = new HashSet<String>();
getNFAPath(isolatedAltStart,
0,
labels,
@@ -388,7 +388,7 @@ public class DecisionProbe {
*  predicate context for a particular alt.
*/
public SemanticContext getSemanticContextForAlt(DFAState d, int alt) {
-		Map altToPredMap = (Map)stateToAltSetWithSemanticPredicatesMap.get(d);
+		Map<Integer, SemanticContext> altToPredMap = stateToAltSetWithSemanticPredicatesMap.get(d);
if ( altToPredMap==null ) {
return null;
}
@@ -400,7 +400,7 @@ public class DecisionProbe {
return stateToAltSetWithSemanticPredicatesMap.size()>0;
}

-	public Set getNondeterministicStatesResolvedWithSemanticPredicate() {
+	public Set<DFAState> getNondeterministicStatesResolvedWithSemanticPredicate() {
return statesResolvedWithSemanticPredicatesSet;
}

@@ -422,10 +422,10 @@ public class DecisionProbe {
issueRecursionWarnings();

// generate a separate message for each problem state in DFA
-		Set resolvedStates = getNondeterministicStatesResolvedWithSemanticPredicate();
-		Set problemStates = getDFAStatesWithSyntacticallyAmbiguousAlts();
+		Set<DFAState> resolvedStates = getNondeterministicStatesResolvedWithSemanticPredicate();
+		Set<DFAState> problemStates = getDFAStatesWithSyntacticallyAmbiguousAlts();
if ( problemStates.size()>0 ) {
-			Iterator it =
+			Iterator<DFAState> it =
problemStates.iterator();
while (	it.hasNext() && !dfa.nfa.grammar.NFAToDFAConversionExternallyAborted() ) {
DFAState d = (DFAState) it.next();
@@ -437,7 +437,7 @@ public class DecisionProbe {
if ( resolvedStates==null || !resolvedStates.contains(d) ) {
// first strip last alt from disableAlts if it's wildcard
// then don't print error if no more disable alts
-					Set disabledAlts = getDisabledAlternatives(d);
+					Set<Integer> disabledAlts = getDisabledAlternatives(d);
stripWildCardAlts(disabledAlts);
if ( disabledAlts.size()>0 ) {
// nondeterminism; same input predicts multiple alts.
@@ -455,10 +455,10 @@ public class DecisionProbe {
}
}

-		Set danglingStates = getDanglingStates();
+		Set<DFAState> danglingStates = getDanglingStates();
if ( danglingStates.size()>0 ) {
//System.err.println("no emanating edges for states: "+danglingStates);
-			for (Iterator it = danglingStates.iterator(); it.hasNext();) {
+			for (Iterator<DFAState> it = danglingStates.iterator(); it.hasNext();) {
DFAState d = (DFAState) it.next();
ErrorManager.danglingState(this,d);
}
@@ -498,8 +498,8 @@ public class DecisionProbe {
*  if that alt is a simple wildcard.  If so, treat like an else clause
*  and don't emit the error.  Strip out the last alt if it's wildcard.
*/
-	protected void stripWildCardAlts(Set disabledAlts) {
-		List sortedDisableAlts = new ArrayList(disabledAlts);
+	protected void stripWildCardAlts(Set<Integer> disabledAlts) {
+		List<Integer> sortedDisableAlts = new ArrayList<Integer>(disabledAlts);
Collections.sort(sortedDisableAlts);
Integer lastAlt =
(Integer)sortedDisableAlts.get(sortedDisableAlts.size()-1);
@@ -530,29 +530,30 @@ public class DecisionProbe {

protected void issueRecursionWarnings() {
// RECURSION OVERFLOW
-		Set dfaStatesWithRecursionProblems =
+		Set<Integer> dfaStatesWithRecursionProblems =
stateToRecursionOverflowConfigurationsMap.keySet();
// now walk truly unique (unaliased) list of dfa states with inf recur
// Goal: create a map from alt to map<target,List<callsites>>
// Map<Map<String target, List<NFAState call sites>>
-		Map altToTargetToCallSitesMap = new HashMap();
+		Map<Integer, Map<String, Set<NFAState>>> altToTargetToCallSitesMap =
+			new HashMap<Integer, Map<String, Set<NFAState>>>();
// track a single problem DFA state for each alt
-		Map altToDFAState = new HashMap();
+		Map<Integer, DFAState> altToDFAState = new HashMap<Integer, DFAState>();
computeAltToProblemMaps(dfaStatesWithRecursionProblems,
stateToRecursionOverflowConfigurationsMap,
altToTargetToCallSitesMap, // output param
altToDFAState);            // output param

// walk each alt with recursion overflow problems and generate error
-		Set alts = altToTargetToCallSitesMap.keySet();
-		List sortedAlts = new ArrayList(alts);
+		Set<Integer> alts = altToTargetToCallSitesMap.keySet();
+		List<Integer> sortedAlts = new ArrayList<Integer>(alts);
Collections.sort(sortedAlts);
-		for (Iterator altsIt = sortedAlts.iterator(); altsIt.hasNext();) {
+		for (Iterator<Integer> altsIt = sortedAlts.iterator(); altsIt.hasNext();) {
Integer altI = (Integer) altsIt.next();
-			Map targetToCallSiteMap =
-				(Map)altToTargetToCallSitesMap.get(altI);
-			Set targetRules = targetToCallSiteMap.keySet();
-			Collection callSiteStates = targetToCallSiteMap.values();
+			Map<String, Set<NFAState>> targetToCallSiteMap =
+				altToTargetToCallSitesMap.get(altI);
+			Set<String> targetRules = targetToCallSiteMap.keySet();
+			Collection<Set<NFAState>> callSiteStates = targetToCallSiteMap.values();
DFAState sampleBadState = (DFAState)altToDFAState.get(altI);
ErrorManager.recursionOverflow(this,
sampleBadState,
@@ -562,15 +563,15 @@ public class DecisionProbe {
}
}

-	private void computeAltToProblemMaps(Set dfaStatesUnaliased,
-										 Map configurationsMap,
-										 Map altToTargetToCallSitesMap,
-										 Map altToDFAState)
+	private void computeAltToProblemMaps(Set<Integer> dfaStatesUnaliased,
+										 Map<Integer, List<NFAConfiguration>> configurationsMap,
+										 Map<Integer, Map<String, Set<NFAState>>> altToTargetToCallSitesMap,
+										 Map<Integer, DFAState> altToDFAState)
{
-		for (Iterator it = dfaStatesUnaliased.iterator(); it.hasNext();) {
+		for (Iterator<Integer> it = dfaStatesUnaliased.iterator(); it.hasNext();) {
Integer stateI = (Integer) it.next();
// walk this DFA's config list
-			List configs = (List)configurationsMap.get(stateI);
+			List<? extends NFAConfiguration> configs = configurationsMap.get(stateI);
for (int i = 0; i < configs.size(); i++) {
NFAConfiguration c = (NFAConfiguration) configs.get(i);
NFAState ruleInvocationState = dfa.nfa.getState(c.state);
@@ -578,16 +579,16 @@ public class DecisionProbe {
RuleClosureTransition ref = (RuleClosureTransition)transition0;
String targetRule = ((NFAState) ref.target).enclosingRule.name;
Integer altI = Utils.integer(c.alt);
-				Map targetToCallSiteMap =
-					(Map)altToTargetToCallSitesMap.get(altI);
+				Map<String, Set<NFAState>> targetToCallSiteMap =
+					altToTargetToCallSitesMap.get(altI);
if ( targetToCallSiteMap==null ) {
-					targetToCallSiteMap = new HashMap();
+					targetToCallSiteMap = new HashMap<String, Set<NFAState>>();
altToTargetToCallSitesMap.put(altI, targetToCallSiteMap);
}
-				Set callSites =
-					(HashSet)targetToCallSiteMap.get(targetRule);
+				Set<NFAState> callSites =
+					targetToCallSiteMap.get(targetRule);
if ( callSites==null ) {
-					callSites = new HashSet();
+					callSites = new HashSet<NFAState>();
targetToCallSiteMap.put(targetRule, callSites);
}
callSites.add(ruleInvocationState);
@@ -600,9 +601,9 @@ public class DecisionProbe {
}
}

-	private Set getUnaliasedDFAStateSet(Set dfaStatesWithRecursionProblems) {
-		Set dfaStatesUnaliased = new HashSet();
-		for (Iterator it = dfaStatesWithRecursionProblems.iterator(); it.hasNext();) {
+	private Set<Integer> getUnaliasedDFAStateSet(Set<Integer> dfaStatesWithRecursionProblems) {
+		Set<Integer> dfaStatesUnaliased = new HashSet<Integer>();
+		for (Iterator<Integer> it = dfaStatesWithRecursionProblems.iterator(); it.hasNext();) {
Integer stateI = (Integer) it.next();
DFAState d = dfa.getState(stateI.intValue());
dfaStatesUnaliased.add(Utils.integer(d.stateNumber));
@@ -689,8 +690,8 @@ public class DecisionProbe {
*  tryToResolveWithSemanticPredicates() while flagging NFA configurations
*  in d as resolved.
*/
-	public void reportAltPredicateContext(DFAState d, Map altPredicateContext) {
-		Map copy = new HashMap();
+	public void reportAltPredicateContext(DFAState d, Map<Integer, ? extends SemanticContext> altPredicateContext) {
+		Map<Integer, SemanticContext> copy = new HashMap<Integer, SemanticContext>();
copy.putAll(altPredicateContext);
stateToAltSetWithSemanticPredicatesMap.put(d,copy);
}
@@ -709,7 +710,7 @@ public class DecisionProbe {
*/
protected boolean reachesState(DFAState startState,
DFAState targetState,
-								   Set states) {
+								   Set<DFAState> states) {
if ( startState==targetState ) {
states.add(targetState);
//System.out.println("found target DFA state "+targetState.getStateNumber());
@@ -750,9 +751,9 @@ public class DecisionProbe {
return false; // no path to targetState found.
}

-	protected Set getDFAPathStatesToTarget(DFAState targetState) {
-		Set dfaStates = new HashSet();
-		stateReachable = new HashMap();
+	protected Set<DFAState> getDFAPathStatesToTarget(DFAState targetState) {
+		Set<DFAState> dfaStates = new HashSet<DFAState>();
+		stateReachable = new HashMap<Integer, Integer>();
if ( dfa==null || dfa.startState==null ) {
return dfaStates;
}
@@ -771,7 +772,7 @@ public class DecisionProbe {
*/
protected void getSampleInputSequenceUsingStateSet(State startState,
State targetState,
-													   Set states,
+													   Set<DFAState> states,
List<Label> labels)
{
statesVisitedDuringSampleSequence.add(startState.stateNumber);
@@ -810,8 +811,8 @@ public class DecisionProbe {
*/
protected boolean getNFAPath(NFAState s,     // starting where?
int labelIndex, // 0..labels.size()-1
-								 List labels,    // input sequence
-								 List path)      // output list of NFA states
+								 List<? extends Label> labels,    // input sequence
+								 List<? super NFAState> path)      // output list of NFA states
{
// track a visit to state s at input index labelIndex if not seen
String thisStateKey = getStateLabelIndexKey(s.stateNumber,labelIndex);
diff --git a/tool/src/main/java/org/antlr/analysis/LL1DFA.java b/tool/src/main/java/org/antlr/analysis/LL1DFA.java
index aeea5ea..bf9f9f1 100644
--- a/tool/src/main/java/org/antlr/analysis/LL1DFA.java
+++ b/tool/src/main/java/org/antlr/analysis/LL1DFA.java
@@ -83,7 +83,7 @@ public class LL1DFA extends DFA {
this.decisionNFAStartState = decisionStartState;
initAltRelatedInfo();
unreachableAlts = null;
-		for (Iterator it = edgeMap.keySet().iterator(); it.hasNext();) {
+		for (Iterator<IntervalSet> it = edgeMap.keySet().iterator(); it.hasNext();) {
IntervalSet edge = (IntervalSet)it.next();
List<Integer> alts = edgeMap.get(edge);
Collections.sort(alts); // make sure alts are attempted in order
diff --git a/tool/src/main/java/org/antlr/analysis/Label.java b/tool/src/main/java/org/antlr/analysis/Label.java
index 93d549f..fcfe108 100644
--- a/tool/src/main/java/org/antlr/analysis/Label.java
+++ b/tool/src/main/java/org/antlr/analysis/Label.java
@@ -37,7 +37,7 @@ import org.antlr.tool.Grammar;
*  (which assumes an epsilon transition) or a tree of predicates (in a DFA).
*  Special label types have to be < 0 to avoid conflict with char.
*/
-public class Label implements Comparable, Cloneable {
+public class Label implements Comparable<Label>, Cloneable {
public static final int INVALID = -7;

public static final int ACTION = -6;
@@ -294,7 +294,7 @@ public class Label implements Comparable, Cloneable {
}

@Override
-    public int compareTo(Object o) {
+    public int compareTo(Label o) {
return this.label-((Label)o).label;
}

diff --git a/tool/src/main/java/org/antlr/analysis/NFAToDFAConverter.java b/tool/src/main/java/org/antlr/analysis/NFAToDFAConverter.java
index 8851671..6c2c6f7 100644
--- a/tool/src/main/java/org/antlr/analysis/NFAToDFAConverter.java
+++ b/tool/src/main/java/org/antlr/analysis/NFAToDFAConverter.java
@@ -40,7 +40,7 @@ import java.util.*;
*/
public class NFAToDFAConverter {
/** A list of DFA states we still need to process during NFA conversion */
-	protected List work = new LinkedList();
+	protected List<DFAState> work = new LinkedList<DFAState>();

/** While converting NFA, we must track states that
*  reference other rule's NFAs so we know what to do
@@ -200,7 +200,7 @@ public class NFAToDFAConverter {
*/
protected void findNewDFAStatesAndAddDFATransitions(DFAState d) {
//System.out.println("work on DFA state "+d);
-		OrderedHashSet labels = d.getReachableLabels();
+		OrderedHashSet<Label> labels = d.getReachableLabels();
//System.out.println("reachable labels="+labels);

/*
@@ -264,7 +264,7 @@ public class NFAToDFAConverter {
*/

int numberOfEdgesEmanating = 0;
-		Map targetToLabelMap = new HashMap();
+		Map<Integer, Transition> targetToLabelMap = new HashMap<Integer, Transition>();
// for each label that could possibly emanate from NFAStates of d
int numLabels = 0;
if ( labels!=null ) {
@@ -408,7 +408,7 @@ public class NFAToDFAConverter {
protected static int addTransition(DFAState d,
Label label,
DFAState targetState,
-									   Map targetToLabelMap)
+									   Map<Integer, Transition> targetToLabelMap)
{
//System.out.println(d.stateNumber+"-"+label.toString(dfa.nfa.grammar)+"->"+targetState.stateNumber);
int n = 0;
@@ -1170,7 +1170,7 @@ public class NFAToDFAConverter {
System.out.println("resolveNonDeterminisms "+d.toString());
}
boolean conflictingLexerRules = false;
-		Set nondeterministicAlts = d.getNonDeterministicAlts();
+		Set<Integer> nondeterministicAlts = d.getNonDeterministicAlts();
if ( debug && nondeterministicAlts!=null ) {
System.out.println("nondet alts="+nondeterministicAlts);
}
@@ -1187,7 +1187,7 @@ public class NFAToDFAConverter {
// indicate that d is nondeterministic on all alts otherwise
// it looks like state has no problem
if ( anyState.isEOTTargetState() ) {
-			Set allAlts = d.getAltSet();
+			Set<Integer> allAlts = d.getAltSet();
// is more than 1 alt predicted?
if ( allAlts!=null && allAlts.size()>1 ) {
nondeterministicAlts = allAlts;
@@ -1233,7 +1233,7 @@ public class NFAToDFAConverter {
//System.out.println("state "+d.stateNumber+" resolved to alt "+winningAlt);
}

-	protected int resolveByChoosingFirstAlt(DFAState d, Set nondeterministicAlts) {
+	protected int resolveByChoosingFirstAlt(DFAState d, Set<Integer> nondeterministicAlts) {
int winningAlt;
if ( dfa.isGreedy() ) {
winningAlt = resolveByPickingMinAlt(d,nondeterministicAlts);
@@ -1270,7 +1270,7 @@ public class NFAToDFAConverter {
*
*  Return the min alt found.
*/
-	protected int resolveByPickingMinAlt(DFAState d, Set nondeterministicAlts) {
+	protected int resolveByPickingMinAlt(DFAState d, Set<Integer> nondeterministicAlts) {
int min;
if ( nondeterministicAlts!=null ) {
min = getMinAlt(nondeterministicAlts);
@@ -1287,7 +1287,7 @@ public class NFAToDFAConverter {
/** Resolve state d by choosing exit alt, which is same value as the
*  number of alternatives.  Return that exit alt.
*/
-	protected int resolveByPickingExitAlt(DFAState d, Set nondeterministicAlts) {
+	protected int resolveByPickingExitAlt(DFAState d, Set<Integer> nondeterministicAlts) {
int exitAlt = dfa.getNumberOfAlts();
turnOffOtherAlts(d, exitAlt, nondeterministicAlts);
return exitAlt;
@@ -1350,7 +1350,7 @@ public class NFAToDFAConverter {
*  This is done down in getPredicatesPerNonDeterministicAlt().
*/
protected boolean tryToResolveWithSemanticPredicates(DFAState d,
-														 Set nondeterministicAlts)
+														 Set<Integer> nondeterministicAlts)
{
Map<Integer, SemanticContext> altToPredMap =
getPredicatesPerNonDeterministicAlt(d, nondeterministicAlts);
@@ -1484,7 +1484,7 @@ public class NFAToDFAConverter {
*  preds, so we really want this for the error message.
*/
protected Map<Integer, SemanticContext> getPredicatesPerNonDeterministicAlt(DFAState d,
-																				Set nondeterministicAlts)
+																				Set<Integer> nondeterministicAlts)
{
// map alt to combined SemanticContext
Map<Integer, SemanticContext> altToPredicateContextMap =
@@ -1492,7 +1492,7 @@ public class NFAToDFAConverter {
// init the alt to predicate set map
Map<Integer, OrderedHashSet<SemanticContext>> altToSetOfContextsMap =
new HashMap<Integer, OrderedHashSet<SemanticContext>>();
-		for (Iterator it = nondeterministicAlts.iterator(); it.hasNext();) {
+		for (Iterator<Integer> it = nondeterministicAlts.iterator(); it.hasNext();) {
Integer altI = (Integer) it.next();
altToSetOfContextsMap.put(altI, new OrderedHashSet<SemanticContext>());
}
@@ -1558,7 +1558,7 @@ public class NFAToDFAConverter {
// with at least 1 predicate and at least one configuration w/o a
// predicate. We want this in order to report to the decision probe.
List<Integer> incompletelyCoveredAlts = new ArrayList<Integer>();
-		for (Iterator it = nondeterministicAlts.iterator(); it.hasNext();) {
+		for (Iterator<Integer> it = nondeterministicAlts.iterator(); it.hasNext();) {
Integer altI = (Integer) it.next();
Set<SemanticContext> contextsForThisAlt = altToSetOfContextsMap.get(altI);
if ( nondetAltsWithUncoveredConfiguration.contains(altI) ) { // >= 1 config has no ctx
@@ -1568,7 +1568,7 @@ public class NFAToDFAConverter {
continue; // don't include at least 1 config has no ctx
}
SemanticContext combinedContext = null;
-			for (Iterator itrSet = contextsForThisAlt.iterator(); itrSet.hasNext();) {
+			for (Iterator<SemanticContext> itrSet = contextsForThisAlt.iterator(); itrSet.hasNext();) {
SemanticContext ctx = (SemanticContext) itrSet.next();
combinedContext =
SemanticContext.or(combinedContext,ctx);
@@ -1630,8 +1630,8 @@ public class NFAToDFAConverter {
/** OR together all predicates from the alts.  Note that the predicate
*  for an alt could itself be a combination of predicates.
*/
-	protected static SemanticContext getUnionOfPredicates(Map altToPredMap) {
-		Iterator iter;
+	protected static SemanticContext getUnionOfPredicates(Map<?, SemanticContext> altToPredMap) {
+		Iterator<SemanticContext> iter;
SemanticContext unionOfPredicatesFromAllAlts = null;
iter = altToPredMap.values().iterator();
while ( iter.hasNext() ) {
@@ -1657,7 +1657,7 @@ public class NFAToDFAConverter {
*  over alt i+1 if both predicates are true.
*/
protected void addPredicateTransitions(DFAState d) {
-		List configsWithPreds = new ArrayList();
+		List<NFAConfiguration> configsWithPreds = new ArrayList<NFAConfiguration>();
// get a list of all configs with predicates
int numConfigs = d.nfaConfigurations.size();
for (int i = 0; i < numConfigs; i++) {
@@ -1668,17 +1668,15 @@ public class NFAToDFAConverter {
}
// Sort ascending according to alt; alt i has higher precedence than i+1
Collections.sort(configsWithPreds,
-			 new Comparator() {
+			 new Comparator<NFAConfiguration>() {
@Override
-				 public int compare(Object a, Object b) {
-					 NFAConfiguration ca = (NFAConfiguration)a;
-					 NFAConfiguration cb = (NFAConfiguration)b;
-					 if ( ca.alt < cb.alt ) return -1;
-					 else if ( ca.alt > cb.alt ) return 1;
+				 public int compare(NFAConfiguration a, NFAConfiguration b) {
+					 if ( a.alt < b.alt ) return -1;
+					 else if ( a.alt > b.alt ) return 1;
return 0;
}
});
-		List predConfigsSortedByAlt = configsWithPreds;
+		List<NFAConfiguration> predConfigsSortedByAlt = configsWithPreds;
// Now, we can add edges emanating from d for these preds in right order
for (int i = 0; i < predConfigsSortedByAlt.size(); i++) {
NFAConfiguration c = (NFAConfiguration)predConfigsSortedByAlt.get(i);
@@ -1718,13 +1716,13 @@ public class NFAToDFAConverter {
}
}

-	public static int max(Set s) {
+	public static int max(Set<Integer> s) {
if ( s==null ) {
return Integer.MIN_VALUE;
}
int i = 0;
int m = 0;
-		for (Iterator it = s.iterator(); it.hasNext();) {
+		for (Iterator<Integer> it = s.iterator(); it.hasNext();) {
i++;
Integer I = (Integer) it.next();
if ( i==1 ) { // init m with first value
diff --git a/tool/src/main/java/org/antlr/analysis/Transition.java b/tool/src/main/java/org/antlr/analysis/Transition.java
index 86a29c1..7438a81 100644
--- a/tool/src/main/java/org/antlr/analysis/Transition.java
+++ b/tool/src/main/java/org/antlr/analysis/Transition.java
@@ -34,7 +34,7 @@ package org.antlr.analysis;
*  transitions) and has a label/target pair.  I have abstracted the notion
*  of a Label to handle the various kinds of things it can be.
*/
-public class Transition implements Comparable {
+public class Transition implements Comparable<Transition> {
/** What label must be consumed to transition to target */
public Label label;

@@ -76,8 +76,7 @@ public class Transition implements Comparable {
}

@Override
-    public int compareTo(Object o) {
-        Transition other = (Transition)o;
+    public int compareTo(Transition other) {
return this.label.compareTo(other.label);
}

diff --git a/tool/src/main/java/org/antlr/codegen/ACyclicDFACodeGenerator.java b/tool/src/main/java/org/antlr/codegen/ACyclicDFACodeGenerator.java
index 6bc5fd3..686f397 100644
--- a/tool/src/main/java/org/antlr/codegen/ACyclicDFACodeGenerator.java
+++ b/tool/src/main/java/org/antlr/codegen/ACyclicDFACodeGenerator.java
@@ -27,6 +27,7 @@
*/
package org.antlr.codegen;

+import java.util.ArrayList;
import org.antlr.analysis.*;
import org.antlr.misc.Utils;
import org.stringtemplate.v4.ST;
@@ -113,14 +114,15 @@ public class ACyclicDFACodeGenerator {
ST edgeST = templates.getInstanceOf(dfaEdgeName);
// If the template wants all the label values delineated, do that
if ( edgeST.impl.formalArguments.get("labels")!=null ) {
-				List labels = edge.label.getSet().toList();
+				List<Integer> labels = edge.label.getSet().toList();
+				List<String> targetLabels = new ArrayList<String>(labels.size());
for (int j = 0; j < labels.size(); j++) {
Integer vI = (Integer) labels.get(j);
String label =
parentGenerator.getTokenTypeAsTargetLabel(vI.intValue());
-					labels.set(j, label); // rewrite List element to be name
+					targetLabels.add(label); // rewrite List element to be name
}
-				edgeST.add("labels", labels);
+				edgeST.add("labels", targetLabels);
}
else { // else create an expression to evaluate (the general case)
edgeST.add("labelExpr",
diff --git a/tool/src/main/java/org/antlr/codegen/CTarget.java b/tool/src/main/java/org/antlr/codegen/CTarget.java
index 303c7f9..01ad46c 100644
--- a/tool/src/main/java/org/antlr/codegen/CTarget.java
+++ b/tool/src/main/java/org/antlr/codegen/CTarget.java
@@ -33,10 +33,11 @@ import org.antlr.tool.Grammar;

import java.io.IOException;
import java.util.ArrayList;
+import java.util.List;

public class CTarget extends Target {

-    ArrayList strings = new ArrayList();
+    List<String> strings = new ArrayList<String>();

@Override
protected void genRecognizerFile(Tool tool,
diff --git a/tool/src/main/java/org/antlr/codegen/CodeGenerator.java b/tool/src/main/java/org/antlr/codegen/CodeGenerator.java
index 695b72c..e4a19a2 100644
--- a/tool/src/main/java/org/antlr/codegen/CodeGenerator.java
+++ b/tool/src/main/java/org/antlr/codegen/CodeGenerator.java
@@ -440,7 +440,7 @@ public class CodeGenerator {
}

// Now that we know what synpreds are used, we can set into template
-		Set synpredNames = null;
+		Set<String> synpredNames = null;
if ( grammar.synPredNamesUsedInDFA.size()>0 ) {
synpredNames = grammar.synPredNamesUsedInDFA;
}
@@ -486,13 +486,13 @@ public class CodeGenerator {
*  '@headerfile:name {action}' or something.  Make sure the
*  target likes the scopes in action table.
*/
-	protected void verifyActionScopesOkForTarget(Map actions) {
-		Set actionScopeKeySet = actions.keySet();
-		for (Iterator it = actionScopeKeySet.iterator(); it.hasNext();) {
+	protected void verifyActionScopesOkForTarget(Map<String, Map<String, Object>> actions) {
+		Set<String> actionScopeKeySet = actions.keySet();
+		for (Iterator<String> it = actionScopeKeySet.iterator(); it.hasNext();) {
String scope = (String)it.next();
if ( !target.isValidActionScope(grammar.type, scope) ) {
// get any action from the scope to get error location
-				Map scopeActions = (Map)actions.get(scope);
+				Map<String, Object> scopeActions = actions.get(scope);
GrammarAST actionAST =
(GrammarAST)scopeActions.values().iterator().next();
ErrorManager.grammarError(
@@ -506,11 +506,11 @@ public class CodeGenerator {
/** Actions may reference $x::y attributes, call translateAction on
*  each action and replace that action in the Map.
*/
-	protected void translateActionAttributeReferences(Map actions) {
-		Set actionScopeKeySet = actions.keySet();
-		for (Iterator it = actionScopeKeySet.iterator(); it.hasNext();) {
+	protected void translateActionAttributeReferences(Map<String, Map<String, Object>> actions) {
+		Set<String> actionScopeKeySet = actions.keySet();
+		for (Iterator<String> it = actionScopeKeySet.iterator(); it.hasNext();) {
String scope = (String)it.next();
-			Map scopeActions = (Map)actions.get(scope);
+			Map<String, Object> scopeActions = actions.get(scope);
translateActionAttributeReferencesForSingleScope(null,scopeActions);
}
}
@@ -518,17 +518,17 @@ public class CodeGenerator {
/** Use for translating rule @init{...} actions that have no scope */
public void translateActionAttributeReferencesForSingleScope(
Rule r,
-		Map scopeActions)
+		Map<String, Object> scopeActions)
{
String ruleName=null;
if ( r!=null ) {
ruleName = r.name;
}
-		Set actionNameSet = scopeActions.keySet();
-		for (Iterator nameIT = actionNameSet.iterator(); nameIT.hasNext();) {
+		Set<String> actionNameSet = scopeActions.keySet();
+		for (Iterator<String> nameIT = actionNameSet.iterator(); nameIT.hasNext();) {
String name = (String) nameIT.next();
GrammarAST actionAST = (GrammarAST)scopeActions.get(name);
-			List chunks = translateAction(ruleName,actionAST);
+			List<?> chunks = translateAction(ruleName,actionAST);
scopeActions.put(name, chunks); // replace with translation
}
}
@@ -582,11 +582,11 @@ public class CodeGenerator {
}
//System.out.println(" "+follow);

-        List tokenTypeList;
+        List<Integer> tokenTypeList;
long[] words;
if ( follow.tokenTypeSet==null ) {
words = new long[1];
-            tokenTypeList = new ArrayList();
+            tokenTypeList = new ArrayList<Integer>();
}
else {
BitSet bits = BitSet.of(follow.tokenTypeSet);
@@ -772,7 +772,7 @@ public class CodeGenerator {
testRangeSTName = "isolatedLookaheadRangeTest";
}
ST setST = templates.getInstanceOf("setTest");
-		Iterator iter = iset.getIntervals().iterator();
+		Iterator<Interval> iter = iset.getIntervals().iterator();
int rangeNumber = 1;
while (iter.hasNext()) {
Interval I = (Interval) iter.next();
@@ -808,7 +808,7 @@ public class CodeGenerator {
*/
protected void genTokenTypeConstants(ST code) {
// make constants for the token types
-		Iterator tokenIDs = grammar.getTokenIDs().iterator();
+		Iterator<String> tokenIDs = grammar.getTokenIDs().iterator();
while (tokenIDs.hasNext()) {
String tokenID = (String) tokenIDs.next();
int tokenType = grammar.getTokenType(tokenID);
@@ -865,7 +865,7 @@ public class CodeGenerator {
vocabFileST.add("tokens",(Object)null);
vocabFileST.impl.name = "vocab-file";
// make constants for the token names
-		Iterator tokenIDs = grammar.getTokenIDs().iterator();
+		Iterator<String> tokenIDs = grammar.getTokenIDs().iterator();
while (tokenIDs.hasNext()) {
String tokenID = (String) tokenIDs.next();
int tokenType = grammar.getTokenType(tokenID);
@@ -875,7 +875,7 @@ public class CodeGenerator {
}

// now dump the strings
-		Iterator literals = grammar.getStringLiterals().iterator();
+		Iterator<String> literals = grammar.getStringLiterals().iterator();
while (literals.hasNext()) {
String literal = (String) literals.next();
int tokenType = grammar.getTokenType(literal);
@@ -887,14 +887,14 @@ public class CodeGenerator {
return vocabFileST;
}

-	public List translateAction(String ruleName,
+	public List<? extends Object> translateAction(String ruleName,
GrammarAST actionTree)
{
if ( actionTree.getType()==ANTLRParser.ARG_ACTION ) {
return translateArgAction(ruleName, actionTree);
}
ActionTranslator translator = new ActionTranslator(this,ruleName,actionTree);
-		List chunks = translator.translateToChunks();
+		List<Object> chunks = translator.translateToChunks();
chunks = target.postProcessAction(chunks, actionTree.token);
return chunks;
}
@@ -918,7 +918,7 @@ public class CodeGenerator {
new ActionTranslator(this,ruleName,
actionToken,
actionTree.outerAltNum);
-				List chunks = translator.translateToChunks();
+				List<Object> chunks = translator.translateToChunks();
chunks = target.postProcessAction(chunks, actionToken);
ST catST = new ST(templates, "<chunks>");
catST.add("chunks", chunks);
diff --git a/tool/src/main/java/org/antlr/codegen/JavaTarget.java b/tool/src/main/java/org/antlr/codegen/JavaTarget.java
index fdc4068..a73f27c 100644
--- a/tool/src/main/java/org/antlr/codegen/JavaTarget.java
+++ b/tool/src/main/java/org/antlr/codegen/JavaTarget.java
@@ -55,7 +55,7 @@ public class JavaTarget extends Target {
for (Rule rule : grammar.getRules()) {
rule.throwsSpec.add("RecognitionException");
}
-		Set<Rule> delegatedRules = grammar.getDelegatedRules();
+		Set<? extends Rule> delegatedRules = grammar.getDelegatedRules();
if ( delegatedRules!=null ) {
for (Rule rule : delegatedRules) {
rule.throwsSpec.add("RecognitionException");
diff --git a/tool/src/main/java/org/antlr/codegen/PythonTarget.java b/tool/src/main/java/org/antlr/codegen/PythonTarget.java
index 259f3a7..bb9f698 100644
--- a/tool/src/main/java/org/antlr/codegen/PythonTarget.java
+++ b/tool/src/main/java/org/antlr/codegen/PythonTarget.java
@@ -70,8 +70,8 @@ public class PythonTarget extends Target {
return String.valueOf(c);
}

-    private List splitLines(String text) {
-		ArrayList l = new ArrayList();
+    private List<String> splitLines(String text) {
+		ArrayList<String> l = new ArrayList<String>();
int idx = 0;

while ( true ) {
@@ -90,7 +90,7 @@ public class PythonTarget extends Target {
}

@Override
-    public List postProcessAction(List chunks, Token actionToken) {
+    public List<Object> postProcessAction(List<Object> chunks, Token actionToken) {
/* TODO
- check for and report TAB usage
*/
@@ -105,7 +105,7 @@ public class PythonTarget extends Target {
- where every LF is at the end of a string chunk
*/

-		List nChunks = new ArrayList();
+		List<Object> nChunks = new ArrayList<Object>();
for (int i = 0; i < chunks.size(); i++) {
Object chunk = chunks.get(i);

@@ -122,11 +122,7 @@ public class PythonTarget extends Target {
text = ws + text;
}

-				List parts = splitLines(text);
-				for ( int j = 0 ; j < parts.size() ; j++ ) {
-					chunk = parts.get(j);
-					nChunks.add(chunk);
-				}
+				nChunks.addAll(splitLines(text));
}
else {
if ( nChunks.isEmpty() && actionToken.getCharPositionInLine() >= 0 ) {
diff --git a/tool/src/main/java/org/antlr/codegen/RubyTarget.java b/tool/src/main/java/org/antlr/codegen/RubyTarget.java
index 0b63160..763e49f 100644
--- a/tool/src/main/java/org/antlr/codegen/RubyTarget.java
+++ b/tool/src/main/java/org/antlr/codegen/RubyTarget.java
@@ -42,8 +42,8 @@ public class RubyTarget extends Target
/** A set of ruby keywords which are used to escape labels and method names
*  which will cause parse errors in the ruby source
*/
-    public static final Set rubyKeywords =
-    new HashSet() {
+    public static final Set<String> rubyKeywords =
+    new HashSet<String>() {
{
add( "alias" );     add( "END" );     add( "retry" );
add( "and" );       add( "ensure" );  add( "return" );
diff --git a/tool/src/main/java/org/antlr/codegen/Target.java b/tool/src/main/java/org/antlr/codegen/Target.java
index 682f376..3530375 100644
--- a/tool/src/main/java/org/antlr/codegen/Target.java
+++ b/tool/src/main/java/org/antlr/codegen/Target.java
@@ -357,7 +357,7 @@ public class Target {
/** Give target a chance to do some postprocessing on actions.
*  Python for example will have to fix the indention.
*/
-	public List postProcessAction(List chunks, Token actionToken) {
+	public List<Object> postProcessAction(List<Object> chunks, Token actionToken) {
return chunks;
}

diff --git a/tool/src/main/java/org/antlr/misc/BitSet.java b/tool/src/main/java/org/antlr/misc/BitSet.java
index b3636a2..90ccfc3 100644
--- a/tool/src/main/java/org/antlr/misc/BitSet.java
+++ b/tool/src/main/java/org/antlr/misc/BitSet.java
@@ -102,7 +102,7 @@ public class BitSet implements IntSet, Cloneable {
else if ( set instanceof IntervalSet ) {
IntervalSet other = (IntervalSet)set;
// walk set and add each interval
-			for (Iterator iter = other.intervals.iterator(); iter.hasNext();) {
+			for (Iterator<Interval> iter = other.intervals.iterator(); iter.hasNext();) {
Interval I = (Interval) iter.next();
this.orInPlace(BitSet.range(I.a,I.b));
}
@@ -124,11 +124,11 @@ public class BitSet implements IntSet, Cloneable {
}
}

-	public void addAll(Iterable elements) {
+	public void addAll(Iterable<Integer> elements) {
if ( elements==null ) {
return;
}
-		Iterator it = elements.iterator();
+		Iterator<Integer> it = elements.iterator();
while (it.hasNext()) {
Object o = (Object) it.next();
if ( !(o instanceof Integer) ) {
@@ -338,9 +338,9 @@ public class BitSet implements IntSet, Cloneable {
return s;
}

-    public static BitSet of(Collection elements) {
+    public static BitSet of(Collection<? extends Integer> elements) {
BitSet s = new BitSet();
-        Iterator iter = elements.iterator();
+        Iterator<? extends Integer> iter = elements.iterator();
while (iter.hasNext()) {
Integer el = (Integer) iter.next();
s.add(el.intValue());
@@ -364,7 +364,7 @@ public class BitSet implements IntSet, Cloneable {
throw new IllegalArgumentException("can't create BitSet from "+set.getClass().getName());
}

-    public static BitSet of(Map elements) {
+    public static BitSet of(Map<? extends Integer, ?> elements) {
return BitSet.of(elements.keySet());
}

@@ -461,7 +461,7 @@ public class BitSet implements IntSet, Cloneable {
}

@Override
-	public List toList() {
+	public List<Integer> toList() {
throw new NoSuchMethodError("BitSet.toList() unimplemented");
}

@@ -520,7 +520,7 @@ public class BitSet implements IntSet, Cloneable {
* separator The string to put in between elements
* @return A commma-separated list of character constants.
*/
-    public String toString(String separator, List vocabulary) {
+    public String toString(String separator, List<String> vocabulary) {
if (vocabulary == null) {
return toString(null);
}
diff --git a/tool/src/main/java/org/antlr/misc/Graph.java b/tool/src/main/java/org/antlr/misc/Graph.java
index cd821d1..9b59ba8 100644
--- a/tool/src/main/java/org/antlr/misc/Graph.java
+++ b/tool/src/main/java/org/antlr/misc/Graph.java
@@ -33,16 +33,16 @@ import java.util.*;
*  This is only used to topologically sort a list of file dependencies
*  at the moment.
*/
-public class Graph {
+public class Graph<T> {

-    public static class Node {
-        Object payload;
-        List<Node> edges; // points at which nodes?
+    public static class Node<T> {
+        T payload;
+        List<Node<T>> edges; // points at which nodes?

-        public Node(Object payload) { this.payload = payload; }
+        public Node(T payload) { this.payload = payload; }

-        public void addEdge(Node n) {
-            if ( edges==null ) edges = new ArrayList<Node>();
+        public void addEdge(Node<T> n) {
+            if ( edges==null ) edges = new ArrayList<Node<T>>();
if ( !edges.contains(n) ) edges.add(n);
}

@@ -51,19 +51,19 @@ public class Graph {
}

/** Map from node payload to node containing it */
-    protected Map<Object,Node> nodes = new HashMap<Object,Node>();
+    protected Map<T,Node<T>> nodes = new HashMap<T,Node<T>>();

-    public void addEdge(Object a, Object b) {
+    public void addEdge(T a, T b) {
//System.out.println("add edge "+a+" to "+b);
-        Node a_node = getNode(a);
-        Node b_node = getNode(b);
+        Node<T> a_node = getNode(a);
+        Node<T> b_node = getNode(b);
a_node.addEdge(b_node);
}

-    protected Node getNode(Object a) {
-        Node existing = nodes.get(a);
+    protected Node<T> getNode(T a) {
+        Node<T> existing = nodes.get(a);
if ( existing!=null ) return existing;
-        Node n = new Node(a);
+        Node<T> n = new Node<T>(a);
nodes.put(a, n);
return n;
}
@@ -79,14 +79,14 @@ public class Graph {
*  So if this gives nonreversed postorder traversal, I get the order
*  I want.
*/
-    public List<Object> sort() {
-        Set<Node> visited = new OrderedHashSet<Node>();
-        ArrayList<Object> sorted = new ArrayList<Object>();
+    public List<T> sort() {
+        Set<Node<T>> visited = new OrderedHashSet<Node<T>>();
+        ArrayList<T> sorted = new ArrayList<T>();
while ( visited.size() < nodes.size() ) {
// pick any unvisited node, n
-            Node n = null;
-            for (Iterator it = nodes.values().iterator(); it.hasNext();) {
-                n = (Node)it.next();
+            Node<T> n = null;
+            for (Iterator<Node<T>> it = nodes.values().iterator(); it.hasNext();) {
+                n = (Node<T>)it.next();
if ( !visited.contains(n) ) break;
}
DFS(n, visited, sorted);
@@ -94,12 +94,12 @@ public class Graph {
return sorted;
}

-    public void DFS(Node n, Set<Node> visited, ArrayList<Object> sorted) {
+    public void DFS(Node<T> n, Set<Node<T>> visited, ArrayList<T> sorted) {
if ( visited.contains(n) ) return;
visited.add(n);
if ( n.edges!=null ) {
-            for (Iterator it = n.edges.iterator(); it.hasNext();) {
-                Node target = (Node) it.next();
+            for (Iterator<Node<T>> it = n.edges.iterator(); it.hasNext();) {
+                Node<T> target = (Node<T>) it.next();
DFS(target, visited, sorted);
}
}
diff --git a/tool/src/main/java/org/antlr/misc/IntArrayList.java b/tool/src/main/java/org/antlr/misc/IntArrayList.java
index 28e5d7d..7844ded 100644
--- a/tool/src/main/java/org/antlr/misc/IntArrayList.java
+++ b/tool/src/main/java/org/antlr/misc/IntArrayList.java
@@ -33,7 +33,7 @@ import java.util.AbstractList;
*  modifiable list as I don't do, for example, add(index,element).
*  TODO: unused?
*/
-public class IntArrayList extends AbstractList implements Cloneable {
+public class IntArrayList extends AbstractList<Integer> implements Cloneable {
private static final int DEFAULT_CAPACITY = 10;
protected int n = 0;
protected int[] elements = null;
@@ -96,7 +96,7 @@ public class IntArrayList extends AbstractList implements Cloneable {
}

@Override
-	public Object get(int i) {
+	public Integer get(int i) {
return Utils.integer(element(i));
}

diff --git a/tool/src/main/java/org/antlr/misc/IntSet.java b/tool/src/main/java/org/antlr/misc/IntSet.java
index 9858335..1551dd3 100644
--- a/tool/src/main/java/org/antlr/misc/IntSet.java
+++ b/tool/src/main/java/org/antlr/misc/IntSet.java
@@ -77,7 +77,7 @@ public interface IntSet {
/** remove this element from this set */
void remove(int el);

-    List toList();
+    List<Integer> toList();

@Override
String toString();
diff --git a/tool/src/main/java/org/antlr/misc/IntervalSet.java b/tool/src/main/java/org/antlr/misc/IntervalSet.java
index 3da43d7..c215b41 100644
--- a/tool/src/main/java/org/antlr/misc/IntervalSet.java
+++ b/tool/src/main/java/org/antlr/misc/IntervalSet.java
@@ -105,7 +105,7 @@ public class IntervalSet implements IntSet {
}
// find position in list
// Use iterators as we modify list in place
-		for (ListIterator iter = intervals.listIterator(); iter.hasNext();) {
+		for (ListIterator<Interval> iter = intervals.listIterator(); iter.hasNext();) {
Interval r = (Interval) iter.next();
if ( addition.equals(r) ) {
return;
@@ -215,7 +215,7 @@ public class IntervalSet implements IntSet {
*  'this' is assumed to be either a subset or equal to vocabulary.
*/
@Override
-    public IntSet complement(IntSet vocabulary) {
+    public IntervalSet complement(IntSet vocabulary) {
if ( vocabulary==null ) {
return null; // nothing in common with null set
}
@@ -261,7 +261,7 @@ public class IntervalSet implements IntSet {
*  anything that is in other but not in this will be ignored.
*/
@Override
-	public IntSet subtract(IntSet other) {
+	public IntervalSet subtract(IntSet other) {
// assume the whole unicode range here for the complement
// because it doesn't matter.  Anything beyond the max of this' set
// will be ignored since we are doing this & ~other.  The intersection
@@ -406,13 +406,13 @@ public class IntervalSet implements IntSet {
*  list lengths n and m.
*/
@Override
-	public IntSet and(IntSet other) {
+	public IntervalSet and(IntSet other) {
if ( other==null ) { //|| !(other instanceof IntervalSet) ) {
return null; // nothing in common with null set
}

-		ArrayList myIntervals = (ArrayList)this.intervals;
-		ArrayList theirIntervals = (ArrayList)((IntervalSet)other).intervals;
+		List<Interval> myIntervals = this.intervals;
+		List<Interval> theirIntervals = ((IntervalSet)other).intervals;
IntervalSet intersection = null;
int mySize = myIntervals.size();
int theirSize = theirIntervals.size();
@@ -580,7 +580,7 @@ public class IntervalSet implements IntSet {
if ( this.intervals.size()>1 ) {
buf.append("{");
}
-        Iterator iter = this.intervals.iterator();
+        Iterator<Interval> iter = this.intervals.iterator();
while (iter.hasNext()) {
Interval I = (Interval) iter.next();
int a = I.a;
@@ -627,8 +627,8 @@ public class IntervalSet implements IntSet {
}

@Override
-    public List toList() {
-		List values = new ArrayList();
+    public List<Integer> toList() {
+		List<Integer> values = new ArrayList<Integer>();
int n = intervals.size();
for (int i = 0; i < n; i++) {
Interval I = (Interval) intervals.get(i);
diff --git a/tool/src/main/java/org/antlr/misc/OrderedHashSet.java b/tool/src/main/java/org/antlr/misc/OrderedHashSet.java
index a66a25c..8f26b5d 100644
--- a/tool/src/main/java/org/antlr/misc/OrderedHashSet.java
+++ b/tool/src/main/java/org/antlr/misc/OrderedHashSet.java
@@ -37,7 +37,7 @@ import java.util.List;
*  I need the replace/set-element-i functionality so I'm subclassing
*  OrderedHashSet.
*/
-public class OrderedHashSet<T> extends LinkedHashSet {
+public class OrderedHashSet<T> extends LinkedHashSet<T> {
/** Track the elements as they are added to the set */
protected List<T> elements = new ArrayList<T>();

@@ -61,7 +61,7 @@ public class OrderedHashSet<T> extends LinkedHashSet {
*  a list of strings.
*/
@Override
-    public boolean add(Object value) {
+    public boolean add(T value) {
boolean result = super.add(value);
if ( result ) {  // only track if new element not in set
elements.add((T)value);
diff --git a/tool/src/main/java/org/antlr/tool/AssignTokenTypesBehavior.java b/tool/src/main/java/org/antlr/tool/AssignTokenTypesBehavior.java
index fba4f0e..7f4fbad 100644
--- a/tool/src/main/java/org/antlr/tool/AssignTokenTypesBehavior.java
+++ b/tool/src/main/java/org/antlr/tool/AssignTokenTypesBehavior.java
@@ -47,7 +47,7 @@ public class AssignTokenTypesBehavior extends AssignTokenTypesWalker {
/** Track actual lexer rule defs so we don't get repeated token defs in
*  generated lexer.
*/
-	protected Set<String> tokenRuleDefs = new HashSet();
+	protected Set<String> tokenRuleDefs = new HashSet<String>();

public AssignTokenTypesBehavior() {
super(null);
@@ -247,8 +247,8 @@ protected void defineStringLiteralsFromDelegates() {
@Override
protected void assignStringTypes(Grammar root) {
// walk string literals assigning types to unassigned ones
-		Set s = stringLiterals.keySet();
-		for (Iterator it = s.iterator(); it.hasNext();) {
+		Set<String> s = stringLiterals.keySet();
+		for (Iterator<String> it = s.iterator(); it.hasNext();) {
String lit = (String) it.next();
Integer oldTypeI = (Integer)stringLiterals.get(lit);
int oldType = oldTypeI.intValue();
@@ -269,8 +269,8 @@ protected void defineStringLiteralsFromDelegates() {
}
// walk aliases if any and assign types to aliased literals if literal
// was referenced
-		Set s = aliases.keySet();
-		for (Iterator it = s.iterator(); it.hasNext();) {
+		Set<String> s = aliases.keySet();
+		for (Iterator<String> it = s.iterator(); it.hasNext();) {
String tokenID = (String) it.next();
String literal = (String)aliases.get(tokenID);
if ( literal.charAt(0)=='\'' && stringLiterals.get(literal)!=null ) {
@@ -287,8 +287,8 @@ protected void defineStringLiteralsFromDelegates() {
@Override
protected void assignTokenIDTypes(Grammar root) {
// walk token names, assigning values if unassigned
-		Set s = tokens.keySet();
-		for (Iterator it = s.iterator(); it.hasNext();) {
+		Set<String> s = tokens.keySet();
+		for (Iterator<String> it = s.iterator(); it.hasNext();) {
String tokenID = (String) it.next();
if ( tokens.get(tokenID)==UNASSIGNED ) {
tokens.put(tokenID, Utils.integer(root.getNewTokenType()));
@@ -298,14 +298,14 @@ protected void defineStringLiteralsFromDelegates() {

@Override
protected void defineTokenNamesAndLiteralsInGrammar(Grammar root) {
-		Set s = tokens.keySet();
-		for (Iterator it = s.iterator(); it.hasNext();) {
+		Set<String> s = tokens.keySet();
+		for (Iterator<String> it = s.iterator(); it.hasNext();) {
String tokenID = (String) it.next();
int ttype = ((Integer)tokens.get(tokenID)).intValue();
root.defineToken(tokenID, ttype);
}
s = stringLiterals.keySet();
-		for (Iterator it = s.iterator(); it.hasNext();) {
+		for (Iterator<String> it = s.iterator(); it.hasNext();) {
String lit = (String) it.next();
int ttype = ((Integer)stringLiterals.get(lit)).intValue();
root.defineToken(lit, ttype);
diff --git a/tool/src/main/java/org/antlr/tool/AttributeScope.java b/tool/src/main/java/org/antlr/tool/AttributeScope.java
index 778d6d6..befae52 100644
--- a/tool/src/main/java/org/antlr/tool/AttributeScope.java
+++ b/tool/src/main/java/org/antlr/tool/AttributeScope.java
@@ -80,10 +80,10 @@ public class AttributeScope {
public boolean isPredefinedLexerRuleScope;

/** The list of Attribute objects */
-	protected LinkedHashMap<String,Attribute> attributes = new LinkedHashMap();
+	protected LinkedHashMap<String,Attribute> attributes = new LinkedHashMap<String, Attribute>();

/* Placeholder for compatibility with the CSharp3 target. */
-	public LinkedHashMap<String, GrammarAST> actions = new LinkedHashMap();
+	public LinkedHashMap<String, GrammarAST> actions = new LinkedHashMap<String, GrammarAST>();

public AttributeScope(String name, Token derivedFromToken) {
this(null,name,derivedFromToken);
@@ -169,13 +169,13 @@ public class AttributeScope {
/** Return the set of keys that collide from
*  this and other.
*/
-	public Set intersection(AttributeScope other) {
+	public Set<String> intersection(AttributeScope other) {
if ( other==null || other.size()==0 || size()==0 ) {
return null;
}
-		Set inter = new HashSet();
-		Set thisKeys = attributes.keySet();
-		for (Iterator it = thisKeys.iterator(); it.hasNext();) {
+		Set<String> inter = new HashSet<String>();
+		Set<String> thisKeys = attributes.keySet();
+		for (Iterator<String> it = thisKeys.iterator(); it.hasNext();) {
String key = (String) it.next();
if ( other.attributes.get(key)!=null ) {
inter.add(key);
diff --git a/tool/src/main/java/org/antlr/tool/CompositeGrammar.java b/tool/src/main/java/org/antlr/tool/CompositeGrammar.java
index b9ef82f..2b4371c 100644
--- a/tool/src/main/java/org/antlr/tool/CompositeGrammar.java
+++ b/tool/src/main/java/org/antlr/tool/CompositeGrammar.java
@@ -81,7 +81,7 @@ public class CompositeGrammar {
protected int maxTokenType = Label.MIN_TOKEN_TYPE-1;

/** Map token like ID (but not literals like "while") to its token type */
-	public Map tokenIDToTypeMap = new LinkedHashMap();
+	public Map<String, Integer> tokenIDToTypeMap = new LinkedHashMap<String, Integer>();

/** Map token literals like "while" to its token type.  It may be that
*  WHILE="while"=35, in which case both tokenIDToTypeMap and this
@@ -209,7 +209,7 @@ public class CompositeGrammar {
if ( children==null ) {
return null;
}
-		List<Grammar> grammars = new ArrayList();
+		List<Grammar> grammars = new ArrayList<Grammar>();
for (int i = 0; children!=null && i < children.size(); i++) {
CompositeGrammarTree child = (CompositeGrammarTree) children.get(i);
grammars.add(child.grammar);
@@ -232,7 +232,7 @@ public class CompositeGrammar {
if ( g==delegateGrammarTreeRoot.grammar ) {
return null;
}
-		List<Grammar> grammars = new ArrayList();
+		List<Grammar> grammars = new ArrayList<Grammar>();
CompositeGrammarTree t = delegateGrammarTreeRoot.findNode(g);
// walk backwards to root, collecting grammars
CompositeGrammarTree p = t.parent;
@@ -252,12 +252,12 @@ public class CompositeGrammar {
*  should not be instantiated directly for use as parsers (you can create
*  them to pass to the root parser's ctor as arguments).
*/
-	public Set<Rule> getDelegatedRules(Grammar g) {
+	public Set<? extends Rule> getDelegatedRules(Grammar g) {
if ( g!=delegateGrammarTreeRoot.grammar ) {
return null;
}
-		Set<Rule> rules = getAllImportedRules(g);
-		for (Iterator it = rules.iterator(); it.hasNext();) {
+		Set<? extends Rule> rules = getAllImportedRules(g);
+		for (Iterator<? extends Rule> it = rules.iterator(); it.hasNext();) {
Rule r = (Rule) it.next();
Rule localRule = g.getLocallyDefinedRule(r.name);
// if locally defined or it's not local but synpred, don't make
@@ -272,9 +272,9 @@ public class CompositeGrammar {
/** Get all rule definitions from all direct/indirect delegate grammars
*  of g.
*/
-	public Set<Rule> getAllImportedRules(Grammar g) {
-		Set<String> ruleNames = new HashSet();
-		Set<Rule> rules = new HashSet();
+	public Set<? extends Rule> getAllImportedRules(Grammar g) {
+		Set<String> ruleNames = new HashSet<String>();
+		Set<Rule> rules = new HashSet<Rule>();
CompositeGrammarTree subtreeRoot = delegateGrammarTreeRoot.findNode(g);

List<Grammar> grammars = subtreeRoot.getPreOrderedGrammarList();
@@ -283,7 +283,7 @@ public class CompositeGrammar {
Grammar delegate = (org.antlr.tool.Grammar) grammars.get(i);
// for each rule in delegate, add to rules if no rule with that
// name as been seen.  (can't use removeAll; wrong hashcode/equals on Rule)
-			for (Iterator it = delegate.getRules().iterator(); it.hasNext();) {
+			for (Iterator<Rule> it = delegate.getRules().iterator(); it.hasNext();) {
Rule r = (Rule)it.next();
if ( !ruleNames.contains(r.name) ) {
ruleNames.add(r.name); // track that we've seen this
diff --git a/tool/src/main/java/org/antlr/tool/DOTGenerator.java b/tool/src/main/java/org/antlr/tool/DOTGenerator.java
index 98f1113..e6bf17f 100644
--- a/tool/src/main/java/org/antlr/tool/DOTGenerator.java
+++ b/tool/src/main/java/org/antlr/tool/DOTGenerator.java
@@ -51,7 +51,7 @@ public class DOTGenerator {
*  which states we've visited.  Make a new set every time you start
*  walking in case you reuse this object.
*/
-    protected Set markedStates = null;
+    protected Set<Object> markedStates = null;

protected Grammar grammar;

@@ -70,7 +70,7 @@ public class DOTGenerator {
}
// The output DOT graph for visualization
ST dot;
-		markedStates = new HashSet();
+		markedStates = new HashSet<Object>();
if ( startState instanceof DFAState ) {
dot = stlib.getInstanceOf("dfa");
dot.add("startState",
@@ -323,11 +323,11 @@ public class DOTGenerator {
buf.append("abortedDueToRecursionOverflow");
}
}
-				Set alts = ((DFAState)s).getAltSet();
+				Set<Integer> alts = ((DFAState)s).getAltSet();
if ( alts!=null ) {
buf.append("\\n");
// separate alts
-					List altList = new ArrayList();
+					List<Integer> altList = new ArrayList<Integer>();
altList.addAll(alts);
Collections.sort(altList);
Set configurations = ((DFAState) s).nfaConfigurations;
@@ -342,8 +342,8 @@ public class DOTGenerator {
buf.append(':');
// get a list of configs for just this alt
// it will help us print better later
-						List configsInAlt = new ArrayList();
-						for (Iterator it = configurations.iterator(); it.hasNext();) {
+						List<NFAConfiguration> configsInAlt = new ArrayList<NFAConfiguration>();
+						for (Iterator<NFAConfiguration> it = configurations.iterator(); it.hasNext();) {
NFAConfiguration c = (NFAConfiguration) it.next();
if ( c.alt!=alt ) continue;
configsInAlt.add(c);
diff --git a/tool/src/main/java/org/antlr/tool/ErrorManager.java b/tool/src/main/java/org/antlr/tool/ErrorManager.java
index 1119fe8..e1d5989 100644
--- a/tool/src/main/java/org/antlr/tool/ErrorManager.java
+++ b/tool/src/main/java/org/antlr/tool/ErrorManager.java
@@ -30,6 +30,7 @@ package org.antlr.tool;
import org.antlr.Tool;
import org.antlr.analysis.DFAState;
import org.antlr.analysis.DecisionProbe;
+import org.antlr.analysis.NFAState;
import org.antlr.misc.BitSet;
import org.antlr.runtime.RecognitionException;
import org.antlr.runtime.Token;
@@ -242,9 +243,9 @@ public class ErrorManager {
*  Map<String,Set> where the key is a method name like danglingState.
*  The set is whatever that method accepts or derives like a DFA.
*/
-	public static final Map emitSingleError = new HashMap() {
+	public static final Map<String, Set<String>> emitSingleError = new HashMap<String, Set<String>>() {
{
-			put("danglingState", new HashSet());
+			put("danglingState", new HashSet<String>());
}
};

@@ -255,7 +256,7 @@ public class ErrorManager {
/** Each thread might need it's own error listener; e.g., a GUI with
*  multiple window frames holding multiple grammars.
*/
-	private static Map threadToListenerMap = new HashMap();
+	private static Map<Thread, ANTLRErrorListener> threadToListenerMap = new HashMap<Thread, ANTLRErrorListener>();

static class ErrorState {
public int errors;
@@ -273,13 +274,13 @@ public class ErrorManager {
/** Track the number of errors regardless of the listener but track
*  per thread.
*/
-	private static Map threadToErrorStateMap = new HashMap();
+	private static Map<Thread, ErrorState> threadToErrorStateMap = new HashMap<Thread, ErrorState>();

/** Each thread has its own ptr to a Tool object, which knows how
*  to panic, for example.  In a GUI, the thread might just throw an Error
*  to exit rather than the suicide System.exit.
*/
-	private static Map threadToToolMap = new HashMap();
+	private static Map<Thread, Tool> threadToToolMap = new HashMap<Thread, Tool>();

/** The group of templates that represent all possible ANTLR errors. */
private static STGroup messages;
@@ -578,7 +579,7 @@ public class ErrorManager {
}

public static void resetErrorState() {
-        threadToListenerMap = new HashMap();
+        threadToListenerMap = new HashMap<Thread, ANTLRErrorListener>();
ErrorState ec = new ErrorState();
threadToErrorStateMap.put(Thread.currentThread(), ec);
}
@@ -639,7 +640,7 @@ public class ErrorManager {
getErrorState().errors++;
Message msg = new GrammarDanglingStateMessage(probe,d);
getErrorState().errorMsgIDs.add(msg.msgID);
-		Set seen = (Set)emitSingleError.get("danglingState");
+		Set<String> seen = emitSingleError.get("danglingState");
if ( !seen.contains(d.dfa.decisionNumber+"|"+d.getAltSet()) ) {
getErrorListener().error(msg);
// we've seen this decision and this alt set; never again
@@ -656,7 +657,7 @@ public class ErrorManager {
}

public static void unreachableAlts(DecisionProbe probe,
-									   List alts)
+									   List<Integer> alts)
{
getErrorState().errors++;
Message msg = new GrammarUnreachableAltsMessage(probe,alts);
@@ -684,8 +685,8 @@ public class ErrorManager {
public static void recursionOverflow(DecisionProbe probe,
DFAState sampleBadState,
int alt,
-										 Collection targetRules,
-										 Collection callSiteStates)
+										 Collection<String> targetRules,
+										 Collection<? extends Collection<? extends NFAState>> callSiteStates)
{
getErrorState().errors++;
Message msg = new RecursionOverflowMessage(probe,sampleBadState, alt,
@@ -708,7 +709,7 @@ public class ErrorManager {
}
*/

-	public static void leftRecursionCycles(Collection cycles) {
+	public static void leftRecursionCycles(Collection<? extends Set<? extends Rule>> cycles) {
getErrorState().errors++;
Message msg = new LeftRecursionCyclesMessage(cycles);
getErrorState().errorMsgIDs.add(msg.msgID);
diff --git a/tool/src/main/java/org/antlr/tool/FASerializer.java b/tool/src/main/java/org/antlr/tool/FASerializer.java
index 401bbb3..f59cdc0 100644
--- a/tool/src/main/java/org/antlr/tool/FASerializer.java
+++ b/tool/src/main/java/org/antlr/tool/FASerializer.java
@@ -41,7 +41,7 @@ public class FASerializer {
*  walking in case you reuse this object.  Multiple threads will trash
*  this shared variable.  Use a different FASerializer per thread.
*/
-    protected Set markedStates;
+    protected Set<State> markedStates;

/** Each state we walk will get a new state number for serialization
*  purposes.  This is the variable that tracks state numbers.
@@ -52,7 +52,7 @@ public class FASerializer {
*  serializing machines, map old state numbers to new state numbers
*  by a State object -> Integer new state number HashMap.
*/
-    protected Map stateNumberTranslator;
+    protected Map<State, Integer> stateNumberTranslator;

protected Grammar grammar;

@@ -77,13 +77,13 @@ public class FASerializer {
*  states.
*/
public String serialize(State s, boolean renumber) {
-        markedStates = new HashSet();
+        markedStates = new HashSet<State>();
stateCounter = 0;
if ( renumber ) {
-			stateNumberTranslator = new HashMap();
+			stateNumberTranslator = new HashMap<State, Integer>();
walkFANormalizingStateNumbers(s);
}
-		List lines = new ArrayList();
+		List<String> lines = new ArrayList<String>();
if ( s.getNumberOfTransitions()>0 ) {
walkSerializingFA(lines, s);
}
@@ -132,7 +132,7 @@ public class FASerializer {
}
}

-    protected void walkSerializingFA(List lines, State s) {
+    protected void walkSerializingFA(List<String> lines, State s) {
if ( markedStates.contains(s) ) {
return; // already visited this node
}
diff --git a/tool/src/main/java/org/antlr/tool/Grammar.java b/tool/src/main/java/org/antlr/tool/Grammar.java
index b084b3e..876fa43 100644
--- a/tool/src/main/java/org/antlr/tool/Grammar.java
+++ b/tool/src/main/java/org/antlr/tool/Grammar.java
@@ -194,10 +194,10 @@ public class Grammar {
*  interpretation of the key/value pairs...they are simply available for
*  who wants them.
*/
-	protected Map options;
+	protected Map<String, Object> options;

-	public static final Set legalLexerOptions =
-			new HashSet() {
+	public static final Set<String> legalLexerOptions =
+			new HashSet<String>() {
{
add("language"); add("tokenVocab");
add("TokenLabelType");
@@ -209,8 +209,8 @@ public class Grammar {
}
};

-	public static final Set legalParserOptions =
-			new HashSet() {
+	public static final Set<String> legalParserOptions =
+			new HashSet<String>() {
{
add("language"); add("tokenVocab");
add("output"); add("rewrite"); add("ASTLabelType");
@@ -222,8 +222,8 @@ public class Grammar {
}
};

-    public static final Set legalTreeParserOptions =
-        new HashSet() {
+    public static final Set<String> legalTreeParserOptions =
+        new HashSet<String>() {
{
add("language"); add("tokenVocab");
add("output"); add("rewrite"); add("ASTLabelType");
@@ -236,36 +236,36 @@ public class Grammar {
}
};

-	public static final Set doNotCopyOptionsToLexer =
-		new HashSet() {
+	public static final Set<String> doNotCopyOptionsToLexer =
+		new HashSet<String>() {
{
add("output"); add("ASTLabelType"); add("superClass");
add("k"); add("backtrack"); add("memoize"); add("rewrite");
}
};

-	public static final Map defaultOptions =
-			new HashMap() {
+	public static final Map<String, String> defaultOptions =
+			new HashMap<String, String>() {
{
put("language","Java");
}
};

-	public static final Set legalBlockOptions =
-			new HashSet() {{add("k"); add("greedy"); add("backtrack"); add("memoize");}};
+	public static final Set<String> legalBlockOptions =
+			new HashSet<String>() {{add("k"); add("greedy"); add("backtrack"); add("memoize");}};

/** What are the default options for a subrule? */
-	public static final Map defaultBlockOptions =
-			new HashMap() {{put("greedy","true");}};
+	public static final Map<String, String> defaultBlockOptions =
+			new HashMap<String, String>() {{put("greedy","true");}};

-	public static final Map defaultLexerBlockOptions =
-			new HashMap() {{put("greedy","true");}};
+	public static final Map<String, String> defaultLexerBlockOptions =
+			new HashMap<String, String>() {{put("greedy","true");}};

// Token options are here to avoid contaminating Token object in runtime

/** Legal options for terminal refs like ID<node=MyVarNode> */
-	public static final Set legalTokenOptions =
-		new HashSet() {
+	public static final Set<String> legalTokenOptions =
+		new HashSet<String>() {
{
add(defaultTokenOption);
add("type");
@@ -319,7 +319,7 @@ public class Grammar {
/** For ANTLRWorks, we want to be able to map a line:col to a specific
*  decision DFA so it can display DFA.
*/
-	Map lineColumnToLookaheadDFAMap = new HashMap();
+	Map<String, DFA> lineColumnToLookaheadDFAMap = new HashMap<String, DFA>();

public Tool tool;

@@ -328,7 +328,7 @@ public class Grammar {
*/
protected Set<GrammarAST> ruleRefs = new HashSet<GrammarAST>();

-	protected Set<GrammarAST> scopedRuleRefs = new HashSet();
+	protected Set<GrammarAST> scopedRuleRefs = new HashSet<GrammarAST>();

/** The unique set of all token ID references in any rule */
protected Set<Token> tokenIDRefs = new HashSet<Token>();
@@ -395,7 +395,7 @@ public class Grammar {
*  this but I'm leaving in case other targets need it.
*  see NameSpaceChecker.lookForReferencesToUndefinedSymbols()
*/
-	protected Set<Rule> delegatedRuleReferences = new HashSet();
+	protected Set<Rule> delegatedRuleReferences = new HashSet<Rule>();

/** The ANTLRParser tracks lexer rules when reading combined grammars
*  so we can build the Tokens rule.
@@ -405,7 +405,7 @@ public class Grammar {
/** Track the scopes defined outside of rules and the scopes associated
*  with all rules (even if empty).
*/
-	protected Map scopes = new HashMap();
+	protected Map<String, AttributeScope> scopes = new HashMap<String, AttributeScope>();

/** An AST that records entire input grammar with all rules.  A simple
*  grammar with one rule, "grammar t; a : A | B ;", looks like:
@@ -474,7 +474,7 @@ public class Grammar {
/** Track decisions with syn preds specified for reporting.
*  This is the a set of BLOCK type AST nodes.
*/
-	public Set<GrammarAST> blocksWithSynPreds = new HashSet();
+	public Set<GrammarAST> blocksWithSynPreds = new HashSet<GrammarAST>();

/** Track decisions that actually use the syn preds in the DFA.
*  Computed during NFA to DFA conversion.
@@ -487,15 +487,15 @@ public class Grammar {
*  incident edges can have synpreds.  Same is try for
*  decisionsWhoseDFAsUsesSynPreds.
*/
-	public Set<String> synPredNamesUsedInDFA = new HashSet();
+	public Set<String> synPredNamesUsedInDFA = new HashSet<String>();

/** Track decisions with syn preds specified for reporting.
*  This is the a set of BLOCK type AST nodes.
*/
-	public Set<GrammarAST> blocksWithSemPreds = new HashSet();
+	public Set<GrammarAST> blocksWithSemPreds = new HashSet<GrammarAST>();

/** Track decisions that actually use the syn preds in the DFA. */
-	public Set<DFA> decisionsWhoseDFAsUsesSemPreds = new HashSet();
+	public Set<DFA> decisionsWhoseDFAsUsesSemPreds = new HashSet<DFA>();

protected boolean allDecisionDFACreated = false;

@@ -788,7 +788,7 @@ public class Grammar {
}
// make sure generated grammar has the same options
if ( options!=null ) {
-			Iterator optionNames = options.keySet().iterator();
+			Iterator<String> optionNames = options.keySet().iterator();
while (optionNames.hasNext()) {
String optionName = (String) optionNames.next();
if ( !doNotCopyOptionsToLexer.contains(optionName) ) {
@@ -913,7 +913,7 @@ public class Grammar {
/** for any syntactic predicates, we need to define rules for them; they will get
*  defined automatically like any other rule. :)
*/
-	protected List getArtificialRulesForSyntacticPredicates(LinkedHashMap<String,GrammarAST> nameToSynpredASTMap)
+	protected List<? extends GrammarAST> getArtificialRulesForSyntacticPredicates(LinkedHashMap<String,GrammarAST> nameToSynpredASTMap)
{
List<GrammarAST> rules = new ArrayList<GrammarAST>();
if ( nameToSynpredASTMap==null ) {
@@ -933,7 +933,7 @@ public class Grammar {

public void addRulesForSyntacticPredicates() {
// Get syn pred rules and add to existing tree
-		List synpredRules =
+		List<? extends GrammarAST> synpredRules =
getArtificialRulesForSyntacticPredicates(nameToSynpredASTMap);
for (int i = 0; i < synpredRules.size(); i++) {
GrammarAST rAST = (GrammarAST) synpredRules.get(i);
@@ -972,8 +972,8 @@ public class Grammar {
nfa = new NFA(this);
factory = new NFAFactory(nfa);

-		Collection rules = getRules();
-		for (Iterator itr = rules.iterator(); itr.hasNext();) {
+		Collection<Rule> rules = getRules();
+		for (Iterator<Rule> itr = rules.iterator(); itr.hasNext();) {
Rule r = (Rule) itr.next();
String ruleName = r.name;
NFAState ruleBeginState = factory.newState();
@@ -1274,7 +1274,7 @@ outer:
disjointSets.set(i, intersection);

// Compute s_i-t to see what is in current set and not in incoming
-				IntSet existingMinusNewElements = s_i.subtract(t);
+				IntervalSet existingMinusNewElements = s_i.subtract(t);
//System.out.println(s_i+"-"+t+"="+existingMinusNewElements);
if ( !existingMinusNewElements.isNil() ) {
// found a new character class, add to the end (doesn't affect
@@ -1411,7 +1411,7 @@ outer:
*/
public void defineRule(Token ruleToken,
String modifier,
-						   Map options,
+						   Map<String, Object> options,
GrammarAST tree,
GrammarAST argActionAST,
int numAlts)
@@ -1456,7 +1456,7 @@ outer:
String currentRuleName)
{
if ( nameToSynpredASTMap==null ) {
-			nameToSynpredASTMap = new LinkedHashMap();
+			nameToSynpredASTMap = new LinkedHashMap<String, GrammarAST>();
}
String predName =
SYNPRED_RULE_PREFIX+(nameToSynpredASTMap.size() + 1)+"_"+name;
@@ -1465,7 +1465,7 @@ outer:
return predName;
}

-	public LinkedHashMap getSyntacticPredicates() {
+	public LinkedHashMap<String, GrammarAST> getSyntacticPredicates() {
return nameToSynpredASTMap;
}

@@ -1749,7 +1749,7 @@ outer:
return (AttributeScope)scopes.get(name);
}

-	public Map getGlobalScopes() {
+	public Map<String, AttributeScope> getGlobalScopes() {
return scopes;
}

@@ -1884,8 +1884,8 @@ outer:
*  rule labels for example.
*/
protected void examineAllExecutableActions() {
-		Collection rules = getRules();
-		for (Iterator it = rules.iterator(); it.hasNext();) {
+		Collection<Rule> rules = getRules();
+		for (Iterator<Rule> it = rules.iterator(); it.hasNext();) {
Rule r = (Rule) it.next();
// walk all actions within the rule elements, args, and exceptions
List<GrammarAST> actions = r.getInlineActions();
@@ -1896,8 +1896,8 @@ outer:
sniffer.analyze();
}
// walk any named actions like @init, @after
-			Collection<GrammarAST> namedActions = r.getActions().values();
-			for (Iterator it2 = namedActions.iterator(); it2.hasNext();) {
+			Collection<? extends Object> namedActions = r.getActions().values();
+			for (Iterator<? extends Object> it2 = namedActions.iterator(); it2.hasNext();) {
GrammarAST actionAST = (GrammarAST) it2.next();
ActionAnalysis sniffer =
new ActionAnalysis(this, r.name, actionAST);
@@ -1913,8 +1913,8 @@ outer:
if ( type==LEXER ) {
return;
}
-		Set rules = nameToRuleMap.keySet();
-		for (Iterator it = rules.iterator(); it.hasNext();) {
+		Set<String> rules = nameToRuleMap.keySet();
+		for (Iterator<String> it = rules.iterator(); it.hasNext();) {
String ruleName = (String) it.next();
Rule r = getRule(ruleName);
removeUselessLabels(r.getRuleLabels());
@@ -1925,13 +1925,13 @@ outer:
/** A label on a rule is useless if the rule has no return value, no
*  tree or template output, and it is not referenced in an action.
*/
-	protected void removeUselessLabels(Map ruleToElementLabelPairMap) {
+	protected void removeUselessLabels(Map<String, LabelElementPair> ruleToElementLabelPairMap) {
if ( ruleToElementLabelPairMap==null ) {
return;
}
-		Collection labels = ruleToElementLabelPairMap.values();
-		List kill = new ArrayList();
-		for (Iterator labelit = labels.iterator(); labelit.hasNext();) {
+		Collection<LabelElementPair> labels = ruleToElementLabelPairMap.values();
+		List<String> kill = new ArrayList<String>();
+		for (Iterator<LabelElementPair> labelit = labels.iterator(); labelit.hasNext();) {
LabelElementPair pair = (LabelElementPair) labelit.next();
Rule refdRule = getRule(pair.elementRef.getText());
if ( refdRule!=null && !refdRule.getHasReturnValue() && !pair.actionReferencesLabel ) {
@@ -2011,7 +2011,7 @@ outer:
}
}

-	public List checkAllRulesForLeftRecursion() {
+	public List<? extends Collection<? extends Rule>> checkAllRulesForLeftRecursion() {
return sanity.checkAllRulesForLeftRecursion();
}

@@ -2089,7 +2089,7 @@ outer:
}

/** Get the list of tokens that are IDs like BLOCK and LPAREN */
-	public Set getTokenIDs() {
+	public Set<String> getTokenIDs() {
return composite.tokenIDToTypeMap.keySet();
}

@@ -2097,8 +2097,8 @@ outer:
*  corresponding token ID like INT or KEYWORD_BEGIN; for stuff
*  like 'begin'.
*/
-	public Collection getTokenTypesWithoutID() {
-		List types = new ArrayList();
+	public Collection<Integer> getTokenTypesWithoutID() {
+		List<Integer> types = new ArrayList<Integer>();
for (int t =Label.MIN_TOKEN_TYPE; t<=getMaxTokenType(); t++) {
String name = getTokenDisplayName(t);
if ( name.charAt(0)=='\'' ) {
@@ -2214,8 +2214,8 @@ outer:
*  Returns the max token type found.
*/
public int importTokenVocabulary(Grammar importFromGr) {
-		Set importedTokenIDs = importFromGr.getTokenIDs();
-		for (Iterator it = importedTokenIDs.iterator(); it.hasNext();) {
+		Set<String> importedTokenIDs = importFromGr.getTokenIDs();
+		for (Iterator<String> it = importedTokenIDs.iterator(); it.hasNext();) {
String tokenID = (String) it.next();
int tokenType = importFromGr.getTokenType(tokenID);
composite.maxTokenType = Math.max(composite.maxTokenType,tokenType);
@@ -2492,7 +2492,7 @@ outer:
composite.getRootGrammar().atLeastOneBacktrackOption = true;
}
if ( options==null ) {
-			options = new HashMap();
+			options = new HashMap<String, Object>();
}
options.put(key, value);
return key;
@@ -2511,13 +2511,13 @@ outer:
}
}

-	public void setOptions(Map options, Token optionsStartToken) {
+	public void setOptions(Map<String, Object> options, Token optionsStartToken) {
if ( options==null ) {
this.options = null;
return;
}
-		Set keys = options.keySet();
-		for (Iterator it = keys.iterator(); it.hasNext();) {
+		Set<String> keys = options.keySet();
+		for (Iterator<String> it = keys.iterator(); it.hasNext();) {
String optionName = (String) it.next();
Object optionValue = options.get(optionName);
String stored=setOption(optionName, optionValue, optionsStartToken);
@@ -2636,14 +2636,14 @@ outer:
*
*  delegatedRules = imported - overridden
*/
-	public Set<Rule> getDelegatedRules() {
+	public Set<? extends Rule> getDelegatedRules() {
return composite.getDelegatedRules(this);
}

/** Get set of all rules imported from all delegate grammars even if
*  indirectly delegated.
*/
-	public Set<Rule> getAllImportedRules() {
+	public Set<? extends Rule> getAllImportedRules() {
return composite.getAllImportedRules(this);
}

@@ -2769,8 +2769,8 @@ outer:
return d;
}

-	public List getDecisionNFAStartStateList() {
-		List states = new ArrayList(100);
+	public List<NFAState> getDecisionNFAStartStateList() {
+		List<NFAState> states = new ArrayList<NFAState>(100);
for (int d = 0; d < indexToDecision.size(); d++) {
Decision dec = (Decision) indexToDecision.get(d);
states.add(dec.startState);
@@ -2811,10 +2811,10 @@ outer:
*  This is not particularly fast as it walks entire line:col->DFA map
*  looking for a prefix of "line:".
*/
-	public List getLookaheadDFAColumnsForLineInFile(int line) {
+	public List<Integer> getLookaheadDFAColumnsForLineInFile(int line) {
String prefix = line+":";
-		List columns = new ArrayList();
-		for(Iterator iter = lineColumnToLookaheadDFAMap.keySet().iterator();
+		List<Integer> columns = new ArrayList<Integer>();
+		for(Iterator<String> iter = lineColumnToLookaheadDFAMap.keySet().iterator();
iter.hasNext(); ) {
String key = (String)iter.next();
if(key.startsWith(prefix)) {
@@ -2830,7 +2830,7 @@ outer:
new StringBuffer().append(line + ":").append(col).toString());
}

-	public Map getLineColumnToLookaheadDFAMap() {
+	public Map<String, DFA> getLineColumnToLookaheadDFAMap() {
return lineColumnToLookaheadDFAMap;
}

diff --git a/tool/src/main/java/org/antlr/tool/GrammarAST.java b/tool/src/main/java/org/antlr/tool/GrammarAST.java
index 3d36cc8..26d3820 100644
--- a/tool/src/main/java/org/antlr/tool/GrammarAST.java
+++ b/tool/src/main/java/org/antlr/tool/GrammarAST.java
@@ -197,7 +197,7 @@ public class GrammarAST extends CommonTree {
*/
public String setBlockOption(Grammar grammar, String key, Object value) {
if ( blockOptions == null ) {
-			blockOptions = new HashMap();
+			blockOptions = new HashMap<String, Object>();
}
return setOption(blockOptions, Grammar.legalBlockOptions, grammar, key, value);
}
@@ -209,7 +209,7 @@ public class GrammarAST extends CommonTree {
return setOption(terminalOptions, Grammar.legalTokenOptions, grammar, key, value);
}

-	public String setOption(Map options, Set legalOptions, Grammar grammar, String key, Object value) {
+	public String setOption(Map<String, Object> options, Set<String> legalOptions, Grammar grammar, String key, Object value) {
if ( !legalOptions.contains(key) ) {
ErrorManager.grammarError(ErrorManager.MSG_ILLEGAL_OPTION,
grammar,
@@ -241,7 +241,7 @@ public class GrammarAST extends CommonTree {
return value;
}

-    public void setOptions(Grammar grammar, Map options) {
+    public void setOptions(Grammar grammar, Map<String, Object> options) {
if ( options==null ) {
this.blockOptions = null;
return;
diff --git a/tool/src/main/java/org/antlr/tool/GrammarDanglingStateMessage.java b/tool/src/main/java/org/antlr/tool/GrammarDanglingStateMessage.java
index 431d16c..3cca533 100644
--- a/tool/src/main/java/org/antlr/tool/GrammarDanglingStateMessage.java
+++ b/tool/src/main/java/org/antlr/tool/GrammarDanglingStateMessage.java
@@ -29,6 +29,7 @@ package org.antlr.tool;

import org.antlr.analysis.DFAState;
import org.antlr.analysis.DecisionProbe;
+import org.antlr.analysis.Label;
import org.stringtemplate.v4.ST;

import java.util.ArrayList;
@@ -59,10 +60,10 @@ public class GrammarDanglingStateMessage extends Message {
if ( fileName!=null ) {
file = fileName;
}
-		List labels = probe.getSampleNonDeterministicInputSequence(problemState);
+		List<Label> labels = probe.getSampleNonDeterministicInputSequence(problemState);
String input = probe.getInputSequenceDisplay(labels);
ST st = getMessageTemplate();
-		List alts = new ArrayList();
+		List<Integer> alts = new ArrayList<Integer>();
alts.addAll(problemState.getAltSet());
Collections.sort(alts);
st.add("danglingAlts", alts);
diff --git a/tool/src/main/java/org/antlr/tool/GrammarNonDeterminismMessage.java b/tool/src/main/java/org/antlr/tool/GrammarNonDeterminismMessage.java
index 1857f2f..00c1b0e 100644
--- a/tool/src/main/java/org/antlr/tool/GrammarNonDeterminismMessage.java
+++ b/tool/src/main/java/org/antlr/tool/GrammarNonDeterminismMessage.java
@@ -29,6 +29,7 @@ package org.antlr.tool;

import org.antlr.analysis.DFAState;
import org.antlr.analysis.DecisionProbe;
+import org.antlr.analysis.Label;
import org.antlr.analysis.NFAState;
import org.antlr.misc.Utils;
import org.stringtemplate.v4.ST;
@@ -68,13 +69,13 @@ public class GrammarNonDeterminismMessage extends Message {

ST st = getMessageTemplate();
// Now fill template with information about problemState
-		List labels = probe.getSampleNonDeterministicInputSequence(problemState);
+		List<Label> labels = probe.getSampleNonDeterministicInputSequence(problemState);
String input = probe.getInputSequenceDisplay(labels);
st.add("input", input);

if ( probe.dfa.isTokensRuleDecision() ) {
-			Set disabledAlts = probe.getDisabledAlternatives(problemState);
-			for (Iterator it = disabledAlts.iterator(); it.hasNext();) {
+			Set<Integer> disabledAlts = probe.getDisabledAlternatives(problemState);
+			for (Iterator<Integer> it = disabledAlts.iterator(); it.hasNext();) {
Integer altI = (Integer) it.next();
String tokenName =
probe.getTokenNameForTokensRuleAlt(altI.intValue());
@@ -90,12 +91,12 @@ public class GrammarNonDeterminismMessage extends Message {
st.add("disabled", probe.getDisabledAlternatives(problemState));
}

-		List nondetAlts = probe.getNonDeterministicAltsForState(problemState);
+		List<Integer> nondetAlts = probe.getNonDeterministicAltsForState(problemState);
NFAState nfaStart = probe.dfa.getNFADecisionStartState();
// all state paths have to begin with same NFA state
int firstAlt = 0;
if ( nondetAlts!=null ) {
-			for (Iterator iter = nondetAlts.iterator(); iter.hasNext();) {
+			for (Iterator<Integer> iter = nondetAlts.iterator(); iter.hasNext();) {
Integer displayAltI = (Integer) iter.next();
if ( DecisionProbe.verbose ) {
int tracePathAlt =
@@ -103,7 +104,7 @@ public class GrammarNonDeterminismMessage extends Message {
if ( firstAlt == 0 ) {
firstAlt = tracePathAlt;
}
-					List path =
+					List<? extends NFAState> path =
probe.getNFAPathStatesForAlt(firstAlt,
tracePathAlt,
labels);
diff --git a/tool/src/main/java/org/antlr/tool/GrammarReport.java b/tool/src/main/java/org/antlr/tool/GrammarReport.java
index aaa508d..b3bd1e5 100644
--- a/tool/src/main/java/org/antlr/tool/GrammarReport.java
+++ b/tool/src/main/java/org/antlr/tool/GrammarReport.java
@@ -112,8 +112,8 @@ public class GrammarReport {

int totalNonSynPredProductions = 0;
int totalNonSynPredRules = 0;
-		Collection rules = g.getRules();
-		for (Iterator it = rules.iterator(); it.hasNext();) {
+		Collection<Rule> rules = g.getRules();
+		for (Iterator<Rule> it = rules.iterator(); it.hasNext();) {
Rule r = (Rule) it.next();
if ( !r.name.toUpperCase()
.startsWith(Grammar.SYNPRED_RULE_PREFIX.toUpperCase()) )
@@ -287,10 +287,10 @@ public class GrammarReport {
return buf.toString();
}

-	protected String getDFALocations(Set dfas) {
-		Set decisions = new HashSet();
+	protected String getDFALocations(Set<DFA> dfas) {
+		Set<Integer> decisions = new HashSet<Integer>();
StringBuffer buf = new StringBuffer();
-		Iterator it = dfas.iterator();
+		Iterator<DFA> it = dfas.iterator();
while ( it.hasNext() ) {
DFA dfa = (DFA) it.next();
// if we aborted a DFA and redid with k=1, the backtrackin
diff --git a/tool/src/main/java/org/antlr/tool/GrammarSanity.java b/tool/src/main/java/org/antlr/tool/GrammarSanity.java
index bcfabfb..f4376f6 100644
--- a/tool/src/main/java/org/antlr/tool/GrammarSanity.java
+++ b/tool/src/main/java/org/antlr/tool/GrammarSanity.java
@@ -57,14 +57,14 @@ public class GrammarSanity {
*/
public List<Set<Rule>> checkAllRulesForLeftRecursion() {
grammar.buildNFA(); // make sure we have NFAs
-		grammar.leftRecursiveRules = new HashSet();
-		List<Set<Rule>> listOfRecursiveCycles = new ArrayList();
+		grammar.leftRecursiveRules = new HashSet<Rule>();
+		List<Set<Rule>> listOfRecursiveCycles = new ArrayList<Set<Rule>>();
for (int i = 0; i < grammar.composite.ruleIndexToRuleList.size(); i++) {
Rule r = grammar.composite.ruleIndexToRuleList.elementAt(i);
if ( r!=null ) {
-				visitedDuringRecursionCheck = new HashSet();
+				visitedDuringRecursionCheck = new HashSet<Rule>();
visitedDuringRecursionCheck.add(r);
-				Set visitedStates = new HashSet();
+				Set<NFAState> visitedStates = new HashSet<NFAState>();
traceStatesLookingForLeftRecursion(r.startState,
visitedStates,
listOfRecursiveCycles);
@@ -87,7 +87,7 @@ public class GrammarSanity {
*  side-effect, set leftRecursiveRules.
*/
protected boolean traceStatesLookingForLeftRecursion(NFAState s,
-														 Set visitedStates,
+														 Set<NFAState> visitedStates,
List<Set<Rule>> listOfRecursiveCycles)
{
if ( s.isAcceptState() ) {
@@ -122,7 +122,7 @@ public class GrammarSanity {
visitedDuringRecursionCheck.add(refRuleDef);
boolean callReachedAcceptState =
traceStatesLookingForLeftRecursion((NFAState)t0.target,
-													   new HashSet(),
+													   new HashSet<NFAState>(),
listOfRecursiveCycles);
// we're back from visiting that rule
visitedDuringRecursionCheck.remove(refRuleDef);
@@ -178,7 +178,7 @@ public class GrammarSanity {
}
}
if ( !foundCycle ) {
-			Set cycle = new HashSet();
+			Set<Rule> cycle = new HashSet<Rule>();
cycle.add(targetRule);
cycle.add(enclosingRule);
listOfRecursiveCycles.add(cycle);
diff --git a/tool/src/main/java/org/antlr/tool/GrammarSerializerFoo.java b/tool/src/main/java/org/antlr/tool/GrammarSerializerFoo.java
index fc1afb8..28a4555 100644
--- a/tool/src/main/java/org/antlr/tool/GrammarSerializerFoo.java
+++ b/tool/src/main/java/org/antlr/tool/GrammarSerializerFoo.java
@@ -31,7 +31,6 @@ package org.antlr.tool;
import org.antlr.runtime.SerializedGrammar;

import java.io.*;
-import java.util.Stack;

/** Serialize a grammar into a highly compressed form with
*  only the info needed to recognize sentences.
@@ -47,7 +46,6 @@ public class GrammarSerializerFoo {
protected String filename;
protected Grammar g;

-    protected Stack streams = new Stack();
protected ByteArrayOutputStream altBuf;
protected int numElementsInAlt = 0;

diff --git a/tool/src/main/java/org/antlr/tool/GrammarUnreachableAltsMessage.java b/tool/src/main/java/org/antlr/tool/GrammarUnreachableAltsMessage.java
index 61bfa99..a44a7fb 100644
--- a/tool/src/main/java/org/antlr/tool/GrammarUnreachableAltsMessage.java
+++ b/tool/src/main/java/org/antlr/tool/GrammarUnreachableAltsMessage.java
@@ -38,10 +38,10 @@ import java.util.List;
*/
public class GrammarUnreachableAltsMessage extends Message {
public DecisionProbe probe;
-    public List alts;
+    public List<Integer> alts;

public GrammarUnreachableAltsMessage(DecisionProbe probe,
-										 List alts)
+										 List<Integer> alts)
{
super(ErrorManager.MSG_UNREACHABLE_ALTS);
this.probe = probe;
diff --git a/tool/src/main/java/org/antlr/tool/Interp.java b/tool/src/main/java/org/antlr/tool/Interp.java
index 7a7639d..71a572d 100644
--- a/tool/src/main/java/org/antlr/tool/Interp.java
+++ b/tool/src/main/java/org/antlr/tool/Interp.java
@@ -33,6 +33,7 @@ import org.antlr.runtime.tree.ParseTree;

import java.io.BufferedReader;
import java.io.FileReader;
+import java.util.Collection;
import java.util.HashSet;
import java.util.List;
import java.util.Set;
@@ -86,7 +87,7 @@ public class Interp {
parser.composite.defineGrammarSymbols();
parser.composite.createNFAs();

-		List leftRecursiveRules = parser.checkAllRulesForLeftRecursion();
+		List<? extends Collection<? extends Rule>> leftRecursiveRules = parser.checkAllRulesForLeftRecursion();
if ( leftRecursiveRules.size()>0 ) {
return;
}
diff --git a/tool/src/main/java/org/antlr/tool/Interpreter.java b/tool/src/main/java/org/antlr/tool/Interpreter.java
index 526cafd..2af82aa 100644
--- a/tool/src/main/java/org/antlr/tool/Interpreter.java
+++ b/tool/src/main/java/org/antlr/tool/Interpreter.java
@@ -125,7 +125,7 @@ public class Interpreter implements TokenSource {
*/
public void scan(String startRule,
DebugEventListener actions,
-					 List visitedStates)
+					 List<NFAState> visitedStates)
throws RecognitionException
{
if ( grammar.type!=Grammar.LEXER ) {
@@ -144,7 +144,7 @@ public class Interpreter implements TokenSource {
}

// do the parse
-		Stack ruleInvocationStack = new Stack();
+		Stack<NFAState> ruleInvocationStack = new Stack<NFAState>();
NFAState start = grammar.getRuleStartState(startRule);
NFAState stop = grammar.getRuleStopState(startRule);
parseEngine(startRule, start, stop, in, ruleInvocationStack,
@@ -158,7 +158,7 @@ public class Interpreter implements TokenSource {
}

public CommonToken scan(String startRule,
-							List visitedStates)
+							List<NFAState> visitedStates)
throws RecognitionException
{
LexerActionGetTokenType actions = new LexerActionGetTokenType(grammar);
@@ -168,7 +168,7 @@ public class Interpreter implements TokenSource {

public void parse(String startRule,
DebugEventListener actions,
-					  List visitedStates)
+					  List<NFAState> visitedStates)
throws RecognitionException
{
//System.out.println("parse("+startRule+")");
@@ -181,7 +181,7 @@ public class Interpreter implements TokenSource {
grammar.createLookaheadDFAs();
}
// do the parse
-		Stack ruleInvocationStack = new Stack();
+		Stack<NFAState> ruleInvocationStack = new Stack<NFAState>();
NFAState start = grammar.getRuleStartState(startRule);
NFAState stop = grammar.getRuleStopState(startRule);
parseEngine(startRule, start, stop, input, ruleInvocationStack,
@@ -194,7 +194,7 @@ public class Interpreter implements TokenSource {
return parse(startRule, null);
}

-	public ParseTree parse(String startRule, List visitedStates)
+	public ParseTree parse(String startRule, List<NFAState> visitedStates)
throws RecognitionException
{
ParseTreeBuilder actions = new ParseTreeBuilder(grammar.name);
@@ -214,9 +214,9 @@ public class Interpreter implements TokenSource {
NFAState start,
NFAState stop,
IntStream input,
-							   Stack ruleInvocationStack,
+							   Stack<NFAState> ruleInvocationStack,
DebugEventListener actions,
-							   List visitedStates)
+							   List<NFAState> visitedStates)
throws RecognitionException
{
NFAState s = start;
diff --git a/tool/src/main/java/org/antlr/tool/LeftRecursionCyclesMessage.java b/tool/src/main/java/org/antlr/tool/LeftRecursionCyclesMessage.java
index 69fd0ea..98e969c 100644
--- a/tool/src/main/java/org/antlr/tool/LeftRecursionCyclesMessage.java
+++ b/tool/src/main/java/org/antlr/tool/LeftRecursionCyclesMessage.java
@@ -36,9 +36,9 @@ import java.util.Collection;
*  invoked when a decision DFA construction finds a problem in closure.
*/
public class LeftRecursionCyclesMessage extends Message {
-	public Collection cycles;
+	public Collection<? extends Collection<? extends Rule>> cycles;

-	public LeftRecursionCyclesMessage(Collection cycles) {
+	public LeftRecursionCyclesMessage(Collection<? extends Collection<? extends Rule>> cycles) {
super(ErrorManager.MSG_LEFT_RECURSION_CYCLES);
this.cycles = cycles;
}
diff --git a/tool/src/main/java/org/antlr/tool/NFAFactory.java b/tool/src/main/java/org/antlr/tool/NFAFactory.java
index 6353df0..ec2f983 100644
--- a/tool/src/main/java/org/antlr/tool/NFAFactory.java
+++ b/tool/src/main/java/org/antlr/tool/NFAFactory.java
@@ -291,9 +291,9 @@ public class NFAFactory {
*  not invoked by another rule (they can only be invoked from outside).
*  These are the start rules.
*/
-    public int build_EOFStates(Collection rules) {
+    public int build_EOFStates(Collection<Rule> rules) {
int numberUnInvokedRules = 0;
-        for (Iterator iterator = rules.iterator(); iterator.hasNext();) {
+        for (Iterator<Rule> iterator = rules.iterator(); iterator.hasNext();) {
Rule r = (Rule) iterator.next();
NFAState endNFAState = r.stopState;
// Is this rule a start symbol?  (no follow links)
@@ -384,7 +384,7 @@ public class NFAFactory {
*
*  Set alt number (1..n) in the left-Transition NFAState.
*/
-    public StateCluster build_AlternativeBlock(List alternativeStateClusters)
+    public StateCluster build_AlternativeBlock(List<StateCluster> alternativeStateClusters)
{
StateCluster result;
if ( alternativeStateClusters==null || alternativeStateClusters.isEmpty() ) {
@@ -411,7 +411,7 @@ public class NFAFactory {
NFAState blockEndNFAState = newState();
blockEndNFAState.setDescription("end block");
int altNum = 1;
-        for (Iterator iter = alternativeStateClusters.iterator(); iter.hasNext();) {
+        for (Iterator<StateCluster> iter = alternativeStateClusters.iterator(); iter.hasNext();) {
StateCluster g = (StateCluster) iter.next();
// add begin NFAState for this alt connected by epsilon
NFAState left = newState();
@@ -700,7 +700,7 @@ public class NFAFactory {
// make optional . alt
StateCluster optionalNodeAlt = build_Wildcard(associatedAST);

-        List alts = new ArrayList();
+        List<StateCluster> alts = new ArrayList<StateCluster>();
alts.add(wildRoot);
alts.add(optionalNodeAlt);
StateCluster blk = build_AlternativeBlock(alts);
diff --git a/tool/src/main/java/org/antlr/tool/NameSpaceChecker.java b/tool/src/main/java/org/antlr/tool/NameSpaceChecker.java
index 6c6dbb5..9d24366 100644
--- a/tool/src/main/java/org/antlr/tool/NameSpaceChecker.java
+++ b/tool/src/main/java/org/antlr/tool/NameSpaceChecker.java
@@ -49,7 +49,7 @@ public class NameSpaceChecker {
}
// walk all labels for Rule r
if ( r.labelNameSpace!=null ) {
-				Iterator it = r.labelNameSpace.values().iterator();
+				Iterator<Grammar.LabelElementPair> it = r.labelNameSpace.values().iterator();
while ( it.hasNext() ) {
Grammar.LabelElementPair pair = (Grammar.LabelElementPair) it.next();
checkForLabelConflict(r, pair.label);
@@ -57,7 +57,7 @@ public class NameSpaceChecker {
}
// walk rule scope attributes for Rule r
if ( r.ruleScope!=null ) {
-				List attributes = r.ruleScope.getAttributes();
+				List<Attribute> attributes = r.ruleScope.getAttributes();
for (int j = 0; j < attributes.size(); j++) {
Attribute attribute = (Attribute) attributes.get(j);
checkForRuleScopeAttributeConflict(r, attribute);
@@ -67,7 +67,7 @@ public class NameSpaceChecker {
checkForRuleArgumentAndReturnValueConflicts(r);
}
// check all global scopes against tokens
-		Iterator it = grammar.getGlobalScopes().values().iterator();
+		Iterator<AttributeScope> it = grammar.getGlobalScopes().values().iterator();
while (it.hasNext()) {
AttributeScope scope = (AttributeScope) it.next();
checkForGlobalScopeTokenConflict(scope);
@@ -78,9 +78,9 @@ public class NameSpaceChecker {

protected void checkForRuleArgumentAndReturnValueConflicts(Rule r) {
if ( r.returnScope!=null ) {
-			Set conflictingKeys = r.returnScope.intersection(r.parameterScope);
+			Set<String> conflictingKeys = r.returnScope.intersection(r.parameterScope);
if (conflictingKeys!=null) {
-				for (Iterator it = conflictingKeys.iterator(); it.hasNext();) {
+				for (Iterator<String> it = conflictingKeys.iterator(); it.hasNext();) {
String key = (String) it.next();
ErrorManager.grammarError(
ErrorManager.MSG_ARG_RETVAL_CONFLICT,
@@ -125,7 +125,7 @@ public class NameSpaceChecker {
*/
protected void lookForReferencesToUndefinedSymbols() {
// for each rule ref, ask if there is a rule definition
-		for (Iterator iter = grammar.ruleRefs.iterator(); iter.hasNext();) {
+		for (Iterator<GrammarAST> iter = grammar.ruleRefs.iterator(); iter.hasNext();) {
GrammarAST refAST = (GrammarAST)iter.next();
Token tok = refAST.token;
String ruleName = tok.getText();
@@ -145,7 +145,7 @@ public class NameSpaceChecker {
if ( grammar.type==Grammar.COMBINED ) {
// if we're a combined grammar, we know which token IDs have no
// associated lexer rule.
-			for (Iterator iter = grammar.tokenIDRefs.iterator(); iter.hasNext();) {
+			for (Iterator<Token> iter = grammar.tokenIDRefs.iterator(); iter.hasNext();) {
Token tok = (Token) iter.next();
String tokenID = tok.getText();
if ( !grammar.composite.lexerRules.contains(tokenID) &&
@@ -159,7 +159,7 @@ public class NameSpaceChecker {
}
}
// check scopes and scoped rule refs
-		for (Iterator it = grammar.scopedRuleRefs.iterator(); it.hasNext();) {
+		for (Iterator<GrammarAST> it = grammar.scopedRuleRefs.iterator(); it.hasNext();) {
GrammarAST scopeAST = (GrammarAST)it.next(); // ^(DOT ID atom)
Grammar scopeG = grammar.composite.getGrammar(scopeAST.getText());
GrammarAST refAST = (GrammarAST)scopeAST.getChild(1);
diff --git a/tool/src/main/java/org/antlr/tool/NonRegularDecisionMessage.java b/tool/src/main/java/org/antlr/tool/NonRegularDecisionMessage.java
index 798a602..2529a06 100644
--- a/tool/src/main/java/org/antlr/tool/NonRegularDecisionMessage.java
+++ b/tool/src/main/java/org/antlr/tool/NonRegularDecisionMessage.java
@@ -59,7 +59,7 @@ public class NonRegularDecisionMessage extends Message {
ST st = getMessageTemplate();
String ruleName = probe.dfa.getNFADecisionStartState().enclosingRule.name;
st.add("ruleName", ruleName);
-		List sortedAlts = new ArrayList();
+		List<Integer> sortedAlts = new ArrayList<Integer>();
sortedAlts.addAll(altsWithRecursion);
Collections.sort(sortedAlts); // make sure it's 1, 2, ...
st.add("alts", sortedAlts);
diff --git a/tool/src/main/java/org/antlr/tool/RandomPhrase.java b/tool/src/main/java/org/antlr/tool/RandomPhrase.java
index fff6086..3959930 100644
--- a/tool/src/main/java/org/antlr/tool/RandomPhrase.java
+++ b/tool/src/main/java/org/antlr/tool/RandomPhrase.java
@@ -38,6 +38,7 @@ import org.antlr.misc.Utils;
import java.io.BufferedReader;
import java.io.FileReader;
import java.util.ArrayList;
+import java.util.Collection;
import java.util.List;
import java.util.Random;
import java.util.Stack;
@@ -70,7 +71,7 @@ public class RandomPhrase {
NFAState state = g.getRuleStartState(startRule);
NFAState stopState = g.getRuleStopState(startRule);

-		Stack ruleInvocationStack = new Stack();
+		Stack<NFAState> ruleInvocationStack = new Stack<NFAState>();
while ( true ) {
if ( state==stopState && ruleInvocationStack.size()==0 ) {
break;
@@ -166,7 +167,7 @@ public class RandomPhrase {
parser.composite.defineGrammarSymbols();
parser.composite.createNFAs();

-			List leftRecursiveRules = parser.checkAllRulesForLeftRecursion();
+			List<? extends Collection<? extends Rule>> leftRecursiveRules = parser.checkAllRulesForLeftRecursion();
if ( leftRecursiveRules.size()>0 ) {
return;
}
diff --git a/tool/src/main/java/org/antlr/tool/RecursionOverflowMessage.java b/tool/src/main/java/org/antlr/tool/RecursionOverflowMessage.java
index a9378f5..fdb3557 100644
--- a/tool/src/main/java/org/antlr/tool/RecursionOverflowMessage.java
+++ b/tool/src/main/java/org/antlr/tool/RecursionOverflowMessage.java
@@ -29,6 +29,8 @@ package org.antlr.tool;

import org.antlr.analysis.DFAState;
import org.antlr.analysis.DecisionProbe;
+import org.antlr.analysis.Label;
+import org.antlr.analysis.NFAState;
import org.stringtemplate.v4.ST;

import java.util.Collection;
@@ -41,14 +43,14 @@ public class RecursionOverflowMessage extends Message {
public DecisionProbe probe;
public DFAState sampleBadState;
public int alt;
-	public Collection targetRules;
-	public Collection callSiteStates;
+	public Collection<String> targetRules;
+	public Collection<? extends Collection<? extends NFAState>> callSiteStates;

public RecursionOverflowMessage(DecisionProbe probe,
DFAState sampleBadState,
int alt,
-									Collection targetRules,
-									Collection callSiteStates)
+									Collection<String> targetRules,
+									Collection<? extends Collection<? extends NFAState>> callSiteStates)
{
super(ErrorManager.MSG_RECURSION_OVERLOW);
this.probe = probe;
@@ -73,7 +75,7 @@ public class RecursionOverflowMessage extends Message {
st.add("alt", alt);
st.add("callSiteStates", callSiteStates);

-		List labels =
+		List<Label> labels =
probe.getSampleNonDeterministicInputSequence(sampleBadState);
String input = probe.getInputSequenceDisplay(labels);
st.add("input", input);
diff --git a/tool/src/main/java/org/antlr/tool/Rule.java b/tool/src/main/java/org/antlr/tool/Rule.java
index 541c035..742c8d3 100644
--- a/tool/src/main/java/org/antlr/tool/Rule.java
+++ b/tool/src/main/java/org/antlr/tool/Rule.java
@@ -44,10 +44,10 @@ public class Rule {
public NFAState stopState;

/** This rule's options */
-	protected Map options;
+	protected Map<String, Object> options;

-	public static final Set legalOptions =
-			new HashSet() {
+	public static final Set<String> legalOptions =
+			new HashSet<String>() {
{
add("k"); add("greedy"); add("memoize");
add("backtrack");
@@ -74,31 +74,31 @@ public class Rule {
public AttributeScope ruleScope;

/** A list of scope names (String) used by this rule */
-	public List useScopes;
+	public List<String> useScopes;

/** Exceptions that this rule can throw */
public Set<String> throwsSpec;

/** A list of all LabelElementPair attached to tokens like id=ID */
-    public LinkedHashMap tokenLabels;
+    public LinkedHashMap<String, Grammar.LabelElementPair> tokenLabels;

/** A list of all LabelElementPair attached to tokens like x=. in tree grammar */
-    public LinkedHashMap wildcardTreeLabels;
+    public LinkedHashMap<String, Grammar.LabelElementPair> wildcardTreeLabels;

/** A list of all LabelElementPair attached to tokens like x+=. in tree grammar */
-    public LinkedHashMap wildcardTreeListLabels;
+    public LinkedHashMap<String, Grammar.LabelElementPair> wildcardTreeListLabels;

/** A list of all LabelElementPair attached to single char literals like x='a' */
-	public LinkedHashMap charLabels;
+	public LinkedHashMap<String, Grammar.LabelElementPair> charLabels;

/** A list of all LabelElementPair attached to rule references like f=field */
-	public LinkedHashMap ruleLabels;
+	public LinkedHashMap<String, Grammar.LabelElementPair> ruleLabels;

/** A list of all Token list LabelElementPair like ids+=ID */
-	public LinkedHashMap tokenListLabels;
+	public LinkedHashMap<String, Grammar.LabelElementPair> tokenListLabels;

/** A list of all rule ref list LabelElementPair like ids+=expr */
-	public LinkedHashMap ruleListLabels;
+	public LinkedHashMap<String, Grammar.LabelElementPair> ruleListLabels;

/** All labels go in here (plus being split per the above lists) to
*  catch dup label and label type mismatches.
@@ -113,8 +113,8 @@ public class Rule {
*  for errors.  A better name is probably namedActions, but I don't
*  want everyone to have to change their code gen templates now.
*/
-	protected Map<String, GrammarAST> actions =
-		new HashMap<String, GrammarAST>();
+	protected Map<String, Object> actions =
+		new HashMap<String, Object>();

/** Track all executable actions other than named actions like @init.
*  Also tracks exception handlers, predicates, and rewrite rewrites.
@@ -157,6 +157,7 @@ public class Rule {

public boolean imported = false;

+	@SuppressWarnings("unchecked")
public Rule(Grammar grammar,
String ruleName,
int ruleIndex,
@@ -167,8 +168,8 @@ public class Rule {
this.numberOfAlts = numberOfAlts;
this.grammar = grammar;
throwsSpec = new HashSet<String>();
-		altToTokenRefMap = new Map[numberOfAlts+1];
-		altToRuleRefMap = new Map[numberOfAlts+1];
+		altToTokenRefMap = (Map<String, List<GrammarAST>>[])new Map<?, ?>[numberOfAlts+1];
+		altToRuleRefMap = (Map<String, List<GrammarAST>>[])new Map<?, ?>[numberOfAlts+1];
for (int alt=1; alt<=numberOfAlts; alt++) {
altToTokenRefMap[alt] = new HashMap<String, List<GrammarAST>>();
altToRuleRefMap[alt] = new HashMap<String, List<GrammarAST>>();
@@ -187,31 +188,31 @@ public class Rule {
labelNameSpace.put(label.getText(), pair);
switch ( type ) {
case Grammar.TOKEN_LABEL :
-                if ( tokenLabels==null ) tokenLabels = new LinkedHashMap();
+                if ( tokenLabels==null ) tokenLabels = new LinkedHashMap<String, Grammar.LabelElementPair>();
tokenLabels.put(label.getText(), pair);
break;
case Grammar.WILDCARD_TREE_LABEL :
-                if ( wildcardTreeLabels==null ) wildcardTreeLabels = new LinkedHashMap();
+                if ( wildcardTreeLabels==null ) wildcardTreeLabels = new LinkedHashMap<String, Grammar.LabelElementPair>();
wildcardTreeLabels.put(label.getText(), pair);
break;
case Grammar.WILDCARD_TREE_LIST_LABEL :
-                if ( wildcardTreeListLabels==null ) wildcardTreeListLabels = new LinkedHashMap();
+                if ( wildcardTreeListLabels==null ) wildcardTreeListLabels = new LinkedHashMap<String, Grammar.LabelElementPair>();
wildcardTreeListLabels.put(label.getText(), pair);
break;
case Grammar.RULE_LABEL :
-				if ( ruleLabels==null ) ruleLabels = new LinkedHashMap();
+				if ( ruleLabels==null ) ruleLabels = new LinkedHashMap<String, Grammar.LabelElementPair>();
ruleLabels.put(label.getText(), pair);
break;
case Grammar.TOKEN_LIST_LABEL :
-				if ( tokenListLabels==null ) tokenListLabels = new LinkedHashMap();
+				if ( tokenListLabels==null ) tokenListLabels = new LinkedHashMap<String, Grammar.LabelElementPair>();
tokenListLabels.put(label.getText(), pair);
break;
case Grammar.RULE_LIST_LABEL :
-				if ( ruleListLabels==null ) ruleListLabels = new LinkedHashMap();
+				if ( ruleListLabels==null ) ruleListLabels = new LinkedHashMap<String, Grammar.LabelElementPair>();
ruleListLabels.put(label.getText(), pair);
break;
case Grammar.CHAR_LABEL :
-				if ( charLabels==null ) charLabels = new LinkedHashMap();
+				if ( charLabels==null ) charLabels = new LinkedHashMap<String, Grammar.LabelElementPair>();
charLabels.put(label.getText(), pair);
break;
}
@@ -229,11 +230,11 @@ public class Rule {
return pair;
}

-	public Map getRuleLabels() {
+	public Map<String, Grammar.LabelElementPair> getRuleLabels() {
return ruleLabels;
}

-	public Map getRuleListLabels() {
+	public Map<String, Grammar.LabelElementPair> getRuleListLabels() {
return ruleListLabels;
}

@@ -268,40 +269,40 @@ public class Rule {
*  token IDs to check for token IDs without corresponding lexer rules.
*/
public void trackTokenReferenceInAlt(GrammarAST refAST, int outerAltNum) {
-		List refs = (List)altToTokenRefMap[outerAltNum].get(refAST.getText());
+		List<GrammarAST> refs = altToTokenRefMap[outerAltNum].get(refAST.getText());
if ( refs==null ) {
-			refs = new ArrayList();
+			refs = new ArrayList<GrammarAST>();
altToTokenRefMap[outerAltNum].put(refAST.getText(), refs);
}
refs.add(refAST);
}

-	public List getTokenRefsInAlt(String ref, int outerAltNum) {
+	public List<GrammarAST> getTokenRefsInAlt(String ref, int outerAltNum) {
if ( altToTokenRefMap[outerAltNum]!=null ) {
-			List tokenRefASTs = (List)altToTokenRefMap[outerAltNum].get(ref);
+			List<GrammarAST> tokenRefASTs = altToTokenRefMap[outerAltNum].get(ref);
return tokenRefASTs;
}
return null;
}

public void trackRuleReferenceInAlt(GrammarAST refAST, int outerAltNum) {
-		List refs = (List)altToRuleRefMap[outerAltNum].get(refAST.getText());
+		List<GrammarAST> refs = altToRuleRefMap[outerAltNum].get(refAST.getText());
if ( refs==null ) {
-			refs = new ArrayList();
+			refs = new ArrayList<GrammarAST>();
altToRuleRefMap[outerAltNum].put(refAST.getText(), refs);
}
refs.add(refAST);
}

-	public List getRuleRefsInAlt(String ref, int outerAltNum) {
+	public List<GrammarAST> getRuleRefsInAlt(String ref, int outerAltNum) {
if ( altToRuleRefMap[outerAltNum]!=null ) {
-			List ruleRefASTs = (List)altToRuleRefMap[outerAltNum].get(ref);
+			List<GrammarAST> ruleRefASTs = altToRuleRefMap[outerAltNum].get(ref);
return ruleRefASTs;
}
return null;
}

-	public Set getTokenRefsInAlt(int altNum) {
+	public Set<String> getTokenRefsInAlt(int altNum) {
return altToTokenRefMap[altNum].keySet();
}

@@ -310,7 +311,7 @@ public class Rule {
*  token types for which the rule needs a list of tokens.  This
*  is called from the rule template not directly by the code generator.
*/
-	public Set getAllTokenRefsInAltsWithRewrites() {
+	public Set<String> getAllTokenRefsInAltsWithRewrites() {
String output = (String)grammar.getOption("output");
Set<String> tokens = new HashSet<String>();
if ( output==null || !output.equals("AST") ) {
@@ -332,7 +333,7 @@ public class Rule {
return tokens;
}

-	public Set getRuleRefsInAlt(int outerAltNum) {
+	public Set<String> getRuleRefsInAlt(int outerAltNum) {
return altToRuleRefMap[outerAltNum].keySet();
}

@@ -340,11 +341,11 @@ public class Rule {
*  left-hand-side; so we need Lists.  This is a unique list of all
*  rule results for which the rule needs a list of results.
*/
-	public Set getAllRuleRefsInAltsWithRewrites() {
-		Set rules = new HashSet();
+	public Set<String> getAllRuleRefsInAltsWithRewrites() {
+		Set<String> rules = new HashSet<String>();
for (int i = 1; i <= numberOfAlts; i++) {
if ( hasRewrite(i) ) {
-				Map m = altToRuleRefMap[i];
+				Map<String, ?> m = altToRuleRefMap[i];
rules.addAll(m.keySet());
}
}
@@ -408,12 +409,12 @@ public class Rule {
Character.isUpperCase(refdSymbol.charAt(0)) )
{
// symbol is a token
-			List tokenRefs = getTokenRefsInAlt(refdSymbol, outerAltNum);
+			List<GrammarAST> tokenRefs = getTokenRefsInAlt(refdSymbol, outerAltNum);
uniqueRefAST = (GrammarAST)tokenRefs.get(0);
}
else {
// symbol is a rule
-			List ruleRefs = getRuleRefsInAlt(refdSymbol, outerAltNum);
+			List<GrammarAST> ruleRefs = getRuleRefsInAlt(refdSymbol, outerAltNum);
uniqueRefAST = (GrammarAST)ruleRefs.get(0);
}
if ( uniqueRefAST.code==null ) {
@@ -472,18 +473,14 @@ public class Rule {

public String getSingleValueReturnType() {
if ( returnScope!=null && returnScope.attributes.size()==1 ) {
-			Collection retvalAttrs = returnScope.attributes.values();
-			Object[] javaSucks = retvalAttrs.toArray();
-			return ((Attribute)javaSucks[0]).type;
+			return returnScope.attributes.values().iterator().next().type;
}
return null;
}

public String getSingleValueReturnName() {
if ( returnScope!=null && returnScope.attributes.size()==1 ) {
-			Collection retvalAttrs = returnScope.attributes.values();
-			Object[] javaSucks = retvalAttrs.toArray();
-			return ((Attribute)javaSucks[0]).name;
+			return returnScope.attributes.values().iterator().next().name;
}
return null;
}
@@ -512,11 +509,11 @@ public class Rule {
inlineActions.add(actionAST);
}

-	public Map<String, GrammarAST> getActions() {
+	public Map<String, Object> getActions() {
return actions;
}

-	public void setActions(Map<String, GrammarAST> actions) {
+	public void setActions(Map<String, Object> actions) {
this.actions = actions;
}

@@ -532,7 +529,7 @@ public class Rule {
return null;
}
if ( options==null ) {
-			options = new HashMap();
+			options = new HashMap<String, Object>();
}
if ( key.equals("memoize") && value.toString().equals("true") ) {
grammar.composite.getRootGrammar().atLeastOneRuleMemoizes = true;
@@ -547,13 +544,13 @@ public class Rule {
return key;
}

-	public void setOptions(Map options, Token optionsStartToken) {
+	public void setOptions(Map<String, Object> options, Token optionsStartToken) {
if ( options==null ) {
this.options = null;
return;
}
-		Set keys = options.keySet();
-		for (Iterator it = keys.iterator(); it.hasNext();) {
+		Set<String> keys = options.keySet();
+		for (Iterator<String> it = keys.iterator(); it.hasNext();) {
String optionName = (String) it.next();
Object optionValue = options.get(optionName);
String stored=setOption(optionName, optionValue, optionsStartToken);
diff --git a/tool/src/main/java/org/antlr/tool/Strip.java b/tool/src/main/java/org/antlr/tool/Strip.java
index da2fb5e..1763eb5 100644
--- a/tool/src/main/java/org/antlr/tool/Strip.java
+++ b/tool/src/main/java/org/antlr/tool/Strip.java
@@ -232,7 +232,7 @@ public class Strip {
}

private static void killTrailingNewline(TokenRewriteStream tokens, int index) {
-        List all = tokens.getTokens();
+        List<? extends Token> all = tokens.getTokens();
Token tok = (Token)all.get(index);
Token after = (Token)all.get(index+1);
String ws = after.getText();
diff --git a/tool/src/main/resources/org/antlr/codegen/templates/Java/Java.stg b/tool/src/main/resources/org/antlr/codegen/templates/Java/Java.stg
index df6a9b8..d6b1e25 100644
--- a/tool/src/main/resources/org/antlr/codegen/templates/Java/Java.stg
+++ b/tool/src/main/resources/org/antlr/codegen/templates/Java/Java.stg
@@ -1191,7 +1191,7 @@ globalAttributeScope(scope) ::= <<
protected static class <scope.name>_scope {
<scope.attributes:{it |<it.decl>;}; separator="\n">
}
-protected Stack <scope.name>_stack = new Stack();<\n>
+protected Stack\<<scope.name>_scope\> <scope.name>_stack = new Stack\<<scope.name>_scope\>();<\n>
<endif>
>>

@@ -1200,7 +1200,7 @@ ruleAttributeScope(scope) ::= <<
protected static class <scope.name>_scope {
<scope.attributes:{it |<it.decl>;}; separator="\n">
}
-protected Stack <scope.name>_stack = new Stack();<\n>
+protected Stack\<<scope.name>_scope\> <scope.name>_stack = new Stack\<<scope.name>_scope\>();<\n>
<endif>
>>

diff --git a/tool/src/test/java/org/antlr/test/BaseTest.java b/tool/src/test/java/org/antlr/test/BaseTest.java
index ac7c821..6446927 100644
--- a/tool/src/test/java/org/antlr/test/BaseTest.java
+++ b/tool/src/test/java/org/antlr/test/BaseTest.java
@@ -150,7 +150,7 @@ public abstract class BaseTest {
mkdir(tmpdir);
writeFile(tmpdir, fileName, grammarStr);
try {
-			final List options = new ArrayList();
+			final List<String> options = new ArrayList<String>();
if ( debug ) {
options.add("-debug");
}
@@ -822,10 +822,10 @@ public abstract class BaseTest {
return lines[0].substring(prefix.length(),lines[0].length());
}

-	public List realElements(List elements) {
-		List n = new ArrayList();
+	public <T> List<T> realElements(List<T> elements) {
+		List<T> n = new ArrayList<T>();
for (int i = Label.NUM_FAUX_LABELS+Label.MIN_TOKEN_TYPE - 1; i < elements.size(); i++) {
-			Object o = (Object) elements.get(i);
+			T o = elements.get(i);
if ( o!=null ) {
n.add(o);
}
@@ -834,8 +834,8 @@ public abstract class BaseTest {
}

public List<String> realElements(Map<String, Integer> elements) {
-		List n = new ArrayList();
-		Iterator iterator = elements.keySet().iterator();
+		List<String> n = new ArrayList<String>();
+		Iterator<String> iterator = elements.keySet().iterator();
while (iterator.hasNext()) {
String tokenID = (String) iterator.next();
if ( elements.get(tokenID) >= Label.MIN_TOKEN_TYPE ) {
@@ -869,7 +869,7 @@ public abstract class BaseTest {
* @param m The Map that contains keys we wish to return in sorted order
* @return A string that represents all the keys in sorted order.
*/
-    public String sortMapToString(Map m) {
+    public <K, V> String sortMapToString(Map<K, V> m) {

System.out.println("Map toString looks like: " + m.toString());
// Pass in crap, and get nothing back
@@ -880,7 +880,7 @@ public abstract class BaseTest {

// Sort the keys in the Map
//
-        TreeMap nset = new TreeMap(m);
+        TreeMap<K, V> nset = new TreeMap<K, V>(m);

System.out.println("Tree map looks like: " + nset.toString());
return nset.toString();
diff --git a/tool/src/test/java/org/antlr/test/ErrorQueue.java b/tool/src/test/java/org/antlr/test/ErrorQueue.java
index 380893a..8546f3c 100644
--- a/tool/src/test/java/org/antlr/test/ErrorQueue.java
+++ b/tool/src/test/java/org/antlr/test/ErrorQueue.java
@@ -35,9 +35,9 @@ import java.util.LinkedList;
import java.util.List;

public class ErrorQueue implements ANTLRErrorListener {
-	List infos = new LinkedList();
-	List errors = new LinkedList();
-	List warnings = new LinkedList();
+	List<String> infos = new LinkedList<String>();
+	List<Message> errors = new LinkedList<Message>();
+	List<Message> warnings = new LinkedList<Message>();

@Override
public void info(String msg) {
diff --git a/tool/src/test/java/org/antlr/test/TestAttributes.java b/tool/src/test/java/org/antlr/test/TestAttributes.java
index a94ce41..b272237 100644
--- a/tool/src/test/java/org/antlr/test/TestAttributes.java
+++ b/tool/src/test/java/org/antlr/test/TestAttributes.java
@@ -2196,7 +2196,7 @@ public class TestAttributes extends BaseTest {

Rule r = g.getRule("r");
AttributeScope retScope = r.returnScope;
-		List parameters = retScope.getAttributes();
+		List<Attribute> parameters = retScope.getAttributes();
assertNotNull("missing return action", parameters);
assertEquals(1, parameters.size());
String found = parameters.get(0).toString();
@@ -2215,7 +2215,7 @@ public class TestAttributes extends BaseTest {

Rule r = g.getRule("r");
AttributeScope retScope = r.returnScope;
-		List parameters = retScope.getAttributes();
+		List<Attribute> parameters = retScope.getAttributes();
assertNotNull("missing return action", parameters);
assertEquals(3, parameters.size());
assertEquals("int x=0", parameters.get(0).toString());
@@ -2234,7 +2234,7 @@ public class TestAttributes extends BaseTest {

Rule r = g.getRule("r");
AttributeScope retScope = r.returnScope;
-		List parameters = retScope.getAttributes();
+		List<Attribute> parameters = retScope.getAttributes();
assertNotNull("missing return action", parameters);
assertEquals(1, parameters.size());
String found = parameters.get(0).toString();
@@ -2801,7 +2801,7 @@ public class TestAttributes extends BaseTest {
translator.translate();

int expectedMsgID = ErrorManager.MSG_WRITE_TO_READONLY_ATTR;
-		ArrayList expectedErrors = new ArrayList(3);
+		ArrayList<Message> expectedErrors = new ArrayList<Message>(3);
GrammarSemanticsMessage expectedMessage =
new GrammarSemanticsMessage(expectedMsgID, g, null, "start", "");
expectedErrors.add(expectedMessage);
@@ -3093,10 +3093,10 @@ public class TestAttributes extends BaseTest {

/** Allow checking for multiple errors in one test */
protected void checkErrors(ErrorQueue equeue,
-							   ArrayList expectedMessages)
+							   ArrayList<Message> expectedMessages)
throws Exception
{
-		ArrayList messageExpected = new ArrayList(equeue.errors.size());
+		ArrayList<Boolean> messageExpected = new ArrayList<Boolean>(equeue.errors.size());
for (int i = 0; i < equeue.errors.size(); i++) {
Message m = (Message)equeue.errors.get(i);
boolean foundMsg = false;
diff --git a/tool/src/test/java/org/antlr/test/TestCharDFAConversion.java b/tool/src/test/java/org/antlr/test/TestCharDFAConversion.java
index 4e65816..3768a7d 100644
--- a/tool/src/test/java/org/antlr/test/TestCharDFAConversion.java
+++ b/tool/src/test/java/org/antlr/test/TestCharDFAConversion.java
@@ -526,7 +526,7 @@ public class TestCharDFAConversion extends BaseTest {
FASerializer serializer = new FASerializer(g);
String result = serializer.serialize(dfa.startState);
//System.out.print(result);
-		List nonDetAlts = dfa.getUnreachableAlts();
+		List<Integer> nonDetAlts = dfa.getUnreachableAlts();
//System.out.println("alts w/o predict state="+nonDetAlts);

// first make sure nondeterministic alts are as expected
diff --git a/tool/src/test/java/org/antlr/test/TestDFAConversion.java b/tool/src/test/java/org/antlr/test/TestDFAConversion.java
index 387b328..b4978ad 100644
--- a/tool/src/test/java/org/antlr/test/TestDFAConversion.java
+++ b/tool/src/test/java/org/antlr/test/TestDFAConversion.java
@@ -30,6 +30,7 @@ package org.antlr.test;
import org.antlr.Tool;
import org.antlr.analysis.DFA;
import org.antlr.analysis.DecisionProbe;
+import org.antlr.analysis.Label;
import org.antlr.codegen.CodeGenerator;
import org.antlr.misc.BitSet;
import org.antlr.tool.*;
@@ -93,7 +94,7 @@ public class TestDFAConversion extends BaseTest {
"parser grammar t;\n"+
"s : a ;\n" +
"a : A a X | A a Y;");
-		List altsWithRecursion = Arrays.asList(new Object[] {1,2});
+		List<Integer> altsWithRecursion = Arrays.asList(1, 2);
assertNonLLStar(g, altsWithRecursion);
}

@@ -102,7 +103,7 @@ public class TestDFAConversion extends BaseTest {
"parser grammar t;\n"+
"s : a Y | A A A A A X ;\n" + // force recursion past m=4
"a : A a | Q;");
-		List expectedTargetRules = Arrays.asList(new Object[] {"a"});
+		List<String> expectedTargetRules = Arrays.asList("a");
int expectedAlt = 1;
assertRecursionOverflow(g, expectedTargetRules, expectedAlt);
}
@@ -112,7 +113,7 @@ public class TestDFAConversion extends BaseTest {
"parser grammar t;\n"+
"s : a Y | A+ X ;\n" + // force recursion past m=4
"a : A a | Q;");
-		List expectedTargetRules = Arrays.asList(new Object[] {"a"});
+		List<String> expectedTargetRules = Arrays.asList("a");
int expectedAlt = 1;
assertRecursionOverflow(g, expectedTargetRules, expectedAlt);
}
@@ -184,7 +185,7 @@ public class TestDFAConversion extends BaseTest {
"y   : L y R\n" +
"    | B\n" +
"    ;");
-		List altsWithRecursion = Arrays.asList(new Object[] {1,2});
+		List<Integer> altsWithRecursion = Arrays.asList(1, 2);
assertNonLLStar(g, altsWithRecursion);
}

@@ -550,8 +551,8 @@ public class TestDFAConversion extends BaseTest {
ErrorManager.setErrorListener(equeue);

Set<Rule> leftRecursive = g.getLeftRecursiveRules();
-		Set expectedRules =
-			new HashSet() {{add("a"); add("b");}};
+		Set<String> expectedRules =
+			new HashSet<String>() {{add("a"); add("b");}};
assertEquals(expectedRules, ruleNames(leftRecursive));

assertEquals(1, equeue.errors.size());
@@ -561,8 +562,8 @@ public class TestDFAConversion extends BaseTest {
LeftRecursionCyclesMessage cyclesMsg = (LeftRecursionCyclesMessage)msg;

// cycle of [a, b]
-		Collection result = cyclesMsg.cycles;
-		Set expecting = new HashSet() {{add("a"); add("b");}};
+		Collection<? extends Collection<? extends Rule>> result = cyclesMsg.cycles;
+		Set<String> expecting = new HashSet<String>() {{add("a"); add("b");}};
assertEquals(expecting, ruleNames2(result));
}

@@ -578,9 +579,9 @@ public class TestDFAConversion extends BaseTest {
ErrorQueue equeue = new ErrorQueue();
ErrorManager.setErrorListener(equeue);

-		Set leftRecursive = g.getLeftRecursiveRules();
-		Set expectedRules =
-			new HashSet() {{add("a"); add("b");}};
+		Set<Rule> leftRecursive = g.getLeftRecursiveRules();
+		Set<String> expectedRules =
+			new HashSet<String>() {{add("a"); add("b");}};
assertEquals(expectedRules, ruleNames(leftRecursive));

assertEquals(1, equeue.errors.size());
@@ -590,8 +591,8 @@ public class TestDFAConversion extends BaseTest {
LeftRecursionCyclesMessage cyclesMsg = (LeftRecursionCyclesMessage)msg;

// cycle of [a, b]
-		Collection result = cyclesMsg.cycles;
-		Set expecting = new HashSet() {{add("a"); add("b");}};
+		Collection<? extends Collection<? extends Rule>> result = cyclesMsg.cycles;
+		Set<String> expecting = new HashSet<String>() {{add("a"); add("b");}};
assertEquals(expecting, ruleNames2(result));
}

@@ -609,9 +610,9 @@ public class TestDFAConversion extends BaseTest {
ErrorQueue equeue = new ErrorQueue();
ErrorManager.setErrorListener(equeue);

-		Set leftRecursive = g.getLeftRecursiveRules();
-		Set expectedRules =
-			new HashSet() {{add("a"); add("b"); add("e"); add("d");}};
+		Set<Rule> leftRecursive = g.getLeftRecursiveRules();
+		Set<String> expectedRules =
+			new HashSet<String>() {{add("a"); add("b"); add("e"); add("d");}};
assertEquals(expectedRules, ruleNames(leftRecursive));

assertEquals(1, equeue.errors.size());
@@ -621,8 +622,8 @@ public class TestDFAConversion extends BaseTest {
LeftRecursionCyclesMessage cyclesMsg = (LeftRecursionCyclesMessage)msg;

// cycle of [a, b]
-		Collection result = cyclesMsg.cycles;
-		Set expecting = new HashSet() {{add("a"); add("b"); add("d"); add("e");}};
+		Collection<? extends Collection<? extends Rule>> result = cyclesMsg.cycles;
+		Set<String> expecting = new HashSet<String>() {{add("a"); add("b"); add("d"); add("e");}};
assertEquals(expecting, ruleNames2(result));
}

@@ -787,8 +788,8 @@ public class TestDFAConversion extends BaseTest {
"parser grammar t;\n"+
"s : a ;\n" +
"a : a A | B;");
-		Set leftRecursive = g.getLeftRecursiveRules();
-		Set expectedRules = new HashSet() {{add("a");}};
+		Set<Rule> leftRecursive = g.getLeftRecursiveRules();
+		Set<String> expectedRules = new HashSet<String>() {{add("a");}};
assertEquals(expectedRules, ruleNames(leftRecursive));
}

@@ -799,8 +800,8 @@ public class TestDFAConversion extends BaseTest {
"a : b | A ;\n" +
"b : c ;\n" +
"c : a | C ;\n");
-		Set leftRecursive = g.getLeftRecursiveRules();
-		Set expectedRules = new HashSet() {{add("a"); add("b"); add("c");}};
+		Set<Rule> leftRecursive = g.getLeftRecursiveRules();
+		Set<String> expectedRules = new HashSet<String>() {{add("a"); add("b"); add("c");}};
assertEquals(expectedRules, ruleNames(leftRecursive));
}

@@ -813,9 +814,9 @@ public class TestDFAConversion extends BaseTest {
"c : a | C ;\n" +
"x : y | X ;\n" +
"y : x ;\n");
-		Set leftRecursive = g.getLeftRecursiveRules();
-		Set expectedRules =
-			new HashSet() {{add("a"); add("b"); add("c"); add("x"); add("y");}};
+		Set<Rule> leftRecursive = g.getLeftRecursiveRules();
+		Set<String> expectedRules =
+			new HashSet<String>() {{add("a"); add("b"); add("c"); add("x"); add("y");}};
assertEquals(expectedRules, ruleNames(leftRecursive));
}

@@ -826,8 +827,8 @@ public class TestDFAConversion extends BaseTest {
"a : (A|)+ B;\n");
// before I added a visitedStates thing, it was possible to loop
// forever inside of a rule if there was an epsilon loop.
-		Set leftRecursive = g.getLeftRecursiveRules();
-		Set expectedRules = new HashSet();
+		Set<Rule> leftRecursive = g.getLeftRecursiveRules();
+		Set<Rule> expectedRules = new HashSet<Rule>();
assertEquals(expectedRules, leftRecursive);
}

@@ -1352,7 +1353,7 @@ As a result, alternative(s) 2 were disabled for that input
"b : A\n" +
"  | A b\n" +
"  ;\n");
-		List altsWithRecursion = Arrays.asList(new Object[] {1,2});
+		List<Integer> altsWithRecursion = Arrays.asList(1, 2);
assertNonLLStar(g, altsWithRecursion);
}

@@ -1492,7 +1493,7 @@ As a result, alternative(s) 2 were disabled for that input
"y   : L y R\n" +
"    | B\n" +
"    ;");
-		List altsWithRecursion = Arrays.asList(new Object[] {1,2});
+		List<Integer> altsWithRecursion = Arrays.asList(1, 2);
assertNonLLStar(g, altsWithRecursion);
}

@@ -1501,7 +1502,7 @@ As a result, alternative(s) 2 were disabled for that input
"parser grammar t;\n"+
"s : (options {greedy=true;} : a Y | A A A A A X) ;\n" + // force recursion past m=4
"a : A a | Q;");
-		List expectedTargetRules = Arrays.asList(new Object[] {"a"});
+		List<String> expectedTargetRules = Arrays.asList("a");
int expectedAlt = 1;
assertRecursionOverflow(g, expectedTargetRules, expectedAlt);
}
@@ -1530,7 +1531,7 @@ As a result, alternative(s) 2 were disabled for that input
checkDecision(g, 1, expecting, null, null, null, null, 0);
}

-	protected void assertNonLLStar(Grammar g, List expectedBadAlts) {
+	protected void assertNonLLStar(Grammar g, List<Integer> expectedBadAlts) {
DecisionProbe.verbose=true; // make sure we get all error info
ErrorQueue equeue = new ErrorQueue();
ErrorManager.setErrorListener(equeue);
@@ -1542,14 +1543,14 @@ As a result, alternative(s) 2 were disabled for that input
}
NonRegularDecisionMessage msg = getNonRegularDecisionMessage(equeue.errors);
assertTrue("expected fatal non-LL(*) msg", msg!=null);
-		List<Integer> alts = new ArrayList();
+		List<Integer> alts = new ArrayList<Integer>();
alts.addAll(msg.altsWithRecursion);
Collections.sort(alts);
assertEquals(expectedBadAlts,alts);
}

protected void assertRecursionOverflow(Grammar g,
-										   List expectedTargetRules,
+										   List<String> expectedTargetRules,
int expectedAlt) {
DecisionProbe.verbose=true; // make sure we get all error info
ErrorQueue equeue = new ErrorQueue();
@@ -1642,7 +1643,7 @@ As a result, alternative(s) 2 were disabled for that input
FASerializer serializer = new FASerializer(g);
String result = serializer.serialize(dfa.startState);

-		List unreachableAlts = dfa.getUnreachableAlts();
+		List<Integer> unreachableAlts = dfa.getUnreachableAlts();

// make sure unreachable alts are as expected
if ( expectingUnreachableAlts!=null ) {
@@ -1665,7 +1666,7 @@ As a result, alternative(s) 2 were disabled for that input
msg instanceof GrammarNonDeterminismMessage);
GrammarNonDeterminismMessage nondetMsg =
getNonDeterminismMessage(equeue.warnings);
-			List labels =
+			List<Label> labels =
nondetMsg.probe.getSampleNonDeterministicInputSequence(nondetMsg.problemState);
String input = nondetMsg.probe.getInputSequenceDisplay(labels);
assertEquals(expectingAmbigInput, input);
@@ -1676,7 +1677,7 @@ As a result, alternative(s) 2 were disabled for that input
RecursionOverflowMessage recMsg = null;
GrammarNonDeterminismMessage nondetMsg =
getNonDeterminismMessage(equeue.warnings);
-			List nonDetAlts = null;
+			List<Integer> nonDetAlts = null;
if ( nondetMsg!=null ) {
nonDetAlts =
nondetMsg.probe.getNonDeterministicAltsForState(nondetMsg.problemState);
@@ -1707,7 +1708,7 @@ As a result, alternative(s) 2 were disabled for that input
assertEquals(expecting, result);
}

-	protected GrammarNonDeterminismMessage getNonDeterminismMessage(List warnings) {
+	protected GrammarNonDeterminismMessage getNonDeterminismMessage(List<Message> warnings) {
for (int i = 0; i < warnings.size(); i++) {
Message m = (Message) warnings.get(i);
if ( m instanceof GrammarNonDeterminismMessage ) {
@@ -1717,7 +1718,7 @@ As a result, alternative(s) 2 were disabled for that input
return null;
}

-	protected NonRegularDecisionMessage getNonRegularDecisionMessage(List errors) {
+	protected NonRegularDecisionMessage getNonRegularDecisionMessage(List<Message> errors) {
for (int i = 0; i < errors.size(); i++) {
Message m = (Message) errors.get(i);
if ( m instanceof NonRegularDecisionMessage ) {
@@ -1727,7 +1728,7 @@ As a result, alternative(s) 2 were disabled for that input
return null;
}

-	protected RecursionOverflowMessage getRecursionOverflowMessage(List warnings) {
+	protected RecursionOverflowMessage getRecursionOverflowMessage(List<Message> warnings) {
for (int i = 0; i < warnings.size(); i++) {
Message m = (Message) warnings.get(i);
if ( m instanceof RecursionOverflowMessage ) {
@@ -1737,7 +1738,7 @@ As a result, alternative(s) 2 were disabled for that input
return null;
}

-	protected LeftRecursionCyclesMessage getLeftRecursionCyclesMessage(List warnings) {
+	protected LeftRecursionCyclesMessage getLeftRecursionCyclesMessage(List<Message> warnings) {
for (int i = 0; i < warnings.size(); i++) {
Message m = (Message) warnings.get(i);
if ( m instanceof LeftRecursionCyclesMessage ) {
@@ -1747,7 +1748,7 @@ As a result, alternative(s) 2 were disabled for that input
return null;
}

-	protected GrammarDanglingStateMessage getDanglingStateMessage(List warnings) {
+	protected GrammarDanglingStateMessage getDanglingStateMessage(List<Message> warnings) {
for (int i = 0; i < warnings.size(); i++) {
Message m = (Message) warnings.get(i);
if ( m instanceof GrammarDanglingStateMessage ) {
@@ -1769,7 +1770,7 @@ As a result, alternative(s) 2 were disabled for that input
return buf.toString();
}

-	protected Set<String> ruleNames(Set<Rule> rules) {
+	protected Set<String> ruleNames(Collection<? extends Rule> rules) {
Set<String> x = new HashSet<String>();
for (Rule r : rules) {
x.add(r.name);
@@ -1777,9 +1778,9 @@ As a result, alternative(s) 2 were disabled for that input
return x;
}

-	protected Set<String> ruleNames2(Collection<HashSet> rules) {
+	protected Set<String> ruleNames2(Collection<? extends Collection<? extends Rule>> rules) {
Set<String> x = new HashSet<String>();
-		for (HashSet s : rules) {
+		for (Collection<? extends Rule> s : rules) {
x.addAll(ruleNames(s));
}
return x;
diff --git a/tool/src/test/java/org/antlr/test/TestIntervalSet.java b/tool/src/test/java/org/antlr/test/TestIntervalSet.java
index 9acc37f..2a3cd84 100644
--- a/tool/src/test/java/org/antlr/test/TestIntervalSet.java
+++ b/tool/src/test/java/org/antlr/test/TestIntervalSet.java
@@ -367,7 +367,6 @@ public class TestIntervalSet extends BaseTest {
s.add(50,55);
s.add(5,5);
String expecting = "[5, 20, 21, 22, 23, 24, 25, 50, 51, 52, 53, 54, 55]";
-		List foo = new ArrayList();
String result = String.valueOf(s.toList());
assertEquals(result, expecting);
}
diff --git a/tool/src/test/java/org/antlr/test/TestSemanticPredicates.java b/tool/src/test/java/org/antlr/test/TestSemanticPredicates.java
index f1598b4..1a900b7 100644
--- a/tool/src/test/java/org/antlr/test/TestSemanticPredicates.java
+++ b/tool/src/test/java/org/antlr/test/TestSemanticPredicates.java
@@ -29,6 +29,7 @@ package org.antlr.test;

import org.antlr.analysis.DFA;
import org.antlr.analysis.DecisionProbe;
+import org.antlr.analysis.Label;
import org.antlr.codegen.CodeGenerator;
import org.antlr.misc.BitSet;
import org.antlr.runtime.Token;
@@ -816,7 +817,7 @@ public class TestSemanticPredicates extends BaseTest {
FASerializer serializer = new FASerializer(g);
String result = serializer.serialize(dfa.startState);
//System.out.print(result);
-		List unreachableAlts = dfa.getUnreachableAlts();
+		List<Integer> unreachableAlts = dfa.getUnreachableAlts();

// make sure unreachable alts are as expected
if ( expectingUnreachableAlts!=null ) {
@@ -840,7 +841,7 @@ public class TestSemanticPredicates extends BaseTest {
msg instanceof GrammarNonDeterminismMessage);
GrammarNonDeterminismMessage nondetMsg =
getNonDeterminismMessage(equeue.warnings);
-			List labels =
+			List<Label> labels =
nondetMsg.probe.getSampleNonDeterministicInputSequence(nondetMsg.problemState);
String input = nondetMsg.probe.getInputSequenceDisplay(labels);
assertEquals(expectingAmbigInput, input);
@@ -852,7 +853,7 @@ public class TestSemanticPredicates extends BaseTest {
getNonDeterminismMessage(equeue.warnings);
assertNotNull("found no nondet alts; expecting: "+
str(expectingNonDetAlts), nondetMsg);
-			List nonDetAlts =
+			List<Integer> nonDetAlts =
nondetMsg.probe.getNonDeterministicAltsForState(nondetMsg.problemState);
// compare nonDetAlts with expectingNonDetAlts
BitSet s = new BitSet();
@@ -876,7 +877,7 @@ public class TestSemanticPredicates extends BaseTest {
assertNotNull("found no GrammarInsufficientPredicatesMessage alts; expecting: "+
str(expectingNonDetAlts), insuffPredMsg);
Map<Integer, Set<Token>> locations = insuffPredMsg.altToLocations;
-			Set actualAlts = locations.keySet();
+			Set<Integer> actualAlts = locations.keySet();
BitSet s = new BitSet();
s.addAll(expectingInsufficientPredAlts);
BitSet s2 = new BitSet();
@@ -898,7 +899,7 @@ public class TestSemanticPredicates extends BaseTest {
assertEquals(expecting, result);
}

-	protected GrammarNonDeterminismMessage getNonDeterminismMessage(List warnings) {
+	protected GrammarNonDeterminismMessage getNonDeterminismMessage(List<? extends Message> warnings) {
for (int i = 0; i < warnings.size(); i++) {
Message m = (Message) warnings.get(i);
if ( m instanceof GrammarNonDeterminismMessage ) {
@@ -908,7 +909,7 @@ public class TestSemanticPredicates extends BaseTest {
return null;
}

-	protected GrammarInsufficientPredicatesMessage getGrammarInsufficientPredicatesMessage(List warnings) {
+	protected GrammarInsufficientPredicatesMessage getGrammarInsufficientPredicatesMessage(List<? extends Message> warnings) {
for (int i = 0; i < warnings.size(); i++) {
Message m = (Message) warnings.get(i);
if ( m instanceof GrammarInsufficientPredicatesMessage ) {
diff --git a/tool/src/test/java/org/antlr/test/TestSymbolDefinitions.java b/tool/src/test/java/org/antlr/test/TestSymbolDefinitions.java
index dcf87b9..ee5d3ed 100644
--- a/tool/src/test/java/org/antlr/test/TestSymbolDefinitions.java
+++ b/tool/src/test/java/org/antlr/test/TestSymbolDefinitions.java
@@ -176,7 +176,7 @@ public class TestSymbolDefinitions extends BaseTest {
Grammar g = new Grammar(
"grammar t;\n"+
"a : '\\n';\n");
-		Set literals = g.getStringLiterals();
+		Set<String> literals = g.getStringLiterals();
// must store literals how they appear in the antlr grammar
assertEquals("'\\n'", literals.toArray()[0]);
}
@@ -842,18 +842,18 @@ public class TestSymbolDefinitions extends BaseTest {
// make sure expected += labels are there
Rule r = g.getRule(ruleName);
StringTokenizer st = new StringTokenizer(tokenLabelsStr, ", ");
-		Set tokenLabels = null;
+		Set<String> tokenLabels = null;
while ( st.hasMoreTokens() ) {
if ( tokenLabels==null ) {
-				tokenLabels = new HashSet();
+				tokenLabels = new HashSet<String>();
}
String labelName = st.nextToken();
tokenLabels.add(labelName);
}
-		Set ruleLabels = null;
+		Set<String> ruleLabels = null;
if ( ruleLabelsStr!=null ) {
st = new StringTokenizer(ruleLabelsStr, ", ");
-			ruleLabels = new HashSet();
+			ruleLabels = new HashSet<String>();
while ( st.hasMoreTokens() ) {
String labelName = st.nextToken();
ruleLabels.add(labelName);
@@ -878,7 +878,7 @@ public class TestSymbolDefinitions extends BaseTest {
String tokensStr)
throws Exception
{
-		Set tokens = g.getTokenDisplayNames();
+		Set<String> tokens = g.getTokenDisplayNames();

// make sure expected tokens are there
StringTokenizer st = new StringTokenizer(tokensStr, ", ");
@@ -889,7 +889,7 @@ public class TestSymbolDefinitions extends BaseTest {
tokens.remove(tokenName);
}
// make sure there are not any others (other than <EOF> etc...)
-		for (Iterator iter = tokens.iterator(); iter.hasNext();) {
+		for (Iterator<String> iter = tokens.iterator(); iter.hasNext();) {
String tokenName = (String) iter.next();
assertTrue("unexpected token name "+tokenName,
g.getTokenType(tokenName)<Label.MIN_TOKEN_TYPE);
@@ -903,7 +903,7 @@ public class TestSymbolDefinitions extends BaseTest {
assertNotNull("rule "+ruleName+" expected", g.getRule(ruleName));
n++;
}
-		Collection rules = g.getRules();
+		Collection<Rule> rules = g.getRules();
//System.out.println("rules="+rules);
// make sure there are no extra rules
assertEquals("number of rules mismatch; expecting "+n+"; found "+rules.size(), n, rules.size());
diff --git a/tool/src/test/java/org/antlr/test/TestTopologicalSort.java b/tool/src/test/java/org/antlr/test/TestTopologicalSort.java
index 43ffbee..1a1455f 100644
--- a/tool/src/test/java/org/antlr/test/TestTopologicalSort.java
+++ b/tool/src/test/java/org/antlr/test/TestTopologicalSort.java
@@ -36,7 +36,7 @@ import java.util.List;
public class TestTopologicalSort extends BaseTest {
@Test
public void testFairlyLargeGraph() throws Exception {
-        Graph g = new Graph();
+        Graph<String> g = new Graph<String>();
g.addEdge("C", "F");
g.addEdge("C", "G");
g.addEdge("C", "A");
@@ -50,63 +50,63 @@ public class TestTopologicalSort extends BaseTest {
g.addEdge("E", "F");

String expecting = "[H, F, E, D, G, A, B, C]";
-        List nodes = g.sort();
+        List<String> nodes = g.sort();
String result = nodes.toString();
assertEquals(expecting, result);
}

@Test
public void testCyclicGraph() throws Exception {
-        Graph g = new Graph();
+        Graph<String> g = new Graph<String>();
g.addEdge("A", "B");
g.addEdge("B", "C");
g.addEdge("C", "A");
g.addEdge("C", "D");

String expecting = "[D, C, B, A]";
-        List nodes = g.sort();
+        List<String> nodes = g.sort();
String result = nodes.toString();
assertEquals(expecting, result);
}

@Test
public void testRepeatedEdges() throws Exception {
-        Graph g = new Graph();
+        Graph<String> g = new Graph<String>();
g.addEdge("A", "B");
g.addEdge("B", "C");
g.addEdge("A", "B"); // dup
g.addEdge("C", "D");

String expecting = "[D, C, B, A]";
-        List nodes = g.sort();
+        List<String> nodes = g.sort();
String result = nodes.toString();
assertEquals(expecting, result);
}

@Test
public void testSimpleTokenDependence() throws Exception {
-        Graph g = new Graph();
+        Graph<String> g = new Graph<String>();
g.addEdge("Java.g", "MyJava.tokens"); // Java feeds off manual token file
g.addEdge("Java.tokens", "Java.g");
g.addEdge("Def.g", "Java.tokens");    // walkers feed off generated tokens
g.addEdge("Ref.g", "Java.tokens");

String expecting = "[MyJava.tokens, Java.g, Java.tokens, Ref.g, Def.g]";
-        List nodes = g.sort();
+        List<String> nodes = g.sort();
String result = nodes.toString();
assertEquals(expecting, result);
}

@Test
public void testParserLexerCombo() throws Exception {
-        Graph g = new Graph();
+        Graph<String> g = new Graph<String>();
g.addEdge("JavaLexer.tokens", "JavaLexer.g");
g.addEdge("JavaParser.g", "JavaLexer.tokens");
g.addEdge("Def.g", "JavaLexer.tokens");
g.addEdge("Ref.g", "JavaLexer.tokens");

String expecting = "[JavaLexer.g, JavaLexer.tokens, JavaParser.g, Ref.g, Def.g]";
-        List nodes = g.sort();
+        List<String> nodes = g.sort();
String result = nodes.toString();
assertEquals(expecting, result);
}
diff --git a/tool/src/test/java/org/antlr/test/TestTreeWizard.java b/tool/src/test/java/org/antlr/test/TestTreeWizard.java
index 50b3d62..2e390be 100644
--- a/tool/src/test/java/org/antlr/test/TestTreeWizard.java
+++ b/tool/src/test/java/org/antlr/test/TestTreeWizard.java
@@ -101,7 +101,7 @@ public class TestTreeWizard extends BaseTest {
@Test public void testSingleNodeIndex() throws Exception {
TreeWizard wiz = new TreeWizard(adaptor, tokens);
CommonTree t = (CommonTree)wiz.create("ID");
-		Map m = wiz.index(t);
+		Map<Integer, List<Object>> m = wiz.index(t);
String found = m.toString();
String expecting = "{10=[ID]}";
assertEquals(expecting, found);
@@ -110,7 +110,7 @@ public class TestTreeWizard extends BaseTest {
@Test public void testNoRepeatsIndex() throws Exception {
TreeWizard wiz = new TreeWizard(adaptor, tokens);
CommonTree t = (CommonTree)wiz.create("(A B C D)");
-		Map m = wiz.index(t);
+		Map<Integer, List<Object>> m = wiz.index(t);
String found = sortMapToString(m);
String expecting = "{5=[A], 6=[B], 7=[C], 8=[D]}";
assertEquals(expecting, found);
@@ -119,7 +119,7 @@ public class TestTreeWizard extends BaseTest {
@Test public void testRepeatsIndex() throws Exception {
TreeWizard wiz = new TreeWizard(adaptor, tokens);
CommonTree t = (CommonTree)wiz.create("(A B (A C B) B D D)");
-		Map m = wiz.index(t);
+		Map<Integer, List<Object>> m = wiz.index(t);
String found =  sortMapToString(m);
String expecting = "{5=[A, A], 6=[B, B, B], 7=[C], 8=[D, D]}";
assertEquals(expecting, found);
@@ -128,7 +128,7 @@ public class TestTreeWizard extends BaseTest {
@Test public void testNoRepeatsVisit() throws Exception {
TreeWizard wiz = new TreeWizard(adaptor, tokens);
CommonTree t = (CommonTree)wiz.create("(A B C D)");
-		final List elements = new ArrayList();
+		final List<Object> elements = new ArrayList<Object>();
wiz.visit(t, wiz.getTokenType("B"), new TreeWizard.Visitor() {
@Override
public void visit(Object t) {
@@ -143,7 +143,7 @@ public class TestTreeWizard extends BaseTest {
@Test public void testNoRepeatsVisit2() throws Exception {
TreeWizard wiz = new TreeWizard(adaptor, tokens);
CommonTree t = (CommonTree)wiz.create("(A B (A C B) B D D)");
-		final List elements = new ArrayList();
+		final List<Object> elements = new ArrayList<Object>();
wiz.visit(t, wiz.getTokenType("C"),
new TreeWizard.Visitor() {
@Override
@@ -159,7 +159,7 @@ public class TestTreeWizard extends BaseTest {
@Test public void testRepeatsVisit() throws Exception {
TreeWizard wiz = new TreeWizard(adaptor, tokens);
CommonTree t = (CommonTree)wiz.create("(A B (A C B) B D D)");
-		final List elements = new ArrayList();
+		final List<Object> elements = new ArrayList<Object>();
wiz.visit(t, wiz.getTokenType("B"),
new TreeWizard.Visitor() {
@Override
@@ -175,7 +175,7 @@ public class TestTreeWizard extends BaseTest {
@Test public void testRepeatsVisit2() throws Exception {
TreeWizard wiz = new TreeWizard(adaptor, tokens);
CommonTree t = (CommonTree)wiz.create("(A B (A C B) B D D)");
-		final List elements = new ArrayList();
+		final List<Object> elements = new ArrayList<Object>();
wiz.visit(t, wiz.getTokenType("A"),
new TreeWizard.Visitor() {
@Override
@@ -191,11 +191,11 @@ public class TestTreeWizard extends BaseTest {
@Test public void testRepeatsVisitWithContext() throws Exception {
TreeWizard wiz = new TreeWizard(adaptor, tokens);
CommonTree t = (CommonTree)wiz.create("(A B (A C B) B D D)");
-		final List elements = new ArrayList();
+		final List<String> elements = new ArrayList<String>();
wiz.visit(t, wiz.getTokenType("B"),
new TreeWizard.ContextVisitor() {
@Override
-			   public void visit(Object t, Object parent, int childIndex, Map labels) {
+			   public void visit(Object t, Object parent, int childIndex, Map<String, Object> labels) {
elements.add(adaptor.getText(t)+"@"+
(parent!=null?adaptor.getText(parent):"nil")+
"["+childIndex+"]");
@@ -209,11 +209,11 @@ public class TestTreeWizard extends BaseTest {
@Test public void testRepeatsVisitWithNullParentAndContext() throws Exception {
TreeWizard wiz = new TreeWizard(adaptor, tokens);
CommonTree t = (CommonTree)wiz.create("(A B (A C B) B D D)");
-		final List elements = new ArrayList();
+		final List<String> elements = new ArrayList<String>();
wiz.visit(t, wiz.getTokenType("A"),
new TreeWizard.ContextVisitor() {
@Override
-			   public void visit(Object t, Object parent, int childIndex, Map labels) {
+			   public void visit(Object t, Object parent, int childIndex, Map<String, Object> labels) {
elements.add(adaptor.getText(t)+"@"+
(parent!=null?adaptor.getText(parent):"nil")+
"["+childIndex+"]");
@@ -227,7 +227,7 @@ public class TestTreeWizard extends BaseTest {
@Test public void testVisitPattern() throws Exception {
TreeWizard wiz = new TreeWizard(adaptor, tokens);
CommonTree t = (CommonTree)wiz.create("(A B C (A B) D)");
-		final List elements = new ArrayList();
+		final List<Object> elements = new ArrayList<Object>();
wiz.visit(t, "(A B)",
new TreeWizard.Visitor() {
@Override
@@ -243,11 +243,11 @@ public class TestTreeWizard extends BaseTest {
@Test public void testVisitPatternMultiple() throws Exception {
TreeWizard wiz = new TreeWizard(adaptor, tokens);
CommonTree t = (CommonTree)wiz.create("(A B C (A B) (D (A B)))");
-		final List elements = new ArrayList();
+		final List<String> elements = new ArrayList<String>();
wiz.visit(t, "(A B)",
new TreeWizard.ContextVisitor() {
@Override
-						   public void visit(Object t, Object parent, int childIndex, Map labels) {
+						   public void visit(Object t, Object parent, int childIndex, Map<String, Object> labels) {
elements.add(adaptor.getText(t)+"@"+
(parent!=null?adaptor.getText(parent):"nil")+
"["+childIndex+"]");
@@ -261,11 +261,11 @@ public class TestTreeWizard extends BaseTest {
@Test public void testVisitPatternMultipleWithLabels() throws Exception {
TreeWizard wiz = new TreeWizard(adaptor, tokens);
CommonTree t = (CommonTree)wiz.create("(A B C (A[foo] B[bar]) (D (A[big] B[dog])))");
-		final List elements = new ArrayList();
+		final List<String> elements = new ArrayList<String>();
wiz.visit(t, "(%a:A %b:B)",
new TreeWizard.ContextVisitor() {
@Override
-						   public void visit(Object t, Object parent, int childIndex, Map labels) {
+						   public void visit(Object t, Object parent, int childIndex, Map<String, Object> labels) {
elements.add(adaptor.getText(t)+"@"+
(parent!=null?adaptor.getText(parent):"nil")+
"["+childIndex+"]"+labels.get("a")+"&"+labels.get("b"));
@@ -332,7 +332,7 @@ public class TestTreeWizard extends BaseTest {
@Test public void testParseLabels() throws Exception {
TreeWizard wiz = new TreeWizard(adaptor, tokens);
CommonTree t = (CommonTree)wiz.create("(A B C)");
-		Map labels = new HashMap();
+		Map<String, Object> labels = new HashMap<String, Object>();
boolean valid = wiz.parse(t, "(%a:A %b:B %c:C)", labels);
assertTrue(valid);
assertEquals("A", labels.get("a").toString());
@@ -343,7 +343,7 @@ public class TestTreeWizard extends BaseTest {
@Test public void testParseWithWildcardLabels() throws Exception {
TreeWizard wiz = new TreeWizard(adaptor, tokens);
CommonTree t = (CommonTree)wiz.create("(A B C)");
-		Map labels = new HashMap();
+		Map<String, Object> labels = new HashMap<String, Object>();
boolean valid = wiz.parse(t, "(A %b:. %c:.)", labels);
assertTrue(valid);
assertEquals("B", labels.get("b").toString());
@@ -353,7 +353,7 @@ public class TestTreeWizard extends BaseTest {
@Test public void testParseLabelsAndTestText() throws Exception {
TreeWizard wiz = new TreeWizard(adaptor, tokens);
CommonTree t = (CommonTree)wiz.create("(A B[foo] C)");
-		Map labels = new HashMap();
+		Map<String, Object> labels = new HashMap<String, Object>();
boolean valid = wiz.parse(t, "(%a:A %b:B[foo] %c:C)", labels);
assertTrue(valid);
assertEquals("A", labels.get("a").toString());
@@ -364,7 +364,7 @@ public class TestTreeWizard extends BaseTest {
@Test public void testParseLabelsInNestedTree() throws Exception {
TreeWizard wiz = new TreeWizard(adaptor, tokens);
CommonTree t = (CommonTree)wiz.create("(A (B C) (D E))");
-		Map labels = new HashMap();
+		Map<String, Object> labels = new HashMap<String, Object>();
boolean valid = wiz.parse(t, "(%a:A (%b:B %c:C) (%d:D %e:E) )", labels);
assertTrue(valid);
assertEquals("A", labels.get("a").toString());
@@ -401,8 +401,8 @@ public class TestTreeWizard extends BaseTest {
@Test public void testFindPattern() throws Exception {
TreeWizard wiz = new TreeWizard(adaptor, tokens);
CommonTree t = (CommonTree)wiz.create("(A B C (A[foo] B[bar]) (D (A[big] B[dog])))");
-		final List subtrees = wiz.find(t, "(A B)");
-		List elements = subtrees;
+		final List<? extends Object> subtrees = wiz.find(t, "(A B)");
+		List<? extends Object> elements = subtrees;
String found = elements.toString();
String expecting = "[foo, big]";
assertEquals(expecting, found);

