commit ed62be4ea57755fd73ad831406d9dd0177a14c30
Author:     Zannick <jokeserver@gmail.com>
AuthorDate: Sun Jun 17 22:55:13 2012 -0700
Commit:     Zannick <jokeserver@gmail.com>
CommitDate: Mon Jun 25 00:59:08 2012 -0700

Carefully update tests to Python3.

- (2to3) New exception handling syntax "except Exception as e".
- (2to3) print is a function now.
- (2to3) Don't need to cast to unicode now.
- (2to3) The StringIO module is now io.
- Grammars use Python3 as their target language.
- Use unittest assertion methods instead of bare asserts, deprecated
aliases, or fail() in a try block (where possible). This also means
we don't need to do our own diffing for error messages.
- Use with blocks instead of open(foo).read().
- Remove some dead/unused commented-out test code
(some of which was Java... o_O).
- Use ' as string delimiters when we want to include " in the string.
- Assert lists are equal to the empty list instead of asserting their
length is 0.
- Use super() instead of manual calls or super(Class, self).
- set, frozenset, and reversed are builtins in Python 3, don't need any
compatibility-related code.
- Use "if r" instead of "if r is not None" in most cases.
- Don't call encode anymore. It returns bytes, which aren't strings.
(Except for hashlib, where we do want bytes.)
- Remove some unnecessary semicolons in the grammars.
- Update required test jar files to the ones I have that I can use (with
the templates and Python3Target.class added appropriately).
- Remove unnecessary assertListEqual definition
(unittest.TestCase has one).
- Fix assert appearing in an impossible conditional in testbase.
- Attempt to fix t059debug.py.

diff --git a/runtime/Python3/tests/t001lexer.g b/runtime/Python3/tests/t001lexer.g
index f92b958..c363316 100644
--- a/runtime/Python3/tests/t001lexer.g
+++ b/runtime/Python3/tests/t001lexer.g
@@ -1,6 +1,6 @@
lexer grammar t001lexer;
options {
-  language = Python;
+  language = Python3;
}

ZERO: '0';
diff --git a/runtime/Python3/tests/t001lexer.py b/runtime/Python3/tests/t001lexer.py
index 3228235..9450e8e 100644
--- a/runtime/Python3/tests/t001lexer.py
+++ b/runtime/Python3/tests/t001lexer.py
@@ -25,10 +25,10 @@ class t001lexer(testbase.ANTLRTest):
lexer = self.getLexer(stream)

token = lexer.nextToken()
-        self.failUnlessEqual(token.type, self.lexerModule.ZERO)
+        self.assertEqual(token.type, self.lexerModule.ZERO)

token = lexer.nextToken()
-        self.failUnlessEqual(token.type, self.lexerModule.EOF)
+        self.assertEqual(token.type, self.lexerModule.EOF)


def testIteratorInterface(self):
@@ -37,7 +37,7 @@ class t001lexer(testbase.ANTLRTest):

types = [token.type for token in lexer]

-        self.failUnlessEqual(types, [self.lexerModule.ZERO])
+        self.assertEqual(types, [self.lexerModule.ZERO])


def testMalformedInput(self):
@@ -48,9 +48,9 @@ class t001lexer(testbase.ANTLRTest):
token = lexer.nextToken()
self.fail()

-        except antlr3.MismatchedTokenException, exc:
-            self.failUnlessEqual(exc.expecting, '0')
-            self.failUnlessEqual(exc.unexpectedType, '1')
+        except antlr3.MismatchedTokenException as exc:
+            self.assertEqual(exc.expecting, '0')
+            self.assertEqual(exc.unexpectedType, '1')


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t002lexer.g b/runtime/Python3/tests/t002lexer.g
index 53b67a9..f794d9b 100644
--- a/runtime/Python3/tests/t002lexer.g
+++ b/runtime/Python3/tests/t002lexer.g
@@ -1,6 +1,6 @@
lexer grammar t002lexer;
options {
-  language = Python;
+  language = Python3;
}

ZERO: '0';
diff --git a/runtime/Python3/tests/t002lexer.py b/runtime/Python3/tests/t002lexer.py
index c2c03ba..37824ba 100644
--- a/runtime/Python3/tests/t002lexer.py
+++ b/runtime/Python3/tests/t002lexer.py
@@ -25,13 +25,13 @@ class t002lexer(testbase.ANTLRTest):
lexer = self.getLexer(stream)

token = lexer.nextToken()
-        self.failUnlessEqual(token.type, self.lexerModule.ZERO)
+        self.assertEqual(token.type, self.lexerModule.ZERO)

token = lexer.nextToken()
-        self.failUnlessEqual(token.type, self.lexerModule.ONE)
+        self.assertEqual(token.type, self.lexerModule.ONE)

token = lexer.nextToken()
-        self.failUnlessEqual(token.type, self.lexerModule.EOF)
+        self.assertEqual(token.type, self.lexerModule.EOF)


def testMalformedInput(self):
@@ -42,8 +42,8 @@ class t002lexer(testbase.ANTLRTest):
token = lexer.nextToken()
self.fail()

-        except antlr3.NoViableAltException, exc:
-            self.failUnlessEqual(exc.unexpectedType, '2')
+        except antlr3.NoViableAltException as exc:
+            self.assertEqual(exc.unexpectedType, '2')


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t003lexer.g b/runtime/Python3/tests/t003lexer.g
index 0e85e11..22253d2 100644
--- a/runtime/Python3/tests/t003lexer.g
+++ b/runtime/Python3/tests/t003lexer.g
@@ -1,6 +1,6 @@
lexer grammar t003lexer;
options {
-  language = Python;
+  language = Python3;
}

ZERO: '0';
diff --git a/runtime/Python3/tests/t003lexer.py b/runtime/Python3/tests/t003lexer.py
index 3a32955..da9421f 100644
--- a/runtime/Python3/tests/t003lexer.py
+++ b/runtime/Python3/tests/t003lexer.py
@@ -25,16 +25,16 @@ class t003lexer(testbase.ANTLRTest):
lexer = self.getLexer(stream)

token = lexer.nextToken()
-        self.failUnlessEqual(token.type, self.lexerModule.ZERO)
+        self.assertEqual(token.type, self.lexerModule.ZERO)

token = lexer.nextToken()
-        self.failUnlessEqual(token.type, self.lexerModule.FOOZE)
+        self.assertEqual(token.type, self.lexerModule.FOOZE)

token = lexer.nextToken()
-        self.failUnlessEqual(token.type, self.lexerModule.ONE)
+        self.assertEqual(token.type, self.lexerModule.ONE)

token = lexer.nextToken()
-        self.failUnlessEqual(token.type, self.lexerModule.EOF)
+        self.assertEqual(token.type, self.lexerModule.EOF)


def testMalformedInput(self):
@@ -45,8 +45,8 @@ class t003lexer(testbase.ANTLRTest):
token = lexer.nextToken()
self.fail()

-        except antlr3.NoViableAltException, exc:
-            self.failUnlessEqual(exc.unexpectedType, '2')
+        except antlr3.NoViableAltException as exc:
+            self.assertEqual(exc.unexpectedType, '2')


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t004lexer.g b/runtime/Python3/tests/t004lexer.g
index c39d10d..4a08d43 100644
--- a/runtime/Python3/tests/t004lexer.g
+++ b/runtime/Python3/tests/t004lexer.g
@@ -1,6 +1,6 @@
lexer grammar t004lexer;
options {
-  language = Python;
+  language = Python3;
}

FOO: 'f' 'o'*;
diff --git a/runtime/Python3/tests/t004lexer.py b/runtime/Python3/tests/t004lexer.py
index 52b444c..633427e 100644
--- a/runtime/Python3/tests/t004lexer.py
+++ b/runtime/Python3/tests/t004lexer.py
@@ -25,31 +25,31 @@ class t004lexer(testbase.ANTLRTest):
lexer = self.getLexer(stream)

token = lexer.nextToken()
-        assert token.type == self.lexerModule.FOO
-        assert token.start == 0, token.start
-        assert token.stop == 0, token.stop
-        assert token.text == 'f', token.text
+        self.assertEqual(token.type, self.lexerModule.FOO)
+        self.assertEqual(token.start, 0)
+        self.assertEqual(token.stop, 0)
+        self.assertEqual(token.text, 'f')

token = lexer.nextToken()
-        assert token.type == self.lexerModule.FOO
-        assert token.start == 1, token.start
-        assert token.stop == 2, token.stop
-        assert token.text == 'fo', token.text
+        self.assertEqual(token.type, self.lexerModule.FOO)
+        self.assertEqual(token.start, 1)
+        self.assertEqual(token.stop, 2)
+        self.assertEqual(token.text, 'fo')

token = lexer.nextToken()
-        assert token.type == self.lexerModule.FOO
-        assert token.start == 3, token.start
-        assert token.stop == 5, token.stop
-        assert token.text == 'foo', token.text
+        self.assertEqual(token.type, self.lexerModule.FOO)
+        self.assertEqual(token.start, 3)
+        self.assertEqual(token.stop, 5)
+        self.assertEqual(token.text, 'foo')

token = lexer.nextToken()
-        assert token.type == self.lexerModule.FOO
-        assert token.start == 6, token.start
-        assert token.stop == 9, token.stop
-        assert token.text == 'fooo', token.text
+        self.assertEqual(token.type, self.lexerModule.FOO)
+        self.assertEqual(token.start, 6)
+        self.assertEqual(token.stop, 9)
+        self.assertEqual(token.text, 'fooo')

token = lexer.nextToken()
-        assert token.type == self.lexerModule.EOF
+        self.assertEqual(token.type, self.lexerModule.EOF)


def testMalformedInput(self):
@@ -60,9 +60,9 @@ class t004lexer(testbase.ANTLRTest):
token = lexer.nextToken()
self.fail()

-        except antlr3.MismatchedTokenException, exc:
-            self.failUnlessEqual(exc.expecting, 'f')
-            self.failUnlessEqual(exc.unexpectedType, '2')
+        except antlr3.MismatchedTokenException as exc:
+            self.assertEqual(exc.expecting, 'f')
+            self.assertEqual(exc.unexpectedType, '2')


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t005lexer.g b/runtime/Python3/tests/t005lexer.g
index f9cc681..247a344 100644
--- a/runtime/Python3/tests/t005lexer.g
+++ b/runtime/Python3/tests/t005lexer.g
@@ -1,6 +1,6 @@
lexer grammar t005lexer;
options {
-  language = Python;
+  language = Python3;
}

FOO: 'f' 'o'+;
diff --git a/runtime/Python3/tests/t005lexer.py b/runtime/Python3/tests/t005lexer.py
index 667083e..e5ee165 100644
--- a/runtime/Python3/tests/t005lexer.py
+++ b/runtime/Python3/tests/t005lexer.py
@@ -25,25 +25,25 @@ class t005lexer(testbase.ANTLRTest):
lexer = self.getLexer(stream)

token = lexer.nextToken()
-        assert token.type == self.lexerModule.FOO
-        assert token.start == 0, token.start
-        assert token.stop == 1, token.stop
-        assert token.text == 'fo', token.text
+        self.assertEqual(token.type, self.lexerModule.FOO)
+        self.assertEqual(token.start, 0)
+        self.assertEqual(token.stop, 1)
+        self.assertEqual(token.text, 'fo')

token = lexer.nextToken()
-        assert token.type == self.lexerModule.FOO
-        assert token.start == 2, token.start
-        assert token.stop == 4, token.stop
-        assert token.text == 'foo', token.text
+        self.assertEqual(token.type, self.lexerModule.FOO)
+        self.assertEqual(token.start, 2)
+        self.assertEqual(token.stop, 4)
+        self.assertEqual(token.text, 'foo')

token = lexer.nextToken()
-        assert token.type == self.lexerModule.FOO
-        assert token.start == 5, token.start
-        assert token.stop == 8, token.stop
-        assert token.text == 'fooo', token.text
+        self.assertEqual(token.type, self.lexerModule.FOO)
+        self.assertEqual(token.start, 5)
+        self.assertEqual(token.stop, 8)
+        self.assertEqual(token.text, 'fooo')

token = lexer.nextToken()
-        assert token.type == self.lexerModule.EOF
+        self.assertEqual(token.type, self.lexerModule.EOF)


def testMalformedInput1(self):
@@ -52,11 +52,11 @@ class t005lexer(testbase.ANTLRTest):

try:
token = lexer.nextToken()
-            raise AssertionError
+            self.fail()

-        except antlr3.MismatchedTokenException, exc:
-            assert exc.expecting == 'f', repr(exc.expecting)
-            assert exc.unexpectedType == '2', repr(exc.unexpectedType)
+        except antlr3.MismatchedTokenException as exc:
+            self.assertEqual(exc.expecting, 'f')
+            self.assertEqual(exc.unexpectedType, '2')


def testMalformedInput2(self):
@@ -65,10 +65,10 @@ class t005lexer(testbase.ANTLRTest):

try:
token = lexer.nextToken()
-            raise AssertionError
+            self.fail()

-        except antlr3.EarlyExitException, exc:
-            assert exc.unexpectedType == antlr3.EOF, repr(exc.unexpectedType)
+        except antlr3.EarlyExitException as exc:
+            self.assertEqual(exc.unexpectedType, antlr3.EOF)


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t006lexer.g b/runtime/Python3/tests/t006lexer.g
index ad93cb4..b7f4f4a 100644
--- a/runtime/Python3/tests/t006lexer.g
+++ b/runtime/Python3/tests/t006lexer.g
@@ -1,6 +1,6 @@
lexer grammar t006lexer;
options {
-  language = Python;
+  language = Python3;
}

FOO: 'f' ('o' | 'a')*;
diff --git a/runtime/Python3/tests/t006lexer.py b/runtime/Python3/tests/t006lexer.py
index a4f845b..daa5d29 100644
--- a/runtime/Python3/tests/t006lexer.py
+++ b/runtime/Python3/tests/t006lexer.py
@@ -25,19 +25,19 @@ class t006lexer(testbase.ANTLRTest):
lexer = self.getLexer(stream)

token = lexer.nextToken()
-        assert token.type == self.lexerModule.FOO
-        assert token.start == 0, token.start
-        assert token.stop == 1, token.stop
-        assert token.text == 'fo', token.text
+        self.assertEqual(token.type, self.lexerModule.FOO)
+        self.assertEqual(token.start, 0)
+        self.assertEqual(token.stop, 1)
+        self.assertEqual(token.text, 'fo')

token = lexer.nextToken()
-        assert token.type == self.lexerModule.FOO
-        assert token.start == 2, token.start
-        assert token.stop == 7, token.stop
-        assert token.text == 'faaooa', token.text
+        self.assertEqual(token.type, self.lexerModule.FOO)
+        self.assertEqual(token.start, 2)
+        self.assertEqual(token.stop, 7)
+        self.assertEqual(token.text, 'faaooa')

token = lexer.nextToken()
-        assert token.type == self.lexerModule.EOF
+        self.assertEqual(token.type, self.lexerModule.EOF)


def testMalformedInput(self):
@@ -48,13 +48,13 @@ class t006lexer(testbase.ANTLRTest):
lexer.nextToken()
try:
token = lexer.nextToken()
-            raise AssertionError, token
+            self.fail(token)

-        except antlr3.MismatchedTokenException, exc:
-            assert exc.expecting == 'f', repr(exc.expecting)
-            assert exc.unexpectedType == '2', repr(exc.unexpectedType)
-            assert exc.charPositionInLine == 10, repr(exc.charPositionInLine)
-            assert exc.line == 1, repr(exc.line)
+        except antlr3.MismatchedTokenException as exc:
+            self.assertEqual(exc.expecting, 'f')
+            self.assertEqual(exc.unexpectedType, '2')
+            self.assertEqual(exc.charPositionInLine, 10)
+            self.assertEqual(exc.line, 1)


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t007lexer.g b/runtime/Python3/tests/t007lexer.g
index b5651d5..e55b4b7 100644
--- a/runtime/Python3/tests/t007lexer.g
+++ b/runtime/Python3/tests/t007lexer.g
@@ -1,6 +1,6 @@
lexer grammar t007lexer;
options {
-  language = Python;
+  language = Python3;
}

FOO: 'f' ('o' | 'a' 'b'+)*;
diff --git a/runtime/Python3/tests/t007lexer.py b/runtime/Python3/tests/t007lexer.py
index 440657b..02abb77 100644
--- a/runtime/Python3/tests/t007lexer.py
+++ b/runtime/Python3/tests/t007lexer.py
@@ -25,19 +25,19 @@ class t007lexer(testbase.ANTLRTest):
lexer = self.getLexer(stream)

token = lexer.nextToken()
-        assert token.type == self.lexerModule.FOO
-        assert token.start == 0, token.start
-        assert token.stop == 1, token.stop
-        assert token.text == 'fo', token.text
+        self.assertEqual(token.type, self.lexerModule.FOO)
+        self.assertEqual(token.start, 0)
+        self.assertEqual(token.stop, 1)
+        self.assertEqual(token.text, 'fo')

token = lexer.nextToken()
-        assert token.type == self.lexerModule.FOO
-        assert token.start == 2, token.start
-        assert token.stop == 12, token.stop
-        assert token.text == 'fababbooabb', token.text
+        self.assertEqual(token.type, self.lexerModule.FOO)
+        self.assertEqual(token.start, 2)
+        self.assertEqual(token.stop, 12)
+        self.assertEqual(token.text, 'fababbooabb')

token = lexer.nextToken()
-        assert token.type == self.lexerModule.EOF
+        self.assertEqual(token.type, self.lexerModule.EOF)


def testMalformedInput(self):
@@ -46,12 +46,12 @@ class t007lexer(testbase.ANTLRTest):

try:
token = lexer.nextToken()
-            raise AssertionError, token
+            self.fail(token)

-        except antlr3.EarlyExitException, exc:
-            assert exc.unexpectedType == 'o', repr(exc.unexpectedType)
-            assert exc.charPositionInLine == 6, repr(exc.charPositionInLine)
-            assert exc.line == 1, repr(exc.line)
+        except antlr3.EarlyExitException as exc:
+            self.assertEqual(exc.unexpectedType, 'o')
+            self.assertEqual(exc.charPositionInLine, 6)
+            self.assertEqual(exc.line, 1)


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t008lexer.g b/runtime/Python3/tests/t008lexer.g
index 5949866..2a7904e 100644
--- a/runtime/Python3/tests/t008lexer.g
+++ b/runtime/Python3/tests/t008lexer.g
@@ -1,6 +1,6 @@
lexer grammar t008lexer;
options {
-  language = Python;
+  language = Python3;
}

FOO: 'f' 'a'?;
diff --git a/runtime/Python3/tests/t008lexer.py b/runtime/Python3/tests/t008lexer.py
index f62c148..f3b1ed9 100644
--- a/runtime/Python3/tests/t008lexer.py
+++ b/runtime/Python3/tests/t008lexer.py
@@ -25,25 +25,25 @@ class t008lexer(testbase.ANTLRTest):
lexer = self.getLexer(stream)

token = lexer.nextToken()
-        assert token.type == self.lexerModule.FOO
-        assert token.start == 0, token.start
-        assert token.stop == 0, token.stop
-        assert token.text == 'f', token.text
+        self.assertEqual(token.type, self.lexerModule.FOO)
+        self.assertEqual(token.start, 0)
+        self.assertEqual(token.stop, 0)
+        self.assertEqual(token.text, 'f')

token = lexer.nextToken()
-        assert token.type == self.lexerModule.FOO
-        assert token.start == 1, token.start
-        assert token.stop == 2, token.stop
-        assert token.text == 'fa', token.text
+        self.assertEqual(token.type, self.lexerModule.FOO)
+        self.assertEqual(token.start, 1)
+        self.assertEqual(token.stop, 2)
+        self.assertEqual(token.text, 'fa')

token = lexer.nextToken()
-        assert token.type == self.lexerModule.FOO
-        assert token.start == 3, token.start
-        assert token.stop == 3, token.stop
-        assert token.text == 'f', token.text
+        self.assertEqual(token.type, self.lexerModule.FOO)
+        self.assertEqual(token.start, 3)
+        self.assertEqual(token.stop, 3)
+        self.assertEqual(token.text, 'f')

token = lexer.nextToken()
-        assert token.type == self.lexerModule.EOF
+        self.assertEqual(token.type, self.lexerModule.EOF)


def testMalformedInput(self):
@@ -54,12 +54,12 @@ class t008lexer(testbase.ANTLRTest):
lexer.nextToken()
try:
token = lexer.nextToken()
-            raise AssertionError, token
+            self.fail(token)

-        except antlr3.MismatchedTokenException, exc:
-            assert exc.unexpectedType == 'b', repr(exc.unexpectedType)
-            assert exc.charPositionInLine == 3, repr(exc.charPositionInLine)
-            assert exc.line == 1, repr(exc.line)
+        except antlr3.MismatchedTokenException as exc:
+            self.assertEqual(exc.unexpectedType, 'b')
+            self.assertEqual(exc.charPositionInLine, 3)
+            self.assertEqual(exc.line, 1)


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t009lexer.g b/runtime/Python3/tests/t009lexer.g
index 6126908..a04b5b4 100644
--- a/runtime/Python3/tests/t009lexer.g
+++ b/runtime/Python3/tests/t009lexer.g
@@ -1,6 +1,6 @@
lexer grammar t009lexer;
options {
-  language = Python;
+  language = Python3;
}

DIGIT: '0' .. '9';
diff --git a/runtime/Python3/tests/t009lexer.py b/runtime/Python3/tests/t009lexer.py
index c32cbbf..bf60bce 100644
--- a/runtime/Python3/tests/t009lexer.py
+++ b/runtime/Python3/tests/t009lexer.py
@@ -25,25 +25,25 @@ class t009lexer(testbase.ANTLRTest):
lexer = self.getLexer(stream)

token = lexer.nextToken()
-        assert token.type == self.lexerModule.DIGIT
-        assert token.start == 0, token.start
-        assert token.stop == 0, token.stop
-        assert token.text == '0', token.text
+        self.assertEqual(token.type, self.lexerModule.DIGIT)
+        self.assertEqual(token.start, 0)
+        self.assertEqual(token.stop, 0)
+        self.assertEqual(token.text, '0')

token = lexer.nextToken()
-        assert token.type == self.lexerModule.DIGIT
-        assert token.start == 1, token.start
-        assert token.stop == 1, token.stop
-        assert token.text == '8', token.text
+        self.assertEqual(token.type, self.lexerModule.DIGIT)
+        self.assertEqual(token.start, 1)
+        self.assertEqual(token.stop, 1)
+        self.assertEqual(token.text, '8')

token = lexer.nextToken()
-        assert token.type == self.lexerModule.DIGIT
-        assert token.start == 2, token.start
-        assert token.stop == 2, token.stop
-        assert token.text == '5', token.text
+        self.assertEqual(token.type, self.lexerModule.DIGIT)
+        self.assertEqual(token.start, 2)
+        self.assertEqual(token.stop, 2)
+        self.assertEqual(token.text, '5')

token = lexer.nextToken()
-        assert token.type == self.lexerModule.EOF
+        self.assertEqual(token.type, self.lexerModule.EOF)


def testMalformedInput(self):
@@ -53,14 +53,14 @@ class t009lexer(testbase.ANTLRTest):
lexer.nextToken()
try:
token = lexer.nextToken()
-            raise AssertionError, token
+            self.fail(token)

-        except antlr3.MismatchedSetException, exc:
+        except antlr3.MismatchedSetException as exc:
# TODO: This should provide more useful information
-            assert exc.expecting is None
-            assert exc.unexpectedType == 'a', repr(exc.unexpectedType)
-            assert exc.charPositionInLine == 1, repr(exc.charPositionInLine)
-            assert exc.line == 1, repr(exc.line)
+            self.assertIsNone(exc.expecting)
+            self.assertEqual(exc.unexpectedType, 'a')
+            self.assertEqual(exc.charPositionInLine, 1)
+            self.assertEqual(exc.line, 1)


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t010lexer.g b/runtime/Python3/tests/t010lexer.g
index a93636c..3a7524d 100644
--- a/runtime/Python3/tests/t010lexer.g
+++ b/runtime/Python3/tests/t010lexer.g
@@ -1,6 +1,6 @@
lexer grammar t010lexer;
options {
-  language = Python;
+  language = Python3;
}

IDENTIFIER: ('a'..'z'|'A'..'Z'|'_') ('a'..'z'|'A'..'Z'|'0'..'9'|'_')*;
diff --git a/runtime/Python3/tests/t010lexer.py b/runtime/Python3/tests/t010lexer.py
index 7cd318c..9cedea3 100644
--- a/runtime/Python3/tests/t010lexer.py
+++ b/runtime/Python3/tests/t010lexer.py
@@ -25,37 +25,37 @@ class t010lexer(testbase.ANTLRTest):
lexer = self.getLexer(stream)

token = lexer.nextToken()
-        assert token.type == self.lexerModule.IDENTIFIER
-        assert token.start == 0, token.start
-        assert token.stop == 5, token.stop
-        assert token.text == 'foobar', token.text
+        self.assertEqual(token.type, self.lexerModule.IDENTIFIER)
+        self.assertEqual(token.start, 0)
+        self.assertEqual(token.stop, 5)
+        self.assertEqual(token.text, 'foobar')

token = lexer.nextToken()
-        assert token.type == self.lexerModule.WS
-        assert token.start == 6, token.start
-        assert token.stop == 6, token.stop
-        assert token.text == ' ', token.text
+        self.assertEqual(token.type, self.lexerModule.WS)
+        self.assertEqual(token.start, 6)
+        self.assertEqual(token.stop, 6)
+        self.assertEqual(token.text, ' ')

token = lexer.nextToken()
-        assert token.type == self.lexerModule.IDENTIFIER
-        assert token.start == 7, token.start
-        assert token.stop == 11, token.stop
-        assert token.text == '_Ab98', token.text
+        self.assertEqual(token.type, self.lexerModule.IDENTIFIER)
+        self.assertEqual(token.start, 7)
+        self.assertEqual(token.stop, 11)
+        self.assertEqual(token.text, '_Ab98')

token = lexer.nextToken()
-        assert token.type == self.lexerModule.WS
-        assert token.start == 12, token.start
-        assert token.stop == 14, token.stop
-        assert token.text == ' \n ', token.text
+        self.assertEqual(token.type, self.lexerModule.WS)
+        self.assertEqual(token.start, 12)
+        self.assertEqual(token.stop, 14)
+        self.assertEqual(token.text, ' \n ')

token = lexer.nextToken()
-        assert token.type == self.lexerModule.IDENTIFIER
-        assert token.start == 15, token.start
-        assert token.stop == 20, token.stop
-        assert token.text == 'A12sdf', token.text
+        self.assertEqual(token.type, self.lexerModule.IDENTIFIER)
+        self.assertEqual(token.start, 15)
+        self.assertEqual(token.stop, 20)
+        self.assertEqual(token.text, 'A12sdf')

token = lexer.nextToken()
-        assert token.type == self.lexerModule.EOF
+        self.assertEqual(token.type, self.lexerModule.EOF)


def testMalformedInput(self):
@@ -65,12 +65,12 @@ class t010lexer(testbase.ANTLRTest):
lexer.nextToken()
try:
token = lexer.nextToken()
-            raise AssertionError, token
+            self.fail(token)

-        except antlr3.NoViableAltException, exc:
-            assert exc.unexpectedType == '-', repr(exc.unexpectedType)
-            assert exc.charPositionInLine == 1, repr(exc.charPositionInLine)
-            assert exc.line == 1, repr(exc.line)
+        except antlr3.NoViableAltException as exc:
+            self.assertEqual(exc.unexpectedType, '-')
+            self.assertEqual(exc.charPositionInLine, 1)
+            self.assertEqual(exc.line, 1)



diff --git a/runtime/Python3/tests/t011lexer.g b/runtime/Python3/tests/t011lexer.g
index fde9a3b..17d01ea 100644
--- a/runtime/Python3/tests/t011lexer.g
+++ b/runtime/Python3/tests/t011lexer.g
@@ -1,6 +1,6 @@
lexer grammar t011lexer;
options {
-  language = Python;
+  language = Python3;
}

IDENTIFIER:
@@ -10,8 +10,8 @@ IDENTIFIER:
|'0'..'9'
|'_'
{
-              print "Underscore"
-              print "foo"
+              print("Underscore")
+              print("foo")
}
)*
;
diff --git a/runtime/Python3/tests/t011lexer.py b/runtime/Python3/tests/t011lexer.py
index 7014255..b417826 100644
--- a/runtime/Python3/tests/t011lexer.py
+++ b/runtime/Python3/tests/t011lexer.py
@@ -25,37 +25,37 @@ class t011lexer(testbase.ANTLRTest):
lexer = self.getLexer(stream)

token = lexer.nextToken()
-        assert token.type == self.lexerModule.IDENTIFIER
-        assert token.start == 0, token.start
-        assert token.stop == 5, token.stop
-        assert token.text == 'foobar', token.text
+        self.assertEqual(token.type, self.lexerModule.IDENTIFIER)
+        self.assertEqual(token.start, 0)
+        self.assertEqual(token.stop, 5)
+        self.assertEqual(token.text, 'foobar')

token = lexer.nextToken()
-        assert token.type == self.lexerModule.WS
-        assert token.start == 6, token.start
-        assert token.stop == 6, token.stop
-        assert token.text == ' ', token.text
+        self.assertEqual(token.type, self.lexerModule.WS)
+        self.assertEqual(token.start, 6)
+        self.assertEqual(token.stop, 6)
+        self.assertEqual(token.text, ' ')

token = lexer.nextToken()
-        assert token.type == self.lexerModule.IDENTIFIER
-        assert token.start == 7, token.start
-        assert token.stop == 11, token.stop
-        assert token.text == '_Ab98', token.text
+        self.assertEqual(token.type, self.lexerModule.IDENTIFIER)
+        self.assertEqual(token.start, 7)
+        self.assertEqual(token.stop, 11)
+        self.assertEqual(token.text, '_Ab98')

token = lexer.nextToken()
-        assert token.type == self.lexerModule.WS
-        assert token.start == 12, token.start
-        assert token.stop == 14, token.stop
-        assert token.text == ' \n ', token.text
+        self.assertEqual(token.type, self.lexerModule.WS)
+        self.assertEqual(token.start, 12)
+        self.assertEqual(token.stop, 14)
+        self.assertEqual(token.text, ' \n ')

token = lexer.nextToken()
-        assert token.type == self.lexerModule.IDENTIFIER
-        assert token.start == 15, token.start
-        assert token.stop == 20, token.stop
-        assert token.text == 'A12sdf', token.text
+        self.assertEqual(token.type, self.lexerModule.IDENTIFIER)
+        self.assertEqual(token.start, 15)
+        self.assertEqual(token.stop, 20)
+        self.assertEqual(token.text, 'A12sdf')

token = lexer.nextToken()
-        assert token.type == self.lexerModule.EOF
+        self.assertEqual(token.type, self.lexerModule.EOF)


def testMalformedInput(self):
@@ -65,12 +65,12 @@ class t011lexer(testbase.ANTLRTest):
lexer.nextToken()
try:
token = lexer.nextToken()
-            raise AssertionError, token
+            self.fail(token)

-        except antlr3.NoViableAltException, exc:
-            assert exc.unexpectedType == '-', repr(exc.unexpectedType)
-            assert exc.charPositionInLine == 1, repr(exc.charPositionInLine)
-            assert exc.line == 1, repr(exc.line)
+        except antlr3.NoViableAltException as exc:
+            self.assertEqual(exc.unexpectedType, '-')
+            self.assertEqual(exc.charPositionInLine, 1)
+            self.assertEqual(exc.line, 1)



diff --git a/runtime/Python3/tests/t012lexerXML.py b/runtime/Python3/tests/t012lexerXML.py
index 3e8f8b4..40d67bb 100644
--- a/runtime/Python3/tests/t012lexerXML.py
+++ b/runtime/Python3/tests/t012lexerXML.py
@@ -3,8 +3,7 @@ import testbase
import unittest
import os
import sys
-from cStringIO import StringIO
-import difflib
+from io import StringIO
import textwrap

class t012lexerXML(testbase.ANTLRTest):
@@ -27,7 +26,9 @@ class t012lexerXML(testbase.ANTLRTest):

def testValid(self):
inputPath = os.path.splitext(__file__)[0] + '.input'
-        stream = antlr3.StringStream(unicode(open(inputPath).read(), 'utf-8'))
+        with open(inputPath) as f:
+            data = f.read()
+        stream = antlr3.StringStream(data)
lexer = self.getLexer(stream)

while True:
@@ -36,18 +37,14 @@ class t012lexerXML(testbase.ANTLRTest):
break


-        output = unicode(lexer.outbuf.getvalue(), 'utf-8')
+        output = lexer.outbuf.getvalue()

outputPath = os.path.splitext(__file__)[0] + '.output'
-        testOutput = unicode(open(outputPath).read(), 'utf-8')

-        success = (output == testOutput)
-        if not success:
-            d = difflib.Differ()
-            r = d.compare(output.splitlines(1), testOutput.splitlines(1))
-            self.fail(
-                ''.join([l.encode('ascii', 'backslashreplace') for l in r])
-                )
+        with open(outputPath) as f:
+            testOutput = f.read()
+
+        self.assertEqual(output, testOutput)


def testMalformedInput1(self):
@@ -63,15 +60,14 @@ class t012lexerXML(testbase.ANTLRTest):
try:
while True:
token = lexer.nextToken()
+                # Should raise NoViableAltException before hitting EOF
if token.type == antlr3.EOF:
-                    break
-
-            raise AssertionError
+                    self.fail()

-        except antlr3.NoViableAltException, exc:
-            assert exc.unexpectedType == '>', repr(exc.unexpectedType)
-            assert exc.charPositionInLine == 11, repr(exc.charPositionInLine)
-            assert exc.line == 2, repr(exc.line)
+        except antlr3.NoViableAltException as exc:
+            self.assertEqual(exc.unexpectedType, '>')
+            self.assertEqual(exc.charPositionInLine, 11)
+            self.assertEqual(exc.line, 2)


def testMalformedInput2(self):
@@ -87,15 +83,14 @@ class t012lexerXML(testbase.ANTLRTest):
try:
while True:
token = lexer.nextToken()
+                # Should raise NoViableAltException before hitting EOF
if token.type == antlr3.EOF:
-                    break
-
-            raise AssertionError
+                    self.fail()

-        except antlr3.MismatchedSetException, exc:
-            assert exc.unexpectedType == 't', repr(exc.unexpectedType)
-            assert exc.charPositionInLine == 2, repr(exc.charPositionInLine)
-            assert exc.line == 1, repr(exc.line)
+        except antlr3.MismatchedSetException as exc:
+            self.assertEqual(exc.unexpectedType, 't')
+            self.assertEqual(exc.charPositionInLine, 2)
+            self.assertEqual(exc.line, 1)


def testMalformedInput3(self):
@@ -111,79 +106,15 @@ class t012lexerXML(testbase.ANTLRTest):
try:
while True:
token = lexer.nextToken()
+                # Should raise NoViableAltException before hitting EOF
if token.type == antlr3.EOF:
-                    break
+                    self.fail()

-            raise AssertionError
-
-        except antlr3.NoViableAltException, exc:
-            assert exc.unexpectedType == 'a', repr(exc.unexpectedType)
-            assert exc.charPositionInLine == 11, repr(exc.charPositionInLine)
-            assert exc.line == 2, repr(exc.line)
+        except antlr3.NoViableAltException as exc:
+            self.assertEqual(exc.unexpectedType, 'a')
+            self.assertEqual(exc.charPositionInLine, 11)
+            self.assertEqual(exc.line, 2)


-
if __name__ == '__main__':
unittest.main()
-
-
-## # run an infinite loop with randomly mangled input
-## while True:
-##     print "ping"
-
-##     input = """\
-## <?xml version='1.0'?>
-## <!DOCTYPE component [
-## <!ELEMENT component (PCDATA|sub)*>
-## <!ATTLIST component
-##           attr CDATA #IMPLIED
-##           attr2 CDATA #IMPLIED
-## >
-## <!ELMENT sub EMPTY>
-
-## ]>
-## <component attr="val'ue" attr2='val"ue'>
-## <!-- This is a comment -->
-## Text
-## <![CDATA[huhu]]>
-## &amp;
-## &lt;
-## <?xtal cursor='11'?>
-## <sub/>
-## <sub></sub>
-## </component>
-## """
-
-##     import random
-##     input = list(input) # make it mutable
-##     for _ in range(3):
-##         p1 = random.randrange(len(input))
-##         p2 = random.randrange(len(input))
-
-##         c1 = input[p1]
-##         input[p1] = input[p2]
-##         input[p2] = c1
-##     input = ''.join(input) # back to string
-
-##     stream = antlr3.StringStream(input)
-##     lexer = Lexer(stream)
-
-##     try:
-##         while True:
-##             token = lexer.nextToken()
-##             if token.type == EOF:
-##                 break
-
-##     except antlr3.RecognitionException, exc:
-##         print exc
-##         for l in input.splitlines()[0:exc.line]:
-##             print l
-##         print ' '*exc.charPositionInLine + '^'
-
-##     except BaseException, exc:
-##         print '\n'.join(['%02d: %s' % (idx+1, l) for idx, l in enumerate(input.splitlines())])
-##         print "%s at %d:%d" % (exc, stream.line, stream.charPositionInLine)
-##         print
-
-##         raise
-
diff --git a/runtime/Python3/tests/t012lexerXMLLexer.g b/runtime/Python3/tests/t012lexerXMLLexer.g
index 31fa203..23e566a 100644
--- a/runtime/Python3/tests/t012lexerXMLLexer.g
+++ b/runtime/Python3/tests/t012lexerXMLLexer.g
@@ -1,10 +1,10 @@
lexer grammar t012lexerXMLLexer;
options {
-  language = Python;
+  language = Python3;
}

@header {
-from cStringIO import StringIO
+from io import StringIO
}

@lexer::init {
@@ -13,7 +13,7 @@ self.outbuf = StringIO()

@lexer::members {
def output(self, line):
-    self.outbuf.write(line.encode('utf-8') + "\n")
+    self.outbuf.write(line + "\n")
}

DOCUMENT
@@ -60,11 +60,11 @@ fragment ELEMENT
: ( START_TAG
(ELEMENT
| t=PCDATA
-                {self.output("PCDATA: \""+$t.text+"\"")}
+                {self.output('PCDATA: "{}"'.format($t.text))}
| t=CDATA
-                {self.output("CDATA: \""+$t.text+"\"")}
+                {self.output('CDATA: "{}"'.format($t.text))}
| t=COMMENT
-                {self.output("Comment: \""+$t.text+"\"")}
+                {self.output('Comment: "{}"'.format($t.text))}
| pi=PI
)*
END_TAG
@@ -86,7 +86,7 @@ fragment EMPTY_ELEMENT

fragment ATTRIBUTE
: name=GENERIC_ID WS? '=' WS? value=VALUE
-        {self.output("Attr: "+name.text+"="+value.text)}
+        {self.output("Attr: {}={}".format(name.text, value.text))}
;

fragment END_TAG
diff --git a/runtime/Python3/tests/t013parser.g b/runtime/Python3/tests/t013parser.g
index c3ab2c9..bf97d77 100644
--- a/runtime/Python3/tests/t013parser.g
+++ b/runtime/Python3/tests/t013parser.g
@@ -1,6 +1,6 @@
grammar t013parser;
options {
-  language = Python;
+  language = Python3;
}

@parser::init {
diff --git a/runtime/Python3/tests/t013parser.py b/runtime/Python3/tests/t013parser.py
index 1c21d5e..4562e36 100644
--- a/runtime/Python3/tests/t013parser.py
+++ b/runtime/Python3/tests/t013parser.py
@@ -14,8 +14,8 @@ class t013parser(testbase.ANTLRTest):
parser = self.getParser(tStream)
parser.document()

-        assert len(parser.reportedErrors) == 0, parser.reportedErrors
-        assert parser.identifiers == ['foobar']
+        self.assertEqual(parser.reportedErrors, [])
+        self.assertEqual(parser.identifiers, ['foobar'])


def testMalformedInput1(self):
@@ -28,7 +28,7 @@ class t013parser(testbase.ANTLRTest):

# FIXME: currently strings with formatted errors are collected
# can't check error locations yet
-        assert len(parser.reportedErrors) == 1, parser.reportedErrors
+        self.assertEqual(len(parser.reportedErrors), 1, parser.reportedErrors)


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t014parser.g b/runtime/Python3/tests/t014parser.g
index 4c8238f..3d58d18 100644
--- a/runtime/Python3/tests/t014parser.g
+++ b/runtime/Python3/tests/t014parser.g
@@ -1,6 +1,6 @@
grammar t014parser;
options {
-  language = Python;
+  language = Python3;
}

@parser::init {
diff --git a/runtime/Python3/tests/t014parser.py b/runtime/Python3/tests/t014parser.py
index e2965a4..ae071d7 100644
--- a/runtime/Python3/tests/t014parser.py
+++ b/runtime/Python3/tests/t014parser.py
@@ -14,13 +14,10 @@ class t014parser(testbase.ANTLRTest):
parser = self.getParser(tStream)
parser.document()

-        assert len(parser.reportedErrors) == 0, parser.reportedErrors
-        assert parser.events == [
-            ('decl', 'foobar'),
-            ('call', 'gnarz'),
-            ('decl', 'blupp'),
-            ('call', 'flupp')
-            ], parser.events
+        self.assertEqual(parser.reportedErrors, [])
+        self.assertEqual(parser.events,
+                         [('decl', 'foobar'), ('call', 'gnarz'),
+                          ('decl', 'blupp'), ('call', 'flupp')])


def testMalformedInput1(self):
@@ -33,8 +30,8 @@ class t014parser(testbase.ANTLRTest):

# FIXME: currently strings with formatted errors are collected
# can't check error locations yet
-        assert len(parser.reportedErrors) == 1, parser.reportedErrors
-        assert parser.events == [], parser.events
+        self.assertEqual(len(parser.reportedErrors), 1, parser.reportedErrors)
+        self.assertEqual(parser.events, [])


def testMalformedInput2(self):
@@ -47,10 +44,8 @@ class t014parser(testbase.ANTLRTest):

# FIXME: currently strings with formatted errors are collected
# can't check error locations yet
-        assert len(parser.reportedErrors) == 1, parser.reportedErrors
-        assert parser.events == [
-            ('call', 'gnarz'),
-            ], parser.events
+        self.assertEqual(len(parser.reportedErrors), 1, parser.reportedErrors)
+        self.assertEqual(parser.events, [('call', 'gnarz')])


def testMalformedInput3(self):
@@ -63,11 +58,8 @@ class t014parser(testbase.ANTLRTest):

# FIXME: currently strings with formatted errors are collected
# can't check error locations yet
-        assert len(parser.reportedErrors) == 1, parser.reportedErrors
-        assert parser.events == [
-            ('call', 'gnarz'),
-            ('call', 'flupp'),
-            ], parser.events
+        self.assertEqual(len(parser.reportedErrors), 1, parser.reportedErrors)
+        self.assertEqual(parser.events, [('call', 'gnarz'), ('call', 'flupp')])


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t015calc.g b/runtime/Python3/tests/t015calc.g
index f08e3ce..54f17ec 100644
--- a/runtime/Python3/tests/t015calc.g
+++ b/runtime/Python3/tests/t015calc.g
@@ -1,6 +1,6 @@
grammar t015calc;
options {
-  language = Python;
+  language = Python3;
}

@header {
diff --git a/runtime/Python3/tests/t015calc.py b/runtime/Python3/tests/t015calc.py
index 0f1fe8a..a7a5639 100644
--- a/runtime/Python3/tests/t015calc.py
+++ b/runtime/Python3/tests/t015calc.py
@@ -13,8 +13,9 @@ class t015calc(testbase.ANTLRTest):
tStream = antlr3.CommonTokenStream(lexer)
parser = self.getParser(tStream)
result = parser.evaluate()
-        assert result == expected, "%r != %r" % (result, expected)
-        assert len(parser.reportedErrors) == len(errors), parser.reportedErrors
+        self.assertEqual(result, expected)
+        self.assertEqual(len(parser.reportedErrors), len(errors),
+                         parser.reportedErrors)


def testValid01(self):
diff --git a/runtime/Python3/tests/t016actions.g b/runtime/Python3/tests/t016actions.g
index 1b7ac65..f6def13 100644
--- a/runtime/Python3/tests/t016actions.g
+++ b/runtime/Python3/tests/t016actions.g
@@ -1,6 +1,6 @@
grammar t016actions;
options {
-  language = Python;
+  language = Python3;
}

declaration returns [name]
diff --git a/runtime/Python3/tests/t016actions.py b/runtime/Python3/tests/t016actions.py
index 5e4cad0..60ea53a 100644
--- a/runtime/Python3/tests/t016actions.py
+++ b/runtime/Python3/tests/t016actions.py
@@ -13,7 +13,7 @@ class t016actions(testbase.ANTLRTest):
tStream = antlr3.CommonTokenStream(lexer)
parser = self.getParser(tStream)
name = parser.declaration()
-        assert name == 'foo', name
+        self.assertEqual(name, 'foo')


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t017parser.g b/runtime/Python3/tests/t017parser.g
index 84c6b03..20b4724 100644
--- a/runtime/Python3/tests/t017parser.g
+++ b/runtime/Python3/tests/t017parser.g
@@ -1,7 +1,7 @@
grammar t017parser;

options {
-    language = Python;
+    language = Python3;
}

program
diff --git a/runtime/Python3/tests/t017parser.py b/runtime/Python3/tests/t017parser.py
index 5b4d851..3add2ad 100644
--- a/runtime/Python3/tests/t017parser.py
+++ b/runtime/Python3/tests/t017parser.py
@@ -9,7 +9,7 @@ class t017parser(testbase.ANTLRTest):
def parserClass(self, base):
class TestParser(base):
def __init__(self, *args, **kwargs):
-                base.__init__(self, *args, **kwargs)
+                super().__init__(*args, **kwargs)

self.reportedErrors = []

@@ -27,7 +27,7 @@ class t017parser(testbase.ANTLRTest):
parser = self.getParser(tStream)
parser.program()

-        assert len(parser.reportedErrors) == 0, parser.reportedErrors
+        self.assertEqual(parser.reportedErrors, [])


def testMalformedInput1(self):
@@ -39,7 +39,7 @@ class t017parser(testbase.ANTLRTest):

# FIXME: currently strings with formatted errors are collected
# can't check error locations yet
-        assert len(parser.reportedErrors) == 1, parser.reportedErrors
+        self.assertEqual(len(parser.reportedErrors), 1, parser.reportedErrors)


def testMalformedInput2(self):
@@ -51,7 +51,7 @@ class t017parser(testbase.ANTLRTest):

# FIXME: currently strings with formatted errors are collected
# can't check error locations yet
-        assert len(parser.reportedErrors) == 2, parser.reportedErrors
+        self.assertEqual(len(parser.reportedErrors), 2, parser.reportedErrors)


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t018llstar.g b/runtime/Python3/tests/t018llstar.g
index 388ab92..40d8857 100644
--- a/runtime/Python3/tests/t018llstar.g
+++ b/runtime/Python3/tests/t018llstar.g
@@ -1,11 +1,11 @@
grammar t018llstar;

options {
-    language = Python;
+    language = Python3;
}

@header {
-from cStringIO import StringIO
+from io import StringIO
}

@init {
diff --git a/runtime/Python3/tests/t018llstar.py b/runtime/Python3/tests/t018llstar.py
index fe67fe2..9cc3e22 100644
--- a/runtime/Python3/tests/t018llstar.py
+++ b/runtime/Python3/tests/t018llstar.py
@@ -3,8 +3,7 @@ import testbase
import unittest
import os
import sys
-from cStringIO import StringIO
-import difflib
+from io import StringIO

class t018llstar(testbase.ANTLRTest):
def setUp(self):
@@ -13,7 +12,8 @@ class t018llstar(testbase.ANTLRTest):

def testValid(self):
inputPath = os.path.splitext(__file__)[0] + '.input'
-        cStream = antlr3.StringStream(open(inputPath).read())
+        with open(inputPath) as f:
+            cStream = antlr3.StringStream(f.read())
lexer = self.getLexer(cStream)
tStream = antlr3.CommonTokenStream(lexer)
parser = self.getParser(tStream)
@@ -22,55 +22,10 @@ class t018llstar(testbase.ANTLRTest):
output = parser.output.getvalue()

outputPath = os.path.splitext(__file__)[0] + '.output'
-        testOutput = open(outputPath).read()
+        with open(outputPath) as f:
+            testOutput = f.read()

-        success = (output == testOutput)
-        if not success:
-            d = difflib.Differ()
-            r = d.compare(output.splitlines(1), testOutput.splitlines(1))
-            self.fail(
-                ''.join([l.encode('ascii', 'backslashreplace') for l in r])
-                )
+        self.assertEqual(output, testOutput)

if __name__ == '__main__':
unittest.main()
-
-
-
-## # run an infinite loop with randomly mangled input
-## while True:
-##     print "ping"
-
-##     input = open(inputPath).read()
-
-##     import random
-##     input = list(input) # make it mutable
-##     for _ in range(3):
-##         p1 = random.randrange(len(input))
-##         p2 = random.randrange(len(input))
-
-##         c1 = input[p1]
-##         input[p1] = input[p2]
-##         input[p2] = c1
-##     input = ''.join(input) # back to string
-
-
-##     try:
-##         cStream = antlr3.StringStream(input)
-##         lexer = Lexer(cStream)
-##         tStream = antlr3.CommonTokenStream(lexer)
-##         parser = TestParser(tStream)
-##         parser.program()
-
-##     except antlr3.RecognitionException, exc:
-##         print exc
-##         for l in input.splitlines()[0:exc.line]:
-##             print l
-##         print ' '*exc.charPositionInLine + '^'
-
-##     except BaseException, exc:
-##         print '\n'.join(['%02d: %s' % (idx+1, l) for idx, l in enumerate(input.splitlines())])
-##         print "%s at %d:%d" % (exc, cStream.line, cStream.charPositionInLine)
-##         print
-
-##         raise
diff --git a/runtime/Python3/tests/t019lexer.g b/runtime/Python3/tests/t019lexer.g
index 3647775..0b986a0 100644
--- a/runtime/Python3/tests/t019lexer.g
+++ b/runtime/Python3/tests/t019lexer.g
@@ -1,6 +1,6 @@
lexer grammar t019lexer;
options {
-    language=Python;
+    language=Python3;
filter=true;
}

diff --git a/runtime/Python3/tests/t019lexer.py b/runtime/Python3/tests/t019lexer.py
index de21d33..90c4fbb 100644
--- a/runtime/Python3/tests/t019lexer.py
+++ b/runtime/Python3/tests/t019lexer.py
@@ -10,7 +10,8 @@ class t019lexer(testbase.ANTLRTest):

def testValid(self):
inputPath = os.path.splitext(__file__)[0] + '.input'
-        stream = antlr3.StringStream(open(inputPath).read())
+        with open(inputPath) as f:
+            stream = antlr3.StringStream(f.read())
lexer = self.getLexer(stream)

while True:
diff --git a/runtime/Python3/tests/t020fuzzy.py b/runtime/Python3/tests/t020fuzzy.py
index 773aa2e..e43a12f 100644
--- a/runtime/Python3/tests/t020fuzzy.py
+++ b/runtime/Python3/tests/t020fuzzy.py
@@ -3,8 +3,7 @@ import sys
import antlr3
import testbase
import unittest
-from cStringIO import StringIO
-import difflib
+from io import StringIO

class t020fuzzy(testbase.ANTLRTest):
def setUp(self):
@@ -13,7 +12,8 @@ class t020fuzzy(testbase.ANTLRTest):

def testValid(self):
inputPath = os.path.splitext(__file__)[0] + '.input'
-        stream = antlr3.StringStream(open(inputPath).read())
+        with open(inputPath) as f:
+            stream = antlr3.StringStream(f.read())
lexer = self.getLexer(stream)

while True:
@@ -25,15 +25,10 @@ class t020fuzzy(testbase.ANTLRTest):
output = lexer.output.getvalue()

outputPath = os.path.splitext(__file__)[0] + '.output'
-        testOutput = open(outputPath).read()
-
-        success = (output == testOutput)
-        if not success:
-            d = difflib.Differ()
-            r = d.compare(output.splitlines(1), testOutput.splitlines(1))
-            self.fail(
-                ''.join([l.encode('ascii', 'backslashreplace') for l in r])
-                )
+        with open(outputPath) as f:
+            testOutput = f.read()
+
+        self.assertEqual(output, testOutput)


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t020fuzzyLexer.g b/runtime/Python3/tests/t020fuzzyLexer.g
index 819af69..f2aeaf5 100644
--- a/runtime/Python3/tests/t020fuzzyLexer.g
+++ b/runtime/Python3/tests/t020fuzzyLexer.g
@@ -1,11 +1,11 @@
lexer grammar t020fuzzyLexer;
options {
-    language=Python;
+    language=Python3;
filter=true;
}

@header {
-from cStringIO import StringIO
+from io import StringIO
}

@init {
diff --git a/runtime/Python3/tests/t021hoist.g b/runtime/Python3/tests/t021hoist.g
index 8caa3ab..4b33c4f 100644
--- a/runtime/Python3/tests/t021hoist.g
+++ b/runtime/Python3/tests/t021hoist.g
@@ -1,6 +1,6 @@
grammar t021hoist;
options {
-    language=Python;
+    language=Python3;
}

/* With this true, enum is seen as a keyword.  False, it's an identifier */
diff --git a/runtime/Python3/tests/t021hoist.py b/runtime/Python3/tests/t021hoist.py
index 59d7260..571a1de 100644
--- a/runtime/Python3/tests/t021hoist.py
+++ b/runtime/Python3/tests/t021hoist.py
@@ -18,7 +18,7 @@ class t021hoist(testbase.ANTLRTest):
parser.enableEnum = True
enumIs = parser.stat()

-        assert enumIs == 'keyword', repr(enumIs)
+        self.assertEqual(enumIs, 'keyword')


def testValid2(self):
@@ -29,7 +29,7 @@ class t021hoist(testbase.ANTLRTest):
parser.enableEnum = False
enumIs = parser.stat()

-        assert enumIs == 'ID', repr(enumIs)
+        self.assertEqual(enumIs, 'ID')



diff --git a/runtime/Python3/tests/t022scopes.g b/runtime/Python3/tests/t022scopes.g
index 1affc83..fffeac5 100644
--- a/runtime/Python3/tests/t022scopes.g
+++ b/runtime/Python3/tests/t022scopes.g
@@ -1,7 +1,7 @@
grammar t022scopes;

options {
-    language=Python;
+    language=Python3;
}

/* global scopes */
diff --git a/runtime/Python3/tests/t022scopes.py b/runtime/Python3/tests/t022scopes.py
index 01bc597..5dc1f2c 100644
--- a/runtime/Python3/tests/t022scopes.py
+++ b/runtime/Python3/tests/t022scopes.py
@@ -36,11 +36,7 @@ class t022scopes(testbase.ANTLRTest):
tStream = antlr3.CommonTokenStream(lexer)
parser = self.getParser(tStream)

-        try:
-            parser.b(False)
-            self.fail()
-        except antlr3.RecognitionException:
-            pass
+        self.assertRaises(antlr3.RecognitionException, parser.b, False)


def testb2(self):
@@ -66,7 +62,7 @@ class t022scopes(testbase.ANTLRTest):
parser = self.getParser(tStream)
symbols = parser.c()

-        self.failUnlessEqual(
+        self.assertEqual(
symbols,
set(['i', 'j'])
)
@@ -87,11 +83,7 @@ class t022scopes(testbase.ANTLRTest):
tStream = antlr3.CommonTokenStream(lexer)
parser = self.getParser(tStream)

-        try:
-            parser.c()
-            self.fail()
-        except RuntimeError, exc:
-            self.failUnlessEqual(exc.args[0], 'x')
+        self.assertRaisesRegex(RuntimeError, r'x', parser.c)


def testd1(self):
@@ -114,7 +106,7 @@ class t022scopes(testbase.ANTLRTest):
parser = self.getParser(tStream)
symbols = parser.d()

-        self.failUnlessEqual(
+        self.assertEqual(
symbols,
set(['i', 'j'])
)
@@ -131,7 +123,7 @@ class t022scopes(testbase.ANTLRTest):
parser = self.getParser(tStream)
res = parser.e()

-        self.failUnlessEqual(res, 12)
+        self.assertEqual(res, 12)


def testf1(self):
@@ -145,7 +137,7 @@ class t022scopes(testbase.ANTLRTest):
parser = self.getParser(tStream)
res = parser.f()

-        self.failUnlessEqual(res, None)
+        self.assertIsNone(res)


def testf2(self):
@@ -159,7 +151,7 @@ class t022scopes(testbase.ANTLRTest):
parser = self.getParser(tStream)
res = parser.f()

-        self.failUnlessEqual(res, None)
+        self.assertIsNone(res)



diff --git a/runtime/Python3/tests/t023scopes.g b/runtime/Python3/tests/t023scopes.g
index 02e69b1..bc94b8d 100644
--- a/runtime/Python3/tests/t023scopes.g
+++ b/runtime/Python3/tests/t023scopes.g
@@ -1,7 +1,7 @@
grammar t023scopes;

options {
-    language=Python;
+    language=Python3;
}

prog
diff --git a/runtime/Python3/tests/t024finally.g b/runtime/Python3/tests/t024finally.g
index 1cd2527..a744de3 100644
--- a/runtime/Python3/tests/t024finally.g
+++ b/runtime/Python3/tests/t024finally.g
@@ -1,7 +1,7 @@
grammar t024finally;

options {
-    language=Python;
+    language=Python3;
}

prog returns [events]
diff --git a/runtime/Python3/tests/t024finally.py b/runtime/Python3/tests/t024finally.py
index 9a269dd..24d0b71 100644
--- a/runtime/Python3/tests/t024finally.py
+++ b/runtime/Python3/tests/t024finally.py
@@ -15,7 +15,7 @@ class t024finally(testbase.ANTLRTest):
parser = self.getParser(tStream)
events = parser.prog()

-        assert events == ['catch', 'finally'], events
+        self.assertEqual(events, ['catch', 'finally'])


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t025lexerRulePropertyRef.g b/runtime/Python3/tests/t025lexerRulePropertyRef.g
index b3500cc..0509375 100644
--- a/runtime/Python3/tests/t025lexerRulePropertyRef.g
+++ b/runtime/Python3/tests/t025lexerRulePropertyRef.g
@@ -1,6 +1,6 @@
lexer grammar t025lexerRulePropertyRef;
options {
-  language = Python;
+  language = Python3;
}

@lexer::init {
diff --git a/runtime/Python3/tests/t025lexerRulePropertyRef.py b/runtime/Python3/tests/t025lexerRulePropertyRef.py
index ae4ac79..5b23c25 100644
--- a/runtime/Python3/tests/t025lexerRulePropertyRef.py
+++ b/runtime/Python3/tests/t025lexerRulePropertyRef.py
@@ -17,37 +17,37 @@ class t025lexerRulePropertyRef(testbase.ANTLRTest):
if token.type == antlr3.EOF:
break

-        assert len(lexer.properties) == 3, lexer.properties
+        self.assertEqual(len(lexer.properties), 3, lexer.properties)

text, type, line, pos, index, channel, start, stop = lexer.properties[0]
-        assert text == 'foobar', lexer.properties[0]
-        assert type == self.lexerModule.IDENTIFIER, lexer.properties[0]
-        assert line == 1, lexer.properties[0]
-        assert pos == 0, lexer.properties[0]
-        assert index == -1, lexer.properties[0]
-        assert channel == antlr3.DEFAULT_CHANNEL, lexer.properties[0]
-        assert start == 0, lexer.properties[0]
-        assert stop == 5, lexer.properties[0]
+        self.assertEqual(text, 'foobar', lexer.properties[0])
+        self.assertEqual(type, self.lexerModule.IDENTIFIER, lexer.properties[0])
+        self.assertEqual(line, 1, lexer.properties[0])
+        self.assertEqual(pos, 0, lexer.properties[0])
+        self.assertEqual(index, -1, lexer.properties[0])
+        self.assertEqual(channel, antlr3.DEFAULT_CHANNEL, lexer.properties[0])
+        self.assertEqual(start, 0, lexer.properties[0])
+        self.assertEqual(stop, 5, lexer.properties[0])

text, type, line, pos, index, channel, start, stop = lexer.properties[1]
-        assert text == '_Ab98', lexer.properties[1]
-        assert type == self.lexerModule.IDENTIFIER, lexer.properties[1]
-        assert line == 1, lexer.properties[1]
-        assert pos == 7, lexer.properties[1]
-        assert index == -1, lexer.properties[1]
-        assert channel == antlr3.DEFAULT_CHANNEL, lexer.properties[1]
-        assert start == 7, lexer.properties[1]
-        assert stop == 11, lexer.properties[1]
+        self.assertEqual(text, '_Ab98', lexer.properties[1])
+        self.assertEqual(type, self.lexerModule.IDENTIFIER, lexer.properties[1])
+        self.assertEqual(line, 1, lexer.properties[1])
+        self.assertEqual(pos, 7, lexer.properties[1])
+        self.assertEqual(index, -1, lexer.properties[1])
+        self.assertEqual(channel, antlr3.DEFAULT_CHANNEL, lexer.properties[1])
+        self.assertEqual(start, 7, lexer.properties[1])
+        self.assertEqual(stop, 11, lexer.properties[1])

text, type, line, pos, index, channel, start, stop = lexer.properties[2]
-        assert text == 'A12sdf', lexer.properties[2]
-        assert type == self.lexerModule.IDENTIFIER, lexer.properties[2]
-        assert line == 2, lexer.properties[2]
-        assert pos == 1, lexer.properties[2]
-        assert index == -1, lexer.properties[2]
-        assert channel == antlr3.DEFAULT_CHANNEL, lexer.properties[2]
-        assert start == 15, lexer.properties[2]
-        assert stop == 20, lexer.properties[2]
+        self.assertEqual(text, 'A12sdf', lexer.properties[2])
+        self.assertEqual(type, self.lexerModule.IDENTIFIER, lexer.properties[2])
+        self.assertEqual(line, 2, lexer.properties[2])
+        self.assertEqual(pos, 1, lexer.properties[2])
+        self.assertEqual(index, -1, lexer.properties[2])
+        self.assertEqual(channel, antlr3.DEFAULT_CHANNEL, lexer.properties[2])
+        self.assertEqual(start, 15, lexer.properties[2])
+        self.assertEqual(stop, 20, lexer.properties[2])


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t026actions.g b/runtime/Python3/tests/t026actions.g
index e8f9fef..124be34 100644
--- a/runtime/Python3/tests/t026actions.g
+++ b/runtime/Python3/tests/t026actions.g
@@ -1,6 +1,6 @@
grammar t026actions;
options {
-  language = Python;
+  language = Python3;
}

@lexer::init {
@@ -16,7 +16,7 @@ prog
}
:   IDENTIFIER EOF
;
-    catch [ RecognitionException, exc ] {
+    catch [ RecognitionException as exc ] {
self.capture('catch;')
raise
}
@@ -30,7 +30,7 @@ IDENTIFIER
{
# a comment
self.capture('action;')
-            self.capture('\%r \%r \%r \%r \%r \%r \%r \%r;' \% ($text, $type, $line, $pos, $index, $channel, $start, $stop))
+            self.capture('{!r} {!r} {!r} {!r} {!r} {!r} {!r} {!r};'.format($text, $type, $line, $pos, $index, $channel, $start, $stop))
if True:
self.capture(self.foobar)
}
diff --git a/runtime/Python3/tests/t026actions.py b/runtime/Python3/tests/t026actions.py
index dd4e5d6..20dc88b 100644
--- a/runtime/Python3/tests/t026actions.py
+++ b/runtime/Python3/tests/t026actions.py
@@ -7,7 +7,7 @@ class t026actions(testbase.ANTLRTest):
def parserClass(self, base):
class TParser(base):
def __init__(self, *args, **kwargs):
-                base.__init__(self, *args, **kwargs)
+                super().__init__(*args, **kwargs)

self._errors = []
self._output = ""
@@ -27,7 +27,7 @@ class t026actions(testbase.ANTLRTest):
def lexerClass(self, base):
class TLexer(base):
def __init__(self, *args, **kwargs):
-                base.__init__(self, *args, **kwargs)
+                super().__init__(*args, **kwargs)

self._errors = []
self._output = ""
@@ -60,7 +60,9 @@ class t026actions(testbase.ANTLRTest):
'init;after;finally;')
self.assertEqual(
lexer._output,
-            'action;u\'foobar\' 4 1 0 -1 0 0 5;attribute;action;u\'_Ab98\' 4 1 7 -1 0 7 11;attribute;action;u\'A12sdf\' 4 2 1 -1 0 15 20;attribute;')
+            "action;'foobar' 4 1 0 -1 0 0 5;attribute;action;"
+            "'_Ab98' 4 1 7 -1 0 7 11;attribute;action;"
+            "'A12sdf' 4 2 1 -1 0 15 20;attribute;")

if __name__ == '__main__':
unittest.main()
diff --git a/runtime/Python3/tests/t027eof.g b/runtime/Python3/tests/t027eof.g
index 9cfbb3a..5c633a2 100644
--- a/runtime/Python3/tests/t027eof.g
+++ b/runtime/Python3/tests/t027eof.g
@@ -1,7 +1,7 @@
lexer grammar t027eof;

options {
-    language=Python;
+    language=Python3;
}

END: EOF;
diff --git a/runtime/Python3/tests/t027eof.py b/runtime/Python3/tests/t027eof.py
index b6ae18d..cf543b5 100644
--- a/runtime/Python3/tests/t027eof.py
+++ b/runtime/Python3/tests/t027eof.py
@@ -14,10 +14,10 @@ class t027eof(testbase.ANTLRTest):
lexer = self.getLexer(cStream)

tok = lexer.nextToken()
-        assert tok.type == self.lexerModule.SPACE, tok
+        self.assertEqual(tok.type, self.lexerModule.SPACE, tok)

tok = lexer.nextToken()
-        assert tok.type == self.lexerModule.END, tok
+        self.assertEqual(tok.type, self.lexerModule.END, tok)


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t029synpredgate.g b/runtime/Python3/tests/t029synpredgate.g
index 7900262..169892a 100644
--- a/runtime/Python3/tests/t029synpredgate.g
+++ b/runtime/Python3/tests/t029synpredgate.g
@@ -1,6 +1,6 @@
lexer grammar t029synpredgate;
options {
-  language = Python;
+  language = Python3;
}

FOO
diff --git a/runtime/Python3/tests/t030specialStates.g b/runtime/Python3/tests/t030specialStates.g
index 7b2e423..51451c4 100644
--- a/runtime/Python3/tests/t030specialStates.g
+++ b/runtime/Python3/tests/t030specialStates.g
@@ -1,6 +1,6 @@
grammar t030specialStates;
options {
-  language = Python;
+  language = Python3;
}

@init {
diff --git a/runtime/Python3/tests/t031emptyAlt.g b/runtime/Python3/tests/t031emptyAlt.g
index 0afa596..de7d46e 100644
--- a/runtime/Python3/tests/t031emptyAlt.g
+++ b/runtime/Python3/tests/t031emptyAlt.g
@@ -1,6 +1,6 @@
grammar t031emptyAlt;
options {
-  language = Python;
+  language = Python3;
}

r
diff --git a/runtime/Python3/tests/t032subrulePredict.g b/runtime/Python3/tests/t032subrulePredict.g
index 3cc2327..557f51f 100644
--- a/runtime/Python3/tests/t032subrulePredict.g
+++ b/runtime/Python3/tests/t032subrulePredict.g
@@ -1,6 +1,6 @@
grammar t032subrulePredict;
options {
-  language = Python;
+  language = Python3;
}

a: 'BEGIN' b WS+ 'END';
diff --git a/runtime/Python3/tests/t033backtracking.g b/runtime/Python3/tests/t033backtracking.g
index 85a4b30..447fac3 100644
--- a/runtime/Python3/tests/t033backtracking.g
+++ b/runtime/Python3/tests/t033backtracking.g
@@ -1,6 +1,6 @@
grammar t033backtracking;
options {
-    language=Python;
+    language=Python3;
backtrack=true;
memoize=true;
k=2;
@@ -10,25 +10,6 @@ scope Symbols {
types;
}

-@header {
-# compatibility stuff
-try:
-    set = set
-    frozenset = frozenset
-except NameError:
-    from sets import Set as set, ImmutableSet as frozenset
-
-
-try:
-    reversed = reversed
-except NameError:
-    def reversed(l):
-        l = l[:]
-        l.reverse()
-        return l
-
-}
-
@members {
def isTypeName(self, name):
for scope in reversed(self.Symbols_stack):
@@ -196,9 +177,9 @@ declarator
direct_declarator
:   (	IDENTIFIER
{
-			if len($declaration)>0 and $declaration::isTypedef:
+			if $declaration and $declaration::isTypedef:
$Symbols::types.add($IDENTIFIER.text)
-				print "define type "+$IDENTIFIER.text
+				print("define type "+$IDENTIFIER.text)
}
|	'(' declarator ')'
)
diff --git a/runtime/Python3/tests/t034tokenLabelPropertyRef.g b/runtime/Python3/tests/t034tokenLabelPropertyRef.g
index 7311235..5a0a35e 100644
--- a/runtime/Python3/tests/t034tokenLabelPropertyRef.g
+++ b/runtime/Python3/tests/t034tokenLabelPropertyRef.g
@@ -1,17 +1,17 @@
grammar t034tokenLabelPropertyRef;
options {
-  language = Python;
+  language = Python3;
}

a: t=A
{
-            print $t.text
-            print $t.type
-            print $t.line
-            print $t.pos
-            print $t.channel
-            print $t.index
-            #print $t.tree
+            print($t.text)
+            print($t.type)
+            print($t.line)
+            print($t.pos)
+            print($t.channel)
+            print($t.index)
+            #print($t.tree)
}
;

diff --git a/runtime/Python3/tests/t035ruleLabelPropertyRef.g b/runtime/Python3/tests/t035ruleLabelPropertyRef.g
index 710a91c..3725d34 100644
--- a/runtime/Python3/tests/t035ruleLabelPropertyRef.g
+++ b/runtime/Python3/tests/t035ruleLabelPropertyRef.g
@@ -1,6 +1,6 @@
grammar t035ruleLabelPropertyRef;
options {
-  language = Python;
+  language = Python3;
}

a returns [bla]: t=b
diff --git a/runtime/Python3/tests/t035ruleLabelPropertyRef.py b/runtime/Python3/tests/t035ruleLabelPropertyRef.py
index c42dbaa..3347801 100644
--- a/runtime/Python3/tests/t035ruleLabelPropertyRef.py
+++ b/runtime/Python3/tests/t035ruleLabelPropertyRef.py
@@ -35,12 +35,12 @@ class t035ruleLabelPropertyRef(testbase.ANTLRTest):
start, stop, text = parser.a()

# first token of rule b is the 2nd token (counting hidden tokens)
-        assert start.index == 1, start
+        self.assertEqual(start.index, 1, start)

# first token of rule b is the 7th token (counting hidden tokens)
-        assert stop.index == 7, stop
+        self.assertEqual(stop.index, 7, stop)

-        assert text == "a a a a", text
+        self.assertEqual(text, "a a a a")


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t036multipleReturnValues.g b/runtime/Python3/tests/t036multipleReturnValues.g
index 04ce14c..a3fc8a3 100644
--- a/runtime/Python3/tests/t036multipleReturnValues.g
+++ b/runtime/Python3/tests/t036multipleReturnValues.g
@@ -1,6 +1,6 @@
grammar t036multipleReturnValues;
options {
-  language = Python;
+  language = Python3;
}

a returns [foo, bar]: A
diff --git a/runtime/Python3/tests/t036multipleReturnValues.py b/runtime/Python3/tests/t036multipleReturnValues.py
index 97e04e3..8dd65be 100644
--- a/runtime/Python3/tests/t036multipleReturnValues.py
+++ b/runtime/Python3/tests/t036multipleReturnValues.py
@@ -33,8 +33,8 @@ class t036multipleReturnValues(testbase.ANTLRTest):
tStream = antlr3.CommonTokenStream(lexer)
parser = self.getParser(tStream)
ret = parser.a()
-        assert ret.foo == 'foo', ret.foo
-        assert ret.bar == 'bar', ret.bar
+        self.assertEqual(ret.foo, 'foo')
+        self.assertEqual(ret.bar, 'bar')


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t037rulePropertyRef.g b/runtime/Python3/tests/t037rulePropertyRef.g
index d2ab177..2069db1 100644
--- a/runtime/Python3/tests/t037rulePropertyRef.g
+++ b/runtime/Python3/tests/t037rulePropertyRef.g
@@ -1,6 +1,6 @@
grammar t037rulePropertyRef;
options {
-  language = Python;
+  language = Python3;
}

a returns [bla]
diff --git a/runtime/Python3/tests/t037rulePropertyRef.py b/runtime/Python3/tests/t037rulePropertyRef.py
index 998a2ba..bba4f3c 100644
--- a/runtime/Python3/tests/t037rulePropertyRef.py
+++ b/runtime/Python3/tests/t037rulePropertyRef.py
@@ -35,12 +35,12 @@ class t037rulePropertyRef(testbase.ANTLRTest):
start, stop, text = parser.a().bla

# first token of rule b is the 2nd token (counting hidden tokens)
-        assert start.index == 1, start
+        self.assertEqual(start.index, 1, start)

# first token of rule b is the 7th token (counting hidden tokens)
-        assert stop.index == 7, stop
+        self.assertEqual(stop.index, 7, stop)

-        assert text == "a a a a", text
+        self.assertEqual(text, "a a a a")


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t038lexerRuleLabel.g b/runtime/Python3/tests/t038lexerRuleLabel.g
index fcc1a61..8a6967d 100644
--- a/runtime/Python3/tests/t038lexerRuleLabel.g
+++ b/runtime/Python3/tests/t038lexerRuleLabel.g
@@ -1,17 +1,17 @@
lexer grammar t038lexerRuleLabel;
options {
-  language = Python;
+  language = Python3;
}

A: 'a'..'z' WS '0'..'9'
{
-            print $WS
-            print $WS.type
-            print $WS.line
-            print $WS.pos
-            print $WS.channel
-            print $WS.index
-            print $WS.text
+            print($WS)
+            print($WS.type)
+            print($WS.line)
+            print($WS.pos)
+            print($WS.channel)
+            print($WS.index)
+            print($WS.text)
}
;

diff --git a/runtime/Python3/tests/t038lexerRuleLabel.py b/runtime/Python3/tests/t038lexerRuleLabel.py
index 2af65f9..7b2e55a 100644
--- a/runtime/Python3/tests/t038lexerRuleLabel.py
+++ b/runtime/Python3/tests/t038lexerRuleLabel.py
@@ -26,7 +26,7 @@ class t038lexerRuleLabel(testbase.ANTLRTest):
t = lexer.nextToken()
if t.type == antlr3.EOF:
break
-            print t
+            print(t)


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t039labels.g b/runtime/Python3/tests/t039labels.g
index d9dc248..12aa649 100644
--- a/runtime/Python3/tests/t039labels.g
+++ b/runtime/Python3/tests/t039labels.g
@@ -1,6 +1,6 @@
grammar t039labels;
options {
-  language = Python;
+  language = Python3;
}

a returns [l]
@@ -10,9 +10,9 @@ a returns [l]

A: 'a'..'z';
B: '0'..'9';
-C: a='A' { print $a };
-D: a='FOOBAR' { print $a };
-E: 'GNU' a=. { print $a };
-F: 'BLARZ' a=EOF { print $a };
+C: a='A' { print($a) };
+D: a='FOOBAR' { print($a) };
+E: 'GNU' a=. { print($a) };
+F: 'BLARZ' a=EOF { print($a) };

WS: ' '+  { $channel = HIDDEN };
diff --git a/runtime/Python3/tests/t039labels.py b/runtime/Python3/tests/t039labels.py
index 8159d6b..9744017 100644
--- a/runtime/Python3/tests/t039labels.py
+++ b/runtime/Python3/tests/t039labels.py
@@ -36,15 +36,15 @@ class t039labels(testbase.ANTLRTest):
parser = self.getParser(tStream)
ids, w = parser.a()

-        assert len(ids) == 6, ids
-        assert ids[0].text == 'a', ids[0]
-        assert ids[1].text == 'b', ids[1]
-        assert ids[2].text == 'c', ids[2]
-        assert ids[3].text == '1', ids[3]
-        assert ids[4].text == '2', ids[4]
-        assert ids[5].text == 'A', ids[5]
-
-        assert w.text == 'GNU1', w
+        self.assertEqual(len(ids), 6, ids)
+        self.assertEqual(ids[0].text, 'a', ids[0])
+        self.assertEqual(ids[1].text, 'b', ids[1])
+        self.assertEqual(ids[2].text, 'c', ids[2])
+        self.assertEqual(ids[3].text, '1', ids[3])
+        self.assertEqual(ids[4].text, '2', ids[4])
+        self.assertEqual(ids[5].text, 'A', ids[5])
+
+        self.assertEqual(w.text, 'GNU1', w)


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t040bug80.g b/runtime/Python3/tests/t040bug80.g
index bdf610b..dbd87c0 100644
--- a/runtime/Python3/tests/t040bug80.g
+++ b/runtime/Python3/tests/t040bug80.g
@@ -1,6 +1,6 @@
lexer grammar t040bug80;
options {
-  language = Python;
+  language = Python3;
}

ID_LIKE
diff --git a/runtime/Python3/tests/t040bug80.py b/runtime/Python3/tests/t040bug80.py
index c6637e5..34c48b9 100644
--- a/runtime/Python3/tests/t040bug80.py
+++ b/runtime/Python3/tests/t040bug80.py
@@ -24,7 +24,7 @@ class t040bug80(testbase.ANTLRTest):
t = lexer.nextToken()
if t.type == antlr3.EOF:
break
-            print t
+            print(t)


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t041parameters.g b/runtime/Python3/tests/t041parameters.g
index b9a8892..44db5bf 100644
--- a/runtime/Python3/tests/t041parameters.g
+++ b/runtime/Python3/tests/t041parameters.g
@@ -1,6 +1,6 @@
grammar t041parameters;
options {
-  language = Python;
+  language = Python3;
}

a[arg1, arg2] returns [l]
diff --git a/runtime/Python3/tests/t041parameters.py b/runtime/Python3/tests/t041parameters.py
index 1fe4a4f..e4bc8c0 100644
--- a/runtime/Python3/tests/t041parameters.py
+++ b/runtime/Python3/tests/t041parameters.py
@@ -34,7 +34,7 @@ class t041parameters(testbase.ANTLRTest):
parser = self.getParser(tStream)
r = parser.a('foo', 'bar')

-        assert r == ('foo', 'bar'), r
+        self.assertEqual(r, ('foo', 'bar'))


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t042ast.g b/runtime/Python3/tests/t042ast.g
index f676835..5d2b9b9 100644
--- a/runtime/Python3/tests/t042ast.g
+++ b/runtime/Python3/tests/t042ast.g
@@ -1,6 +1,6 @@
grammar t042ast;
options {
-    language = Python;
+    language = Python3;
output = AST;
}

diff --git a/runtime/Python3/tests/t042ast.py b/runtime/Python3/tests/t042ast.py
index e29c077..559d5f1 100644
--- a/runtime/Python3/tests/t042ast.py
+++ b/runtime/Python3/tests/t042ast.py
@@ -22,7 +22,7 @@ class t042ast(testbase.ANTLRTest):
return TParser


-    def parse(self, text, method, rArgs=[], **kwargs):
+    def parse(self, text, method, rArgs=(), **kwargs):
self.compileGrammar() #options='-trace')

cStream = antlr3.StringStream(text)
@@ -38,7 +38,7 @@ class t042ast(testbase.ANTLRTest):

def testR1(self):
r = self.parse("1 + 2", 'r1')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(+ 1 2)'
)
@@ -46,7 +46,7 @@ class t042ast(testbase.ANTLRTest):

def testR2a(self):
r = self.parse("assert 2+3;", 'r2')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(assert (+ 2 3))'
)
@@ -54,7 +54,7 @@ class t042ast(testbase.ANTLRTest):

def testR2b(self):
r = self.parse("assert 2+3 : 5;", 'r2')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(assert (+ 2 3) 5)'
)
@@ -62,7 +62,7 @@ class t042ast(testbase.ANTLRTest):

def testR3a(self):
r = self.parse("if 1 fooze", 'r3')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(if 1 fooze)'
)
@@ -70,7 +70,7 @@ class t042ast(testbase.ANTLRTest):

def testR3b(self):
r = self.parse("if 1 fooze else fooze", 'r3')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(if 1 fooze fooze)'
)
@@ -78,7 +78,7 @@ class t042ast(testbase.ANTLRTest):

def testR4a(self):
r = self.parse("while 2 fooze", 'r4')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(while 2 fooze)'
)
@@ -86,7 +86,7 @@ class t042ast(testbase.ANTLRTest):

def testR5a(self):
r = self.parse("return;", 'r5')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'return'
)
@@ -94,7 +94,7 @@ class t042ast(testbase.ANTLRTest):

def testR5b(self):
r = self.parse("return 2+3;", 'r5')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(return (+ 2 3))'
)
@@ -102,7 +102,7 @@ class t042ast(testbase.ANTLRTest):

def testR6a(self):
r = self.parse("3", 'r6')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'3'
)
@@ -110,7 +110,7 @@ class t042ast(testbase.ANTLRTest):

def testR6b(self):
r = self.parse("3 a", 'r6')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'3 a'
)
@@ -118,14 +118,12 @@ class t042ast(testbase.ANTLRTest):

def testR7(self):
r = self.parse("3", 'r7')
-        self.failUnless(
-            r.tree is None
-            )
+        self.assertIsNone(r.tree)


def testR8(self):
r = self.parse("var foo:bool", 'r8')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(var bool foo)'
)
@@ -133,7 +131,7 @@ class t042ast(testbase.ANTLRTest):

def testR9(self):
r = self.parse("int foo;", 'r9')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(VARDEF int foo)'
)
@@ -141,7 +139,7 @@ class t042ast(testbase.ANTLRTest):

def testR10(self):
r = self.parse("10", 'r10')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'10.0'
)
@@ -149,7 +147,7 @@ class t042ast(testbase.ANTLRTest):

def testR11a(self):
r = self.parse("1+2", 'r11')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(EXPR (+ 1 2))'
)
@@ -157,7 +155,7 @@ class t042ast(testbase.ANTLRTest):

def testR11b(self):
r = self.parse("", 'r11')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'EXPR'
)
@@ -165,7 +163,7 @@ class t042ast(testbase.ANTLRTest):

def testR12a(self):
r = self.parse("foo", 'r12')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'foo'
)
@@ -173,7 +171,7 @@ class t042ast(testbase.ANTLRTest):

def testR12b(self):
r = self.parse("foo, bar, gnurz", 'r12')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'foo bar gnurz'
)
@@ -181,7 +179,7 @@ class t042ast(testbase.ANTLRTest):

def testR13a(self):
r = self.parse("int foo;", 'r13')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(int foo)'
)
@@ -189,7 +187,7 @@ class t042ast(testbase.ANTLRTest):

def testR13b(self):
r = self.parse("bool foo, bar, gnurz;", 'r13')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(bool foo bar gnurz)'
)
@@ -197,7 +195,7 @@ class t042ast(testbase.ANTLRTest):

def testR14a(self):
r = self.parse("1+2 int", 'r14')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(EXPR (+ 1 2) int)'
)
@@ -205,7 +203,7 @@ class t042ast(testbase.ANTLRTest):

def testR14b(self):
r = self.parse("1+2 int bool", 'r14')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(EXPR (+ 1 2) int bool)'
)
@@ -213,7 +211,7 @@ class t042ast(testbase.ANTLRTest):

def testR14c(self):
r = self.parse("int bool", 'r14')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(EXPR int bool)'
)
@@ -221,7 +219,7 @@ class t042ast(testbase.ANTLRTest):

def testR14d(self):
r = self.parse("fooze fooze int bool", 'r14')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(EXPR fooze fooze int bool)'
)
@@ -229,7 +227,7 @@ class t042ast(testbase.ANTLRTest):

def testR14e(self):
r = self.parse("7+9 fooze fooze int bool", 'r14')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(EXPR (+ 7 9) fooze fooze int bool)'
)
@@ -237,7 +235,7 @@ class t042ast(testbase.ANTLRTest):

def testR15(self):
r = self.parse("7", 'r15')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'7 7'
)
@@ -245,7 +243,7 @@ class t042ast(testbase.ANTLRTest):

def testR16a(self):
r = self.parse("int foo", 'r16')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(int foo)'
)
@@ -254,7 +252,7 @@ class t042ast(testbase.ANTLRTest):
def testR16b(self):
r = self.parse("int foo, bar, gnurz", 'r16')

-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(int foo) (int bar) (int gnurz)'
)
@@ -262,7 +260,7 @@ class t042ast(testbase.ANTLRTest):

def testR17a(self):
r = self.parse("for ( fooze ; 1 + 2 ; fooze ) fooze", 'r17')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(for fooze (+ 1 2) fooze fooze)'
)
@@ -270,7 +268,7 @@ class t042ast(testbase.ANTLRTest):

def testR18a(self):
r = self.parse("for", 'r18')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'BLOCK'
)
@@ -278,7 +276,7 @@ class t042ast(testbase.ANTLRTest):

def testR19a(self):
r = self.parse("for", 'r19')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'for'
)
@@ -286,7 +284,7 @@ class t042ast(testbase.ANTLRTest):

def testR20a(self):
r = self.parse("for", 'r20')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'FOR'
)
@@ -294,7 +292,7 @@ class t042ast(testbase.ANTLRTest):

def testR21a(self):
r = self.parse("for", 'r21')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'BLOCK'
)
@@ -302,7 +300,7 @@ class t042ast(testbase.ANTLRTest):

def testR22a(self):
r = self.parse("for", 'r22')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'for'
)
@@ -310,7 +308,7 @@ class t042ast(testbase.ANTLRTest):

def testR23a(self):
r = self.parse("for", 'r23')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'FOR'
)
@@ -318,7 +316,7 @@ class t042ast(testbase.ANTLRTest):

def testR24a(self):
r = self.parse("fooze 1 + 2", 'r24')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(fooze (+ 1 2))'
)
@@ -326,7 +324,7 @@ class t042ast(testbase.ANTLRTest):

def testR25a(self):
r = self.parse("fooze, fooze2 1 + 2", 'r25')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(fooze (+ 1 2))'
)
@@ -334,7 +332,7 @@ class t042ast(testbase.ANTLRTest):

def testR26a(self):
r = self.parse("fooze, fooze2", 'r26')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(BLOCK fooze fooze2)'
)
@@ -342,7 +340,7 @@ class t042ast(testbase.ANTLRTest):

def testR27a(self):
r = self.parse("fooze 1 + 2", 'r27')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(fooze (fooze (+ 1 2)))'
)
@@ -350,17 +348,11 @@ class t042ast(testbase.ANTLRTest):

def testR28(self):
r = self.parse("foo28a", 'r28')
-        self.failUnless(
-            r.tree is None
-            )
+        self.assertIsNone(r.tree)


def testR29(self):
-        try:
-            r = self.parse("", 'r29')
-            self.fail()
-        except RuntimeError:
-            pass
+        self.assertRaises(RuntimeError, self.parse, "", 'r29')


# FIXME: broken upstream?
@@ -374,7 +366,7 @@ class t042ast(testbase.ANTLRTest):

def testR31a(self):
r = self.parse("public int gnurz = 1 + 2;", 'r31', flag=0)
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(VARDEF gnurz public int (+ 1 2))'
)
@@ -382,7 +374,7 @@ class t042ast(testbase.ANTLRTest):

def testR31b(self):
r = self.parse("public int gnurz = 1 + 2;", 'r31', flag=1)
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(VARIABLE gnurz public int (+ 1 2))'
)
@@ -390,7 +382,7 @@ class t042ast(testbase.ANTLRTest):

def testR31c(self):
r = self.parse("public int gnurz = 1 + 2;", 'r31', flag=2)
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(FIELD gnurz public int (+ 1 2))'
)
@@ -398,7 +390,7 @@ class t042ast(testbase.ANTLRTest):

def testR32a(self):
r = self.parse("gnurz 32", 'r32', [1], flag=2)
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'gnurz'
)
@@ -406,7 +398,7 @@ class t042ast(testbase.ANTLRTest):

def testR32b(self):
r = self.parse("gnurz 32", 'r32', [2], flag=2)
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'32'
)
@@ -414,14 +406,12 @@ class t042ast(testbase.ANTLRTest):

def testR32c(self):
r = self.parse("gnurz 32", 'r32', [3], flag=2)
-        self.failUnless(
-            r.tree is None
-            )
+        self.assertIsNone(r.tree)


def testR33a(self):
r = self.parse("public private fooze", 'r33')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'fooze'
)
@@ -429,7 +419,7 @@ class t042ast(testbase.ANTLRTest):

def testR34a(self):
r = self.parse("public class gnurz { fooze fooze2 }", 'r34')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(class gnurz public fooze fooze2)'
)
@@ -437,24 +427,19 @@ class t042ast(testbase.ANTLRTest):

def testR34b(self):
r = self.parse("public class gnurz extends bool implements int, bool { fooze fooze2 }", 'r34')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(class gnurz public (extends bool) (implements int bool) fooze fooze2)'
)


def testR35(self):
-        try:
-            r = self.parse("{ extends }", 'r35')
-            self.fail()
-
-        except RuntimeError:
-            pass
+        self.assertRaises(RuntimeError, self.parse, "{ extends }", 'r35')


def testR36a(self):
r = self.parse("if ( 1 + 2 ) fooze", 'r36')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(if (EXPR (+ 1 2)) fooze)'
)
@@ -462,7 +447,7 @@ class t042ast(testbase.ANTLRTest):

def testR36b(self):
r = self.parse("if ( 1 + 2 ) fooze else fooze2", 'r36')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(if (EXPR (+ 1 2)) fooze fooze2)'
)
@@ -470,7 +455,7 @@ class t042ast(testbase.ANTLRTest):

def testR37(self):
r = self.parse("1 + 2 + 3", 'r37')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(+ (+ 1 2) 3)'
)
@@ -478,7 +463,7 @@ class t042ast(testbase.ANTLRTest):

def testR38(self):
r = self.parse("1 + 2 + 3", 'r38')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(+ (+ 1 2) 3)'
)
@@ -486,7 +471,7 @@ class t042ast(testbase.ANTLRTest):

def testR39a(self):
r = self.parse("gnurz[1]", 'r39')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(INDEX gnurz 1)'
)
@@ -494,7 +479,7 @@ class t042ast(testbase.ANTLRTest):

def testR39b(self):
r = self.parse("gnurz(2)", 'r39')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(CALL gnurz 2)'
)
@@ -502,7 +487,7 @@ class t042ast(testbase.ANTLRTest):

def testR39c(self):
r = self.parse("gnurz.gnarz", 'r39')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(FIELDACCESS gnurz gnarz)'
)
@@ -510,7 +495,7 @@ class t042ast(testbase.ANTLRTest):

def testR39d(self):
r = self.parse("gnurz.gnarz.gnorz", 'r39')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(FIELDACCESS (FIELDACCESS gnurz gnarz) gnorz)'
)
@@ -518,7 +503,7 @@ class t042ast(testbase.ANTLRTest):

def testR40(self):
r = self.parse("1 + 2 + 3;", 'r40')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(+ 1 2 3)'
)
@@ -526,7 +511,7 @@ class t042ast(testbase.ANTLRTest):

def testR41(self):
r = self.parse("1 + 2 + 3;", 'r41')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(3 (2 1))'
)
@@ -534,7 +519,7 @@ class t042ast(testbase.ANTLRTest):

def testR42(self):
r = self.parse("gnurz, gnarz, gnorz", 'r42')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'gnurz gnarz gnorz'
)
@@ -542,10 +527,8 @@ class t042ast(testbase.ANTLRTest):

def testR43(self):
r = self.parse("gnurz, gnarz, gnorz", 'r43')
-        self.failUnless(
-            r.tree is None
-            )
-        self.failUnlessEqual(
+        self.assertIsNone(r.tree)
+        self.assertEqual(
r.res,
['gnurz', 'gnarz', 'gnorz']
)
@@ -553,7 +536,7 @@ class t042ast(testbase.ANTLRTest):

def testR44(self):
r = self.parse("gnurz, gnarz, gnorz", 'r44')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(gnorz (gnarz gnurz))'
)
@@ -561,7 +544,7 @@ class t042ast(testbase.ANTLRTest):

def testR45(self):
r = self.parse("gnurz", 'r45')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'gnurz'
)
@@ -569,10 +552,8 @@ class t042ast(testbase.ANTLRTest):

def testR46(self):
r = self.parse("gnurz, gnarz, gnorz", 'r46')
-        self.failUnless(
-            r.tree is None
-            )
-        self.failUnlessEqual(
+        self.assertIsNone(r.tree)
+        self.assertEqual(
r.res,
['gnurz', 'gnarz', 'gnorz']
)
@@ -580,7 +561,7 @@ class t042ast(testbase.ANTLRTest):

def testR47(self):
r = self.parse("gnurz, gnarz, gnorz", 'r47')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'gnurz gnarz gnorz'
)
@@ -588,7 +569,7 @@ class t042ast(testbase.ANTLRTest):

def testR48(self):
r = self.parse("gnurz, gnarz, gnorz", 'r48')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'gnurz gnarz gnorz'
)
@@ -596,7 +577,7 @@ class t042ast(testbase.ANTLRTest):

def testR49(self):
r = self.parse("gnurz gnorz", 'r49')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(gnurz gnorz)'
)
@@ -604,7 +585,7 @@ class t042ast(testbase.ANTLRTest):

def testR50(self):
r = self.parse("gnurz", 'r50')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(1.0 gnurz)'
)
@@ -612,7 +593,7 @@ class t042ast(testbase.ANTLRTest):

def testR51(self):
r = self.parse("gnurza gnurzb gnurzc", 'r51')
-        self.failUnlessEqual(
+        self.assertEqual(
r.res.toStringTree(),
'gnurzb'
)
@@ -620,7 +601,7 @@ class t042ast(testbase.ANTLRTest):

def testR52(self):
r = self.parse("gnurz", 'r52')
-        self.failUnlessEqual(
+        self.assertEqual(
r.res.toStringTree(),
'gnurz'
)
@@ -628,7 +609,7 @@ class t042ast(testbase.ANTLRTest):

def testR53(self):
r = self.parse("gnurz", 'r53')
-        self.failUnlessEqual(
+        self.assertEqual(
r.res.toStringTree(),
'gnurz'
)
@@ -636,7 +617,7 @@ class t042ast(testbase.ANTLRTest):

def testR54(self):
r = self.parse("gnurza 1 + 2 gnurzb", 'r54')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(+ 1 2)'
)
@@ -644,7 +625,7 @@ class t042ast(testbase.ANTLRTest):

def testR55a(self):
r = self.parse("public private 1 + 2", 'r55')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'public private (+ 1 2)'
)
@@ -652,7 +633,7 @@ class t042ast(testbase.ANTLRTest):

def testR55b(self):
r = self.parse("public fooze", 'r55')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'public fooze'
)
@@ -660,7 +641,7 @@ class t042ast(testbase.ANTLRTest):

def testR56(self):
r = self.parse("a b c d", 'r56')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'foo'
)
@@ -668,7 +649,7 @@ class t042ast(testbase.ANTLRTest):

def testR57(self):
r = self.parse("a b c d", 'r57')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'foo'
)
@@ -676,7 +657,7 @@ class t042ast(testbase.ANTLRTest):

def testR59(self):
r = self.parse("a b c fooze", 'r59')
-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
'(a fooze) (b fooze) (c fooze)'
)
diff --git a/runtime/Python3/tests/t043synpred.g b/runtime/Python3/tests/t043synpred.g
index 7294f23..478b8be 100644
--- a/runtime/Python3/tests/t043synpred.g
+++ b/runtime/Python3/tests/t043synpred.g
@@ -1,6 +1,6 @@
grammar t043synpred;
options {
-  language = Python;
+  language = Python3;
}

a: ((s+ P)=> s+ b)? E;
diff --git a/runtime/Python3/tests/t044trace.g b/runtime/Python3/tests/t044trace.g
index 0b7aa71..e170bba 100644
--- a/runtime/Python3/tests/t044trace.g
+++ b/runtime/Python3/tests/t044trace.g
@@ -1,6 +1,6 @@
grammar t044trace;
options {
-  language = Python;
+  language = Python3;
}

@init {
diff --git a/runtime/Python3/tests/t044trace.py b/runtime/Python3/tests/t044trace.py
index 13c9b76..2d60b61 100644
--- a/runtime/Python3/tests/t044trace.py
+++ b/runtime/Python3/tests/t044trace.py
@@ -11,7 +11,7 @@ class T(testbase.ANTLRTest):
def lexerClass(self, base):
class TLexer(base):
def __init__(self, *args, **kwargs):
-                base.__init__(self, *args, **kwargs)
+                super().__init__(*args, **kwargs)

self.traces = []

@@ -34,7 +34,7 @@ class T(testbase.ANTLRTest):
def parserClass(self, base):
class TParser(base):
def __init__(self, *args, **kwargs):
-                base.__init__(self, *args, **kwargs)
+                super().__init__(*args, **kwargs)

self.traces = []

@@ -64,7 +64,7 @@ class T(testbase.ANTLRTest):
parser = self.getParser(tStream)
parser.a()

-        self.failUnlessEqual(
+        self.assertEqual(
lexer.traces,
[ '>T__7', '<T__7', '>WS', '<WS', '>INT', '<INT', '>WS', '<WS',
'>T__6', '<T__6', '>WS', '<WS', '>INT', '<INT', '>WS', '<WS',
@@ -72,7 +72,7 @@ class T(testbase.ANTLRTest):
'>T__8', '<T__8']
)

-        self.failUnlessEqual(
+        self.assertEqual(
parser.traces,
[ '>a', '>synpred1_t044trace_fragment', '<synpred1_t044trace_fragment', '>b', '>c',
'<c', '>c', '<c', '>c', '<c', '<b', '<a' ]
@@ -86,10 +86,7 @@ class T(testbase.ANTLRTest):
parser = self.getParser(tStream)
parser.a()

-        self.failUnlessEqual(
-            parser._stack,
-            ['a', 'b', 'c']
-            )
+        self.assertEqual(parser._stack, ['a', 'b', 'c'])

if __name__ == '__main__':
unittest.main()
diff --git a/runtime/Python3/tests/t045dfabug.g b/runtime/Python3/tests/t045dfabug.g
index 4ad895b..436aefa 100644
--- a/runtime/Python3/tests/t045dfabug.g
+++ b/runtime/Python3/tests/t045dfabug.g
@@ -1,6 +1,6 @@
grammar t045dfabug;
options {
-    language = Python;
+    language = Python3;
output = AST;
}

diff --git a/runtime/Python3/tests/t046rewrite.g b/runtime/Python3/tests/t046rewrite.g
index e8dc1dc..58e4071 100644
--- a/runtime/Python3/tests/t046rewrite.g
+++ b/runtime/Python3/tests/t046rewrite.g
@@ -1,6 +1,6 @@
grammar t046rewrite;
options {
-    language=Python;
+    language=Python3;
}

program
diff --git a/runtime/Python3/tests/t046rewrite.py b/runtime/Python3/tests/t046rewrite.py
index a61ede4..be1f4aa 100644
--- a/runtime/Python3/tests/t046rewrite.py
+++ b/runtime/Python3/tests/t046rewrite.py
@@ -44,10 +44,7 @@ class T(testbase.ANTLRTest):

''')

-        self.failUnlessEqual(
-            str(tStream),
-            expectedOutput
-            )
+        self.assertEqual(str(tStream), expectedOutput)


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t047treeparser.g b/runtime/Python3/tests/t047treeparser.g
index 7e50ac4..30cd25e 100644
--- a/runtime/Python3/tests/t047treeparser.g
+++ b/runtime/Python3/tests/t047treeparser.g
@@ -1,6 +1,6 @@
grammar t047treeparser;
options {
-    language=Python;
+    language=Python3;
output=AST;
}

diff --git a/runtime/Python3/tests/t047treeparser.py b/runtime/Python3/tests/t047treeparser.py
index 1c0cb05..5b866b2 100644
--- a/runtime/Python3/tests/t047treeparser.py
+++ b/runtime/Python3/tests/t047treeparser.py
@@ -8,7 +8,7 @@ class T(testbase.ANTLRTest):
def walkerClass(self, base):
class TWalker(base):
def __init__(self, *args, **kwargs):
-                base.__init__(self, *args, **kwargs)
+                super().__init__(*args, **kwargs)

self.traces = []

@@ -56,7 +56,7 @@ class T(testbase.ANTLRTest):
parser = self.getParser(tStream)
r = parser.program()

-        self.failUnlessEqual(
+        self.assertEqual(
r.tree.toStringTree(),
"(VAR_DEF char c) (VAR_DEF int x) (FUNC_DECL (FUNC_HDR void bar (ARG_DEF int x))) (FUNC_DEF (FUNC_HDR int foo (ARG_DEF int y) (ARG_DEF char d)) (BLOCK (VAR_DEF int i) (for (= i 0) (< i 3) (= i (+ i 1)) (BLOCK (= x 3) (= y 5)))))"
)
@@ -69,7 +69,7 @@ class T(testbase.ANTLRTest):
# FIXME: need to crosscheck with Java target (compile walker with
# -trace option), if this is the real list. For now I'm happy that
# it does not crash ;)
-        self.failUnlessEqual(
+        self.assertEqual(
walker.traces,
[ '>program', '>declaration', '>variable', '>type', '<type',
'>declarator', '<declarator', '<variable', '<declaration',
@@ -115,7 +115,7 @@ class T(testbase.ANTLRTest):
walker = self.getWalker(nodes)
r = walker.variable()

-        self.failUnlessEqual(r, 'c')
+        self.assertEqual(r, 'c')


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t047treeparserWalker.g b/runtime/Python3/tests/t047treeparserWalker.g
index b6e0b3c..e78b1df 100644
--- a/runtime/Python3/tests/t047treeparserWalker.g
+++ b/runtime/Python3/tests/t047treeparserWalker.g
@@ -1,6 +1,6 @@
tree grammar t047treeparserWalker;
options {
-    language=Python;
+    language=Python3;
tokenVocab=t047treeparser;
ASTLabelType=CommonTree;
}
diff --git a/runtime/Python3/tests/t048rewrite.g b/runtime/Python3/tests/t048rewrite.g
index 4103b82..e15e76d 100644
--- a/runtime/Python3/tests/t048rewrite.g
+++ b/runtime/Python3/tests/t048rewrite.g
@@ -1,6 +1,6 @@
lexer grammar t048rewrite;
options {
-    language=Python;
+    language=Python3;
}

A: 'a';
diff --git a/runtime/Python3/tests/t048rewrite.py b/runtime/Python3/tests/t048rewrite.py
index 685bf86..76edbfe 100644
--- a/runtime/Python3/tests/t048rewrite.py
+++ b/runtime/Python3/tests/t048rewrite.py
@@ -27,7 +27,7 @@ class T1(testbase.ANTLRTest):

result = tokens.toString()
expecting = "0abc"
-        self.failUnlessEqual(result, expecting)
+        self.assertEqual(result, expecting)


def testInsertAfterLastIndex(self):
@@ -36,7 +36,7 @@ class T1(testbase.ANTLRTest):

result = tokens.toString()
expecting = "abcx"
-        self.failUnlessEqual(result, expecting)
+        self.assertEqual(result, expecting)


def test2InsertBeforeAfterMiddleIndex(self):
@@ -46,7 +46,7 @@ class T1(testbase.ANTLRTest):

result = tokens.toString()
expecting = "axbxc"
-        self.failUnlessEqual(result, expecting)
+        self.assertEqual(result, expecting)


def testReplaceIndex0(self):
@@ -55,7 +55,7 @@ class T1(testbase.ANTLRTest):

result = tokens.toString()
expecting = "xbc"
-        self.failUnlessEqual(result, expecting)
+        self.assertEqual(result, expecting)


def testReplaceLastIndex(self):
@@ -64,7 +64,7 @@ class T1(testbase.ANTLRTest):

result = tokens.toString()
expecting = "abx"
-        self.failUnlessEqual(result, expecting)
+        self.assertEqual(result, expecting)


def testReplaceMiddleIndex(self):
@@ -73,7 +73,7 @@ class T1(testbase.ANTLRTest):

result = tokens.toString()
expecting = "axc"
-        self.failUnlessEqual(result, expecting)
+        self.assertEqual(result, expecting)


def test2ReplaceMiddleIndex(self):
@@ -83,7 +83,7 @@ class T1(testbase.ANTLRTest):

result = tokens.toString()
expecting = "ayc"
-        self.failUnlessEqual(result, expecting)
+        self.assertEqual(result, expecting)


def test2ReplaceMiddleIndex1InsertBefore(self):
@@ -94,7 +94,7 @@ class T1(testbase.ANTLRTest):

result = tokens.toString()
expecting = "_ayc"
-        self.failUnlessEqual(expecting, result)
+        self.assertEqual(expecting, result)


def testReplaceThenDeleteMiddleIndex(self):
@@ -104,22 +104,18 @@ class T1(testbase.ANTLRTest):

result = tokens.toString()
expecting = "ac"
-        self.failUnlessEqual(result, expecting)
+        self.assertEqual(result, expecting)


def testInsertInPriorReplace(self):
tokens = self._parse("abc")
tokens.replace(0, 2, "x")
tokens.insertBefore(1, "0")
-        try:
-            tokens.toString()
-            self.fail()
-        except ValueError, exc:
-            self.failUnlessEqual(
-                str(exc),
-                "insert op <InsertBeforeOp@1:\"0\"> within boundaries of "
-                "previous <ReplaceOp@0..2:\"x\">"
-                )
+        self.assertRaisesRegex(
+            ValueError,
+            (r'insert op <InsertBeforeOp@1:"0"> within boundaries of '
+             r'previous <ReplaceOp@0\.\.2:"x">'),
+            tokens.toString)

def testInsertThenReplaceSameIndex(self):
tokens = self._parse("abc")
@@ -128,7 +124,7 @@ class T1(testbase.ANTLRTest):

result = tokens.toString()
expecting = "0xbc"
-        self.failUnlessEqual(result, expecting)
+        self.assertEqual(result, expecting)


def test2InsertMiddleIndex(self):
@@ -138,7 +134,7 @@ class T1(testbase.ANTLRTest):

result = tokens.toString()
expecting = "ayxbc"
-        self.failUnlessEqual(result, expecting)
+        self.assertEqual(result, expecting)


def test2InsertThenReplaceIndex0(self):
@@ -149,7 +145,7 @@ class T1(testbase.ANTLRTest):

result = tokens.toString()
expecting = "yxzbc"
-        self.failUnlessEqual(result, expecting)
+        self.assertEqual(result, expecting)


def testReplaceThenInsertBeforeLastIndex(self):
@@ -159,7 +155,7 @@ class T1(testbase.ANTLRTest):

result = tokens.toString()
expecting = "abyx"
-        self.failUnlessEqual(result, expecting)
+        self.assertEqual(result, expecting)


def testInsertThenReplaceLastIndex(self):
@@ -169,7 +165,7 @@ class T1(testbase.ANTLRTest):

result = tokens.toString()
expecting = "abyx"
-        self.failUnlessEqual(result, expecting)
+        self.assertEqual(result, expecting)


def testReplaceThenInsertAfterLastIndex(self):
@@ -179,7 +175,7 @@ class T1(testbase.ANTLRTest):

result = tokens.toString()
expecting = "abxy"
-        self.failUnlessEqual(result, expecting)
+        self.assertEqual(result, expecting)


def testReplaceRangeThenInsertAtLeftEdge(self):
@@ -189,7 +185,7 @@ class T1(testbase.ANTLRTest):

result = tokens.toString()
expecting = "abyxba"
-        self.failUnlessEqual(result, expecting)
+        self.assertEqual(result, expecting)


def testReplaceRangeThenInsertAtRightEdge(self):
@@ -197,14 +193,11 @@ class T1(testbase.ANTLRTest):
tokens.replace(2, 4, "x")
tokens.insertBefore(4, "y") # no effect; within range of a replace

-        try:
-            tokens.toString()
-            self.fail()
-        except ValueError, exc:
-            self.failUnlessEqual(
-                str(exc),
-                "insert op <InsertBeforeOp@4:\"y\"> within boundaries of "
-                "previous <ReplaceOp@2..4:\"x\">")
+        self.assertRaisesRegex(
+            ValueError,
+            (r'insert op <InsertBeforeOp@4:"y"> within boundaries of '
+             r'previous <ReplaceOp@2\.\.4:"x">'),
+            tokens.toString)


def testReplaceRangeThenInsertAfterRightEdge(self):
@@ -214,7 +207,7 @@ class T1(testbase.ANTLRTest):

result = tokens.toString()
expecting = "abxyba"
-        self.failUnlessEqual(result, expecting)
+        self.assertEqual(result, expecting)


def testReplaceAll(self):
@@ -223,7 +216,7 @@ class T1(testbase.ANTLRTest):

result = tokens.toString()
expecting = "x"
-        self.failUnlessEqual(result, expecting)
+        self.assertEqual(result, expecting)


def testReplaceSubsetThenFetch(self):
@@ -232,7 +225,7 @@ class T1(testbase.ANTLRTest):

result = tokens.toString(0, 6)
expecting = "abxyzba"
-        self.failUnlessEqual(result, expecting)
+        self.assertEqual(result, expecting)


def testReplaceThenReplaceSuperset(self):
@@ -240,14 +233,11 @@ class T1(testbase.ANTLRTest):
tokens.replace(2, 4, "xyz")
tokens.replace(3, 5, "foo") # overlaps, error

-        try:
-            tokens.toString()
-            self.fail()
-        except ValueError, exc:
-            self.failUnlessEqual(
-                str(exc),
-                "replace op boundaries of <ReplaceOp@3..5:\"foo\"> overlap "
-                "with previous <ReplaceOp@2..4:\"xyz\">")
+        self.assertRaisesRegex(
+            ValueError,
+            (r'replace op boundaries of <ReplaceOp@3\.\.5:"foo"> overlap '
+             r'with previous <ReplaceOp@2\.\.4:"xyz">'),
+            tokens.toString)


def testReplaceThenReplaceLowerIndexedSuperset(self):
@@ -255,14 +245,11 @@ class T1(testbase.ANTLRTest):
tokens.replace(2, 4, "xyz")
tokens.replace(1, 3, "foo") # overlap, error

-        try:
-            tokens.toString()
-            self.fail()
-        except ValueError, exc:
-            self.failUnlessEqual(
-                str(exc),
-                "replace op boundaries of <ReplaceOp@1..3:\"foo\"> overlap "
-                "with previous <ReplaceOp@2..4:\"xyz\">")
+        self.assertRaisesRegex(
+            ValueError,
+            (r'replace op boundaries of <ReplaceOp@1\.\.3:"foo"> overlap '
+             r'with previous <ReplaceOp@2\.\.4:"xyz">'),
+            tokens.toString)


def testReplaceSingleMiddleThenOverlappingSuperset(self):
@@ -272,7 +259,7 @@ class T1(testbase.ANTLRTest):

result = tokens.toString()
expecting = "fooa"
-        self.failUnlessEqual(result, expecting)
+        self.assertEqual(result, expecting)


def testCombineInserts(self):
@@ -281,7 +268,7 @@ class T1(testbase.ANTLRTest):
tokens.insertBefore(0, "y")
result = tokens.toString()
expecting = "yxabc"
-        self.failUnlessEqual(expecting, result)
+        self.assertEqual(expecting, result)


def testCombine3Inserts(self):
@@ -291,7 +278,7 @@ class T1(testbase.ANTLRTest):
tokens.insertBefore(1, "z")
result = tokens.toString()
expecting = "yazxbc"
-        self.failUnlessEqual(expecting, result)
+        self.assertEqual(expecting, result)


def testCombineInsertOnLeftWithReplace(self):
@@ -300,7 +287,7 @@ class T1(testbase.ANTLRTest):
tokens.insertBefore(0, "z") # combine with left edge of rewrite
result = tokens.toString()
expecting = "zfoo"
-        self.failUnlessEqual(expecting, result)
+        self.assertEqual(expecting, result)


def testCombineInsertOnLeftWithDelete(self):
@@ -309,7 +296,7 @@ class T1(testbase.ANTLRTest):
tokens.insertBefore(0, "z") # combine with left edge of rewrite
result = tokens.toString()
expecting = "z" # make sure combo is not znull
-        self.failUnlessEqual(expecting, result)
+        self.assertEqual(expecting, result)


def testDisjointInserts(self):
@@ -319,7 +306,7 @@ class T1(testbase.ANTLRTest):
tokens.insertBefore(0, "z")
result = tokens.toString()
expecting = "zaxbyc"
-        self.failUnlessEqual(expecting, result)
+        self.assertEqual(expecting, result)


def testOverlappingReplace(self):
@@ -328,7 +315,7 @@ class T1(testbase.ANTLRTest):
tokens.replace(0, 3, "bar") # wipes prior nested replace
result = tokens.toString()
expecting = "bar"
-        self.failUnlessEqual(expecting, result)
+        self.assertEqual(expecting, result)


def testOverlappingReplace2(self):
@@ -336,14 +323,11 @@ class T1(testbase.ANTLRTest):
tokens.replace(0, 3, "bar")
tokens.replace(1, 2, "foo") # cannot split earlier replace

-        try:
-            tokens.toString()
-            self.fail()
-        except ValueError, exc:
-            self.failUnlessEqual(
-                str(exc),
-                "replace op boundaries of <ReplaceOp@1..2:\"foo\"> overlap "
-                "with previous <ReplaceOp@0..3:\"bar\">")
+        self.assertRaisesRegex(
+            ValueError,
+            (r'replace op boundaries of <ReplaceOp@1\.\.2:"foo"> overlap '
+             r'with previous <ReplaceOp@0\.\.3:"bar">'),
+            tokens.toString)


def testOverlappingReplace3(self):
@@ -352,7 +336,7 @@ class T1(testbase.ANTLRTest):
tokens.replace(0, 2, "bar") # wipes prior nested replace
result = tokens.toString()
expecting = "barc"
-        self.failUnlessEqual(expecting, result)
+        self.assertEqual(expecting, result)


def testOverlappingReplace4(self):
@@ -361,7 +345,7 @@ class T1(testbase.ANTLRTest):
tokens.replace(1, 3, "bar") # wipes prior nested replace
result = tokens.toString()
expecting = "abar"
-        self.failUnlessEqual(expecting, result)
+        self.assertEqual(expecting, result)


def testDropIdenticalReplace(self):
@@ -370,7 +354,7 @@ class T1(testbase.ANTLRTest):
tokens.replace(1, 2, "foo") # drop previous, identical
result = tokens.toString()
expecting = "afooc"
-        self.failUnlessEqual(expecting, result)
+        self.assertEqual(expecting, result)


def testDropPrevCoveredInsert(self):
@@ -379,7 +363,7 @@ class T1(testbase.ANTLRTest):
tokens.replace(1, 2, "foo") # kill prev insert
result = tokens.toString()
expecting = "afoofoo"
-        self.failUnlessEqual(expecting, result)
+        self.assertEqual(expecting, result)


def testLeaveAloneDisjointInsert(self):
@@ -388,7 +372,7 @@ class T1(testbase.ANTLRTest):
tokens.replace(2, 3, "foo")
result = tokens.toString()
expecting = "axbfoo"
-        self.failUnlessEqual(expecting, result)
+        self.assertEqual(expecting, result)


def testLeaveAloneDisjointInsert2(self):
@@ -397,7 +381,7 @@ class T1(testbase.ANTLRTest):
tokens.insertBefore(1, "x")
result = tokens.toString()
expecting = "axbfoo"
-        self.failUnlessEqual(expecting, result)
+        self.assertEqual(expecting, result)


def testInsertBeforeTokenThenDeleteThatToken(self):
@@ -406,7 +390,7 @@ class T1(testbase.ANTLRTest):
tokens.delete(2)
result = tokens.toString()
expecting = "aby"
-        self.failUnlessEqual(expecting, result)
+        self.assertEqual(expecting, result)


class T2(testbase.ANTLRTest):
@@ -431,19 +415,19 @@ class T2(testbase.ANTLRTest):

result = tokens.toOriginalString()
expecting = "x = 3 * 0;"
-        self.failUnlessEqual(expecting, result)
+        self.assertEqual(expecting, result)

result = tokens.toString()
expecting = "x = 0;"
-        self.failUnlessEqual(expecting, result)
+        self.assertEqual(expecting, result)

result = tokens.toString(0, 9)
expecting = "x = 0;"
-        self.failUnlessEqual(expecting, result)
+        self.assertEqual(expecting, result)

result = tokens.toString(4, 8)
expecting = "0"
-        self.failUnlessEqual(expecting, result)
+        self.assertEqual(expecting, result)


def testToStringStartStop2(self):
@@ -453,37 +437,37 @@ class T2(testbase.ANTLRTest):

result = tokens.toOriginalString()
expecting = "x = 3 * 0 + 2 * 0;"
-        self.failUnlessEqual(expecting, result)
+        self.assertEqual(expecting, result)

tokens.replace(4, 8, "0") # replace 3 * 0 with 0
result = tokens.toString()
expecting = "x = 0 + 2 * 0;"
-        self.failUnlessEqual(expecting, result)
+        self.assertEqual(expecting, result)

result = tokens.toString(0, 17)
expecting = "x = 0 + 2 * 0;"
-        self.failUnlessEqual(expecting, result)
+        self.assertEqual(expecting, result)

result = tokens.toString(4, 8)
expecting = "0"
-        self.failUnlessEqual(expecting, result)
+        self.assertEqual(expecting, result)

result = tokens.toString(0, 8)
expecting = "x = 0"
-        self.failUnlessEqual(expecting, result)
+        self.assertEqual(expecting, result)

result = tokens.toString(12, 16)
expecting = "2 * 0"
-        self.failUnlessEqual(expecting, result)
+        self.assertEqual(expecting, result)

tokens.insertAfter(17, "// comment")
result = tokens.toString(12, 18)
expecting = "2 * 0;// comment"
-        self.failUnlessEqual(expecting, result)
+        self.assertEqual(expecting, result)

result = tokens.toString(0, 8) # try again after insert at end
expecting = "x = 0"
-        self.failUnlessEqual(expecting, result)
+        self.assertEqual(expecting, result)


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t048rewrite2.g b/runtime/Python3/tests/t048rewrite2.g
index f98251c..60178d7 100644
--- a/runtime/Python3/tests/t048rewrite2.g
+++ b/runtime/Python3/tests/t048rewrite2.g
@@ -1,6 +1,6 @@
lexer grammar t048rewrite2;
options {
-    language=Python;
+    language=Python3;
}

ID : 'a'..'z'+;
diff --git a/runtime/Python3/tests/t049treeparser.py b/runtime/Python3/tests/t049treeparser.py
index 9c7157d..ec77618 100644
--- a/runtime/Python3/tests/t049treeparser.py
+++ b/runtime/Python3/tests/t049treeparser.py
@@ -8,7 +8,7 @@ class T(testbase.ANTLRTest):
def walkerClass(self, base):
class TWalker(base):
def __init__(self, *args, **kwargs):
-                base.__init__(self, *args, **kwargs)
+                super().__init__(*args, **kwargs)

self._output = ""

@@ -53,7 +53,7 @@ class T(testbase.ANTLRTest):
grammar = textwrap.dedent(
r'''grammar T;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
a : ID INT;
@@ -65,11 +65,11 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r'''tree grammar TP;
options {
-            language=Python;
+            language=Python3;
ASTLabelType=CommonTree;
}
a : ID INT
-            {self.capture("\%s, \%s" \% ($ID, $INT))}
+            {self.capture("{}, {}".format($ID, $INT))}
;
''')

@@ -79,7 +79,7 @@ class T(testbase.ANTLRTest):
"abc 34"
)

-        self.failUnlessEqual("abc, 34", found)
+        self.assertEqual("abc, 34", found)



@@ -87,7 +87,7 @@ class T(testbase.ANTLRTest):
grammar = textwrap.dedent(
r'''grammar T;
options {
-                language=Python;
+                language=Python3;
output=AST;
}
a : ID INT -> ^(ID INT);
@@ -99,7 +99,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r'''tree grammar TP;
options {
-                language=Python;
+                language=Python3;
ASTLabelType=CommonTree;
}
a : ^(ID INT)
@@ -113,14 +113,14 @@ class T(testbase.ANTLRTest):
"abc 34"
)

-        self.failUnlessEqual("abc, 34", found)
+        self.assertEqual("abc, 34", found)


def testFlatVsTreeDecision(self):
grammar = textwrap.dedent(
r'''grammar T;
options {
-                language=Python;
+                language=Python3;
output=AST;
}
a : b c ;
@@ -134,7 +134,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r'''tree grammar TP;
options {
-                language=Python;
+                language=Python3;
ASTLabelType=CommonTree;
}
a : b b ;
@@ -148,14 +148,14 @@ class T(testbase.ANTLRTest):
treeGrammar, 'a',
"a 1 b 2"
)
-        self.failUnlessEqual("^(a 1)b 2\n", found)
+        self.assertEqual("^(a 1)b 2\n", found)


def testFlatVsTreeDecision2(self):
grammar = textwrap.dedent(
r"""grammar T;
options {
-                language=Python;
+                language=Python3;
output=AST;
}
a : b c ;
@@ -169,7 +169,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r'''tree grammar TP;
options {
-                language=Python;
+                language=Python3;
ASTLabelType=CommonTree;
}
a : b b ;
@@ -183,14 +183,14 @@ class T(testbase.ANTLRTest):
treeGrammar, 'a',
"a 1 2 3 b 4 5"
)
-        self.failUnlessEqual("^(a 3)b 5\n", found)
+        self.assertEqual("^(a 3)b 5\n", found)


def testCyclicDFALookahead(self):
grammar = textwrap.dedent(
r'''grammar T;
options {
-                language=Python;
+                language=Python3;
output=AST;
}
a : ID INT+ PERIOD;
@@ -204,7 +204,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r'''tree grammar TP;
options {
-                language=Python;
+                language=Python3;
ASTLabelType=CommonTree;
}
a : ID INT+ PERIOD {self.capture("alt 1")}
@@ -217,36 +217,14 @@ class T(testbase.ANTLRTest):
treeGrammar, 'a',
"a 1 2 3."
)
-        self.failUnlessEqual("alt 1", found)
-
-
-##     def testTemplateOutput(self):
-## 		String grammar =
-## 			"grammar T;\n" +
-## 			"options {output=AST;}\n" +
-## 			"a : ID INT;\n" +
-## 			"ID : 'a'..'z'+ ;\n" +
-## 			"INT : '0'..'9'+;\n" +
-## 			"WS : (' '|'\\n') {$channel=HIDDEN;} ;\n";
-
-## 		String treeGrammar =
-## 			"tree grammar TP;\n" +
-## 			"options {output=template; ASTLabelType=CommonTree;}\n" +
-## 			"s : a {System.out.println($a.st);};\n" +
-## 			"a : ID INT -> {new StringTemplate($INT.text)}\n" +
-## 			"  ;\n";
-
-## 		String found = execTreeParser("T.g", grammar, "TParser", "TP.g",
-## 				    treeGrammar, "TP", "TLexer", "a", "s", "abc 34");
-## 		assertEquals("34\n", found);
-## 	}
+        self.assertEqual("alt 1", found)


def testNullableChildList(self):
grammar = textwrap.dedent(
r'''grammar T;
options {
-                language=Python;
+                language=Python3;
output=AST;
}
a : ID INT? -> ^(ID INT?);
@@ -258,7 +236,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r'''tree grammar TP;
options {
-                language=Python;
+                language=Python3;
ASTLabelType=CommonTree;
}
a : ^(ID INT?)
@@ -271,14 +249,14 @@ class T(testbase.ANTLRTest):
treeGrammar, 'a',
"abc"
)
-        self.failUnlessEqual("abc", found)
+        self.assertEqual("abc", found)


def testNullableChildList2(self):
grammar = textwrap.dedent(
r'''grammar T;
options {
-                language=Python;
+                language=Python3;
output=AST;
}
a : ID INT? SEMI -> ^(ID INT?) SEMI ;
@@ -291,7 +269,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r'''tree grammar TP;
options {
-                language=Python;
+                language=Python3;
ASTLabelType=CommonTree;
}
a : ^(ID INT?) SEMI
@@ -304,14 +282,14 @@ class T(testbase.ANTLRTest):
treeGrammar, 'a',
"abc;"
)
-        self.failUnlessEqual("abc", found)
+        self.assertEqual("abc", found)


def testNullableChildList3(self):
grammar = textwrap.dedent(
r'''grammar T;
options {
-                language=Python;
+                language=Python3;
output=AST;
}
a : x=ID INT? (y=ID)? SEMI -> ^($x INT? $y?) SEMI ;
@@ -324,7 +302,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r'''tree grammar TP;
options {
-                language=Python;
+                language=Python3;
ASTLabelType=CommonTree;
}
a : ^(ID INT? b) SEMI
@@ -338,14 +316,14 @@ class T(testbase.ANTLRTest):
treeGrammar, 'a',
"abc def;"
)
-        self.failUnlessEqual("abc, def", found)
+        self.assertEqual("abc, def", found)


def testActionsAfterRoot(self):
grammar = textwrap.dedent(
r'''grammar T;
options {
-                language=Python;
+                language=Python3;
output=AST;
}
a : x=ID INT? SEMI -> ^($x INT?) ;
@@ -358,7 +336,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r'''tree grammar TP;
options {
-                language=Python;
+                language=Python3;
ASTLabelType=CommonTree;
}
a @init {x=0} : ^(ID {x=1} {x=2} INT?)
@@ -371,14 +349,14 @@ class T(testbase.ANTLRTest):
treeGrammar, 'a',
"abc;"
)
-        self.failUnless("abc, 2\n", found)
+        self.assertEqual("abc, 2", found)


def testWildcardLookahead(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python; output=AST;}
+            options {language=Python3; output=AST;}
a : ID '+'^ INT;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
@@ -390,7 +368,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r'''
tree grammar TP;
-            options {language=Python; tokenVocab=T; ASTLabelType=CommonTree;}
+            options {language=Python3; tokenVocab=T; ASTLabelType=CommonTree;}
a : ^('+' . INT) { self.capture("alt 1") }
;
''')
@@ -399,14 +377,14 @@ class T(testbase.ANTLRTest):
grammar, 'a',
treeGrammar, 'a',
"a + 2")
-        self.assertEquals("alt 1", found)
+        self.assertEqual("alt 1", found)


def testWildcardLookahead2(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python; output=AST;}
+            options {language=Python3; output=AST;}
a : ID '+'^ INT;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
@@ -418,7 +396,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r'''
tree grammar TP;
-            options {language=Python; tokenVocab=T; ASTLabelType=CommonTree;}
+            options {language=Python3; tokenVocab=T; ASTLabelType=CommonTree;}
a : ^('+' . INT) { self.capture("alt 1") }
| ^('+' . .)   { self.capture("alt 2") }
;
@@ -430,14 +408,14 @@ class T(testbase.ANTLRTest):
grammar, 'a',
treeGrammar, 'a',
"a + 2")
-        self.assertEquals("alt 1", found)
+        self.assertEqual("alt 1", found)


def testWildcardLookahead3(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python; output=AST;}
+            options {language=Python3; output=AST;}
a : ID '+'^ INT;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
@@ -449,7 +427,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r'''
tree grammar TP;
-            options {language=Python; tokenVocab=T; ASTLabelType=CommonTree;}
+            options {language=Python3; tokenVocab=T; ASTLabelType=CommonTree;}
a : ^('+' ID INT) { self.capture("alt 1") }
| ^('+' . .)   { self.capture("alt 2") }
;
@@ -461,14 +439,14 @@ class T(testbase.ANTLRTest):
grammar, 'a',
treeGrammar, 'a',
"a + 2")
-        self.assertEquals("alt 1", found)
+        self.assertEqual("alt 1", found)


def testWildcardPlusLookahead(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python; output=AST;}
+            options {language=Python3; output=AST;}
a : ID '+'^ INT;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
@@ -480,7 +458,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r'''
tree grammar TP;
-            options {language=Python; tokenVocab=T; ASTLabelType=CommonTree;}
+            options {language=Python3; tokenVocab=T; ASTLabelType=CommonTree;}
a : ^('+' INT INT ) { self.capture("alt 1") }
| ^('+' .+)   { self.capture("alt 2") }
;
@@ -492,7 +470,7 @@ class T(testbase.ANTLRTest):
grammar, 'a',
treeGrammar, 'a',
"a + 2")
-        self.assertEquals("alt 2", found)
+        self.assertEqual("alt 2", found)


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t050decorate.g b/runtime/Python3/tests/t050decorate.g
index a8b17d1..50e54e7 100644
--- a/runtime/Python3/tests/t050decorate.g
+++ b/runtime/Python3/tests/t050decorate.g
@@ -1,6 +1,6 @@
grammar t050decorate;
options {
-  language = Python;
+  language = Python3;
}

@header {
diff --git a/runtime/Python3/tests/t050decorate.py b/runtime/Python3/tests/t050decorate.py
index bb6b85e..b5337a6 100644
--- a/runtime/Python3/tests/t050decorate.py
+++ b/runtime/Python3/tests/t050decorate.py
@@ -14,7 +14,7 @@ class t013parser(testbase.ANTLRTest):
parser = self.getParser(tStream)
parser.document()

-        assert parser.events == ['before', 'after']
+        self.assertEqual(parser.events, ['before', 'after'])


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t051treeRewriteAST.py b/runtime/Python3/tests/t051treeRewriteAST.py
index 39253b4..3c9ced6 100644
--- a/runtime/Python3/tests/t051treeRewriteAST.py
+++ b/runtime/Python3/tests/t051treeRewriteAST.py
@@ -8,7 +8,7 @@ class T(testbase.ANTLRTest):
def walkerClass(self, base):
class TWalker(base):
def __init__(self, *args, **kwargs):
-                base.__init__(self, *args, **kwargs)
+                super().__init__(*args, **kwargs)
self.buf = ""

def traceIn(self, ruleName, ruleIndex):
@@ -40,7 +40,7 @@ class T(testbase.ANTLRTest):
walker = walkerCls(nodes)
r = getattr(walker, treeEntry)()

-        if r.tree is not None:
+        if r.tree:
return r.tree.toStringTree()

return ""
@@ -51,7 +51,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T1;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
a : ID INT;
@@ -64,7 +64,7 @@ class T(testbase.ANTLRTest):
r'''
tree grammar TP1;
options {
-            language=Python;
+            language=Python3;
output=AST;
ASTLabelType=CommonTree;
tokenVocab=T1;
@@ -79,7 +79,7 @@ class T(testbase.ANTLRTest):
"abc 34"
)

-        self.failUnlessEqual("34 abc", found)
+        self.assertEqual("34 abc", found)


def testSimpleTree(self):
@@ -87,7 +87,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T2;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
a : ID INT -> ^(ID INT);
@@ -100,7 +100,7 @@ class T(testbase.ANTLRTest):
r'''
tree grammar TP2;
options {
-            language=Python;
+            language=Python3;
output=AST;
ASTLabelType=CommonTree;
tokenVocab=T2;
@@ -114,7 +114,7 @@ class T(testbase.ANTLRTest):
"abc 34"
)

-        self.failUnlessEqual("(34 abc)", found)
+        self.assertEqual("(34 abc)", found)


def testCombinedRewriteAndAuto(self):
@@ -122,7 +122,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T3;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
a : ID INT -> ^(ID INT) | INT ;
@@ -135,7 +135,7 @@ class T(testbase.ANTLRTest):
r'''
tree grammar TP3;
options {
-            language=Python;
+            language=Python3;
output=AST;
ASTLabelType=CommonTree;
tokenVocab=T3;
@@ -149,7 +149,7 @@ class T(testbase.ANTLRTest):
"abc 34"
)

-        self.failUnlessEqual("(34 abc)", found)
+        self.assertEqual("(34 abc)", found)


found = self.execTreeParser(
@@ -158,7 +158,7 @@ class T(testbase.ANTLRTest):
"34"
)

-        self.failUnlessEqual("34", found)
+        self.assertEqual("34", found)


def testAvoidDup(self):
@@ -166,7 +166,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T4;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
a : ID ;
@@ -179,7 +179,7 @@ class T(testbase.ANTLRTest):
r'''
tree grammar TP4;
options {
-            language=Python;
+            language=Python3;
output=AST;
ASTLabelType=CommonTree;
tokenVocab=T4;
@@ -193,7 +193,7 @@ class T(testbase.ANTLRTest):
"abc"
)

-        self.failUnlessEqual("(abc abc)", found)
+        self.assertEqual("(abc abc)", found)


def testLoop(self):
@@ -201,7 +201,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T5;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
a : ID+ INT+ -> (^(ID INT))+ ;
@@ -214,7 +214,7 @@ class T(testbase.ANTLRTest):
r'''
tree grammar TP5;
options {
-            language=Python;
+            language=Python3;
output=AST;
ASTLabelType=CommonTree;
tokenVocab=T5;
@@ -228,7 +228,7 @@ class T(testbase.ANTLRTest):
"a b c 3 4 5"
)

-        self.failUnlessEqual("3 4 5 a b c", found)
+        self.assertEqual("3 4 5 a b c", found)


def testAutoDup(self):
@@ -236,7 +236,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T6;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
a : ID ;
@@ -249,7 +249,7 @@ class T(testbase.ANTLRTest):
r'''
tree grammar TP6;
options {
-            language=Python;
+            language=Python3;
output=AST;
ASTLabelType=CommonTree;
tokenVocab=T6;
@@ -263,7 +263,7 @@ class T(testbase.ANTLRTest):
"abc"
)

-        self.failUnlessEqual("abc", found)
+        self.assertEqual("abc", found)


def testAutoDupRule(self):
@@ -271,7 +271,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T7;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
a : ID INT ;
@@ -284,7 +284,7 @@ class T(testbase.ANTLRTest):
r'''
tree grammar TP7;
options {
-            language=Python;
+            language=Python3;
output=AST;
ASTLabelType=CommonTree;
tokenVocab=T7;
@@ -300,14 +300,14 @@ class T(testbase.ANTLRTest):
"a 1"
)

-        self.failUnlessEqual("a 1", found)
+        self.assertEqual("a 1", found)


def testAutoWildcard(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID INT ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
@@ -317,7 +317,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r'''
tree grammar TP;
-            options {language=Python;output=AST; ASTLabelType=CommonTree; tokenVocab=T;}
+            options {language=Python3;output=AST; ASTLabelType=CommonTree; tokenVocab=T;}
a : ID .
;
''')
@@ -326,42 +326,14 @@ class T(testbase.ANTLRTest):
grammar, 'a',
treeGrammar, 'a',
"abc 34")
-        self.assertEquals("abc 34", found)
-
-
-#     def testNoWildcardAsRootError(self):
-#         ErrorQueue equeue = new ErrorQueue();
-#         ErrorManager.setErrorListener(equeue);
-# >
-#         String treeGrammar =
-#             "tree grammar TP;\n"+
-#             "options {language=Python;output=AST;}
-#             "a : ^(. INT)
-#             "  ;\n";
-# >
-#         Grammar g = new Grammar(treeGrammar);
-#         Tool antlr = newTool();
-#         antlr.setOutputDirectory(null); // write to /dev/null
-#         CodeGenerator generator = new CodeGenerator(antlr, g, "Java");
-#         g.setCodeGenerator(generator);
-#         generator.genRecognizer();
-# >
-#         assertEquals("unexpected errors: "+equeue, 1, equeue.errors.size());
-# >
-#         int expectedMsgID = ErrorManager.MSG_WILDCARD_AS_ROOT;
-#         Object expectedArg = null;
-#         antlr.RecognitionException expectedExc = null;
-#         GrammarSyntaxMessage expectedMessage =
-#             new GrammarSyntaxMessage(expectedMsgID, g, null, expectedArg, expectedExc);
-# >
-#         checkError(equeue, expectedMessage);
-#     }
+        self.assertEqual("abc 34", found)
+

def testAutoWildcard2(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID INT -> ^(ID INT);
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
@@ -371,7 +343,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r'''
tree grammar TP;
-            options {language=Python;output=AST; ASTLabelType=CommonTree; tokenVocab=T;}
+            options {language=Python3;output=AST; ASTLabelType=CommonTree; tokenVocab=T;}
a : ^(ID .)
;
''')
@@ -380,14 +352,14 @@ class T(testbase.ANTLRTest):
grammar, 'a',
treeGrammar, 'a',
"abc 34")
-        self.assertEquals("(abc 34)", found)
+        self.assertEqual("(abc 34)", found)


def testAutoWildcardWithLabel(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID INT ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
@@ -397,7 +369,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r'''
tree grammar TP;
-            options {language=Python;output=AST; ASTLabelType=CommonTree; tokenVocab=T;}
+            options {language=Python3;output=AST; ASTLabelType=CommonTree; tokenVocab=T;}
a : ID c=.
;
''')
@@ -406,14 +378,14 @@ class T(testbase.ANTLRTest):
grammar, 'a',
treeGrammar, 'a',
"abc 34")
-        self.assertEquals("abc 34", found)
+        self.assertEqual("abc 34", found)


def testAutoWildcardWithListLabel(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID INT ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
@@ -423,7 +395,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r'''
tree grammar TP;
-            options {language=Python;output=AST; ASTLabelType=CommonTree; tokenVocab=T;}
+            options {language=Python3;output=AST; ASTLabelType=CommonTree; tokenVocab=T;}
a : ID c+=.
;
''')
@@ -432,7 +404,7 @@ class T(testbase.ANTLRTest):
grammar, 'a',
treeGrammar, 'a',
"abc 34")
-        self.assertEquals("abc 34", found)
+        self.assertEqual("abc 34", found)


def testAutoDupMultiple(self):
@@ -440,7 +412,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T8;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
a : ID ID INT;
@@ -453,7 +425,7 @@ class T(testbase.ANTLRTest):
r'''
tree grammar TP8;
options {
-            language=Python;
+            language=Python3;
output=AST;
ASTLabelType=CommonTree;
tokenVocab=T8;
@@ -468,7 +440,7 @@ class T(testbase.ANTLRTest):
"a b 3"
)

-        self.failUnlessEqual("a b 3", found)
+        self.assertEqual("a b 3", found)


def testAutoDupTree(self):
@@ -476,7 +448,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T9;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
a : ID INT -> ^(ID INT);
@@ -489,7 +461,7 @@ class T(testbase.ANTLRTest):
r'''
tree grammar TP9;
options {
-            language=Python;
+            language=Python3;
output=AST;
ASTLabelType=CommonTree;
tokenVocab=T9;
@@ -504,7 +476,7 @@ class T(testbase.ANTLRTest):
"a 3"
)

-        self.failUnlessEqual("(a 3)", found)
+        self.assertEqual("(a 3)", found)


def testAutoDupTreeWithLabels(self):
@@ -512,7 +484,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T10;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
a : ID INT -> ^(ID INT);
@@ -525,7 +497,7 @@ class T(testbase.ANTLRTest):
r'''
tree grammar TP10;
options {
-            language=Python;
+            language=Python3;
output=AST;
ASTLabelType=CommonTree;
tokenVocab=T10;
@@ -540,7 +512,7 @@ class T(testbase.ANTLRTest):
"a 3"
)

-        self.failUnlessEqual("(a 3)", found)
+        self.assertEqual("(a 3)", found)


def testAutoDupTreeWithListLabels(self):
@@ -548,7 +520,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T11;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
a : ID INT -> ^(ID INT);
@@ -561,7 +533,7 @@ class T(testbase.ANTLRTest):
r'''
tree grammar TP11;
options {
-            language=Python;
+            language=Python3;
output=AST;
ASTLabelType=CommonTree;
tokenVocab=T11;
@@ -576,7 +548,7 @@ class T(testbase.ANTLRTest):
"a 3"
)

-        self.failUnlessEqual("(a 3)", found)
+        self.assertEqual("(a 3)", found)


def testAutoDupTreeWithRuleRoot(self):
@@ -584,7 +556,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T12;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
a : ID INT -> ^(ID INT);
@@ -597,7 +569,7 @@ class T(testbase.ANTLRTest):
r'''
tree grammar TP12;
options {
-            language=Python;
+            language=Python3;
output=AST;
ASTLabelType=CommonTree;
tokenVocab=T12;
@@ -612,7 +584,7 @@ class T(testbase.ANTLRTest):
"a 3"
)

-        self.failUnlessEqual("(a 3)", found)
+        self.assertEqual("(a 3)", found)


def testAutoDupTreeWithRuleRootAndLabels(self):
@@ -620,7 +592,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T13;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
a : ID INT -> ^(ID INT);
@@ -633,7 +605,7 @@ class T(testbase.ANTLRTest):
r'''
tree grammar TP13;
options {
-            language=Python;
+            language=Python3;
output=AST;
ASTLabelType=CommonTree;
tokenVocab=T13;
@@ -648,7 +620,7 @@ class T(testbase.ANTLRTest):
"a 3"
)

-        self.failUnlessEqual("(a 3)", found)
+        self.assertEqual("(a 3)", found)


def testAutoDupTreeWithRuleRootAndListLabels(self):
@@ -656,7 +628,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T14;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
a : ID INT -> ^(ID INT);
@@ -669,7 +641,7 @@ class T(testbase.ANTLRTest):
r'''
tree grammar TP14;
options {
-            language=Python;
+            language=Python3;
output=AST;
ASTLabelType=CommonTree;
tokenVocab=T14;
@@ -685,7 +657,7 @@ class T(testbase.ANTLRTest):
"a 3"
)

-        self.failUnlessEqual("(a 3)", found)
+        self.assertEqual("(a 3)", found)


def testAutoDupNestedTree(self):
@@ -693,7 +665,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T15;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
a : x=ID y=ID INT -> ^($x ^($y INT));
@@ -706,7 +678,7 @@ class T(testbase.ANTLRTest):
r'''
tree grammar TP15;
options {
-            language=Python;
+            language=Python3;
output=AST;
ASTLabelType=CommonTree;
tokenVocab=T15;
@@ -721,7 +693,7 @@ class T(testbase.ANTLRTest):
"a b 3"
)

-        self.failUnlessEqual("(a (b 3))", found)
+        self.assertEqual("(a (b 3))", found)


def testDelete(self):
@@ -729,7 +701,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T16;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
a : ID ;
@@ -742,7 +714,7 @@ class T(testbase.ANTLRTest):
r'''
tree grammar TP16;
options {
-            language=Python;
+            language=Python3;
output=AST;
ASTLabelType=CommonTree;
tokenVocab=T16;
@@ -757,14 +729,14 @@ class T(testbase.ANTLRTest):
"abc"
)

-        self.failUnlessEqual("", found)
+        self.assertEqual("", found)

def testSetMatchNoRewrite(self):
grammar = textwrap.dedent(
r'''
grammar T;
options {
-                language=Python;
+                language=Python3;
output=AST;
}
a : ID INT ;
@@ -777,7 +749,7 @@ class T(testbase.ANTLRTest):
r'''
tree grammar TP;
options {
-                language=Python;
+                language=Python3;
output=AST;
ASTLabelType=CommonTree;
tokenVocab=T;
@@ -792,7 +764,7 @@ class T(testbase.ANTLRTest):
"abc 34"
)

-        self.failUnlessEqual("abc 34", found)
+        self.assertEqual("abc 34", found)


def testSetOptionalMatchNoRewrite(self):
@@ -800,7 +772,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T;
options {
-                language=Python;
+                language=Python3;
output=AST;
}
a : ID INT ;
@@ -813,7 +785,7 @@ class T(testbase.ANTLRTest):
r'''
tree grammar TP;
options {
-                language=Python;
+                language=Python3;
output=AST;
ASTLabelType=CommonTree;
tokenVocab=T;
@@ -826,7 +798,7 @@ class T(testbase.ANTLRTest):
treeGrammar, 'a',
"abc 34")

-        self.failUnlessEqual("abc 34", found)
+        self.assertEqual("abc 34", found)


def testSetMatchNoRewriteLevel2(self):
@@ -834,7 +806,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T;
options {
-                language=Python;
+                language=Python3;
output=AST;
}
a : x=ID INT -> ^($x INT);
@@ -847,7 +819,7 @@ class T(testbase.ANTLRTest):
r'''
tree grammar TP;
options {
-                language=Python;
+                language=Python3;
output=AST;
ASTLabelType=CommonTree;
tokenVocab=T;
@@ -861,7 +833,7 @@ class T(testbase.ANTLRTest):
"abc 34"
)

-        self.failUnlessEqual("(abc 34)", found)
+        self.assertEqual("(abc 34)", found)


def testSetMatchNoRewriteLevel2Root(self):
@@ -869,7 +841,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T;
options {
-                language=Python;
+                language=Python3;
output=AST;
}
a : x=ID INT -> ^($x INT);
@@ -882,7 +854,7 @@ class T(testbase.ANTLRTest):
r'''
tree grammar TP;
options {
-                language=Python;
+                language=Python3;
output=AST;
ASTLabelType=CommonTree;
tokenVocab=T;
@@ -896,7 +868,7 @@ class T(testbase.ANTLRTest):
"abc 34"
)

-        self.failUnlessEqual("(abc 34)", found)
+        self.assertEqual("(abc 34)", found)


## REWRITE MODE
@@ -906,7 +878,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T17;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
a : ID INT -> ^(ID INT) | INT ;
@@ -919,7 +891,7 @@ class T(testbase.ANTLRTest):
r'''
tree grammar TP17;
options {
-            language=Python;
+            language=Python3;
output=AST;
ASTLabelType=CommonTree;
tokenVocab=T17;
@@ -936,7 +908,7 @@ class T(testbase.ANTLRTest):
"abc 34"
)

-        self.failUnlessEqual("(ick 34)", found)
+        self.assertEqual("(ick 34)", found)


found = self.execTreeParser(
@@ -945,7 +917,7 @@ class T(testbase.ANTLRTest):
"34"
)

-        self.failUnlessEqual("34", found)
+        self.assertEqual("34", found)


def testRewriteModeFlatTree(self):
@@ -953,7 +925,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T18;
options {
-              language=Python;
+              language=Python3;
output=AST;
}
a : ID INT -> ID INT | INT ;
@@ -966,7 +938,7 @@ class T(testbase.ANTLRTest):
r'''
tree grammar TP18;
options {
-              language=Python;
+              language=Python3;
output=AST;
ASTLabelType=CommonTree;
tokenVocab=T18;
@@ -982,14 +954,14 @@ class T(testbase.ANTLRTest):
treeGrammar, 's',
"abc 34"
)
-        self.assertEquals("abc 1", found)
+        self.assertEqual("abc 1", found)


def testRewriteModeChainRuleFlatTree(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python; output=AST;}
+            options {language=Python3; output=AST;}
a : ID INT -> ID INT | INT ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
@@ -999,7 +971,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r'''
tree grammar TP;
-            options {language=Python; output=AST; ASTLabelType=CommonTree; tokenVocab=T; rewrite=true;}
+            options {language=Python3; output=AST; ASTLabelType=CommonTree; tokenVocab=T; rewrite=true;}
s : a ;
a : b ;
b : ID INT -> INT ID
@@ -1010,14 +982,14 @@ class T(testbase.ANTLRTest):
grammar, 'a',
treeGrammar, 's',
"abc 34")
-        self.assertEquals("34 abc", found)
+        self.assertEqual("34 abc", found)


def testRewriteModeChainRuleTree(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python; output=AST;}
+            options {language=Python3; output=AST;}
a : ID INT -> ^(ID INT) ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
@@ -1027,7 +999,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r'''
tree grammar TP;
-            options {language=Python; output=AST; ASTLabelType=CommonTree; tokenVocab=T; rewrite=true;}
+            options {language=Python3; output=AST; ASTLabelType=CommonTree; tokenVocab=T; rewrite=true;}
s : a ;
a : b ; // a.tree must become b.tree
b : ^(ID INT) -> INT
@@ -1038,14 +1010,14 @@ class T(testbase.ANTLRTest):
grammar, 'a',
treeGrammar, 's',
"abc 34")
-        self.assertEquals("34", found)
+        self.assertEqual("34", found)


def testRewriteModeChainRuleTree2(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python; output=AST;}
+            options {language=Python3; output=AST;}
a : ID INT -> ^(ID INT) ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
@@ -1055,7 +1027,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r"""
tree grammar TP;
-            options {language=Python; output=AST; ASTLabelType=CommonTree; tokenVocab=T; rewrite=true;}
+            options {language=Python3; output=AST; ASTLabelType=CommonTree; tokenVocab=T; rewrite=true;}
tokens { X; }
s : a* b ; // only b contributes to tree, but it's after a*; s.tree = b.tree
a : X ;
@@ -1067,14 +1039,14 @@ class T(testbase.ANTLRTest):
grammar, 'a',
treeGrammar, 's',
"abc 34")
-        self.assertEquals("34", found)
+        self.assertEqual("34", found)


def testRewriteModeChainRuleTree3(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python; output=AST;}
+            options {language=Python3; output=AST;}
a : 'boo' ID INT -> 'boo' ^(ID INT) ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
@@ -1084,7 +1056,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r"""
tree grammar TP;
-            options {language=Python; output=AST; ASTLabelType=CommonTree; tokenVocab=T; rewrite=true;}
+            options {language=Python3; output=AST; ASTLabelType=CommonTree; tokenVocab=T; rewrite=true;}
tokens { X; }
s : 'boo' a* b ; // don't reset s.tree to b.tree due to 'boo'
a : X ;
@@ -1096,14 +1068,14 @@ class T(testbase.ANTLRTest):
grammar, 'a',
treeGrammar, 's',
"boo abc 34")
-        self.assertEquals("boo 34", found)
+        self.assertEqual("boo 34", found)


def testRewriteModeChainRuleTree4(self):
grammar = textwrap.dedent(
r"""
grammar T;
-            options {language=Python; output=AST;}
+            options {language=Python3; output=AST;}
a : 'boo' ID INT -> ^('boo' ^(ID INT)) ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
@@ -1113,7 +1085,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r"""
tree grammar TP;
-            options {language=Python; output=AST; ASTLabelType=CommonTree; tokenVocab=T; rewrite=true;}
+            options {language=Python3; output=AST; ASTLabelType=CommonTree; tokenVocab=T; rewrite=true;}
tokens { X; }
s : ^('boo' a* b) ; // don't reset s.tree to b.tree due to 'boo'
a : X ;
@@ -1125,14 +1097,14 @@ class T(testbase.ANTLRTest):
grammar, 'a',
treeGrammar, 's',
"boo abc 34")
-        self.assertEquals("(boo 34)", found)
+        self.assertEqual("(boo 34)", found)


def testRewriteModeChainRuleTree5(self):
grammar = textwrap.dedent(
r"""
grammar T;
-            options {language=Python; output=AST;}
+            options {language=Python3; output=AST;}
a : 'boo' ID INT -> ^('boo' ^(ID INT)) ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
@@ -1142,7 +1114,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r"""
tree grammar TP;
-            options {language=Python; output=AST; ASTLabelType=CommonTree; tokenVocab=T; rewrite=true;}
+            options {language=Python3; output=AST; ASTLabelType=CommonTree; tokenVocab=T; rewrite=true;}
tokens { X; }
s : ^(a b) ; // s.tree is a.tree
a : 'boo' ;
@@ -1154,14 +1126,14 @@ class T(testbase.ANTLRTest):
grammar, 'a',
treeGrammar, 's',
"boo abc 34")
-        self.assertEquals("(boo 34)", found)
+        self.assertEqual("(boo 34)", found)


def testRewriteOfRuleRef(self):
grammar = textwrap.dedent(
r"""
grammar T;
-            options {language=Python; output=AST;}
+            options {language=Python3; output=AST;}
a : ID INT -> ID INT | INT ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
@@ -1171,7 +1143,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r"""
tree grammar TP;
-            options {language=Python; output=AST; ASTLabelType=CommonTree; tokenVocab=T; rewrite=true;}
+            options {language=Python3; output=AST; ASTLabelType=CommonTree; tokenVocab=T; rewrite=true;}
s : a -> a ;
a : ID INT -> ID INT ;
""")
@@ -1180,14 +1152,14 @@ class T(testbase.ANTLRTest):
grammar, 'a',
treeGrammar, 's',
"abc 34")
-        self.failUnlessEqual("abc 34", found)
+        self.assertEqual("abc 34", found)


def testRewriteOfRuleRefRoot(self):
grammar = textwrap.dedent(
r"""
grammar T;
-            options {language=Python; output=AST;}
+            options {language=Python3; output=AST;}
a : ID INT INT -> ^(INT ^(ID INT));
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
@@ -1197,7 +1169,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r"""
tree grammar TP;
-            options {language=Python; output=AST; ASTLabelType=CommonTree; tokenVocab=T; rewrite=true;}
+            options {language=Python3; output=AST; ASTLabelType=CommonTree; tokenVocab=T; rewrite=true;}
s : ^(a ^(ID INT)) -> a ;
a : INT ;
""")
@@ -1209,14 +1181,14 @@ class T(testbase.ANTLRTest):
# emits whole tree when you ref the root since I can't know whether
# you want the children or not.  You might be returning a whole new
# tree.  Hmm...still seems weird.  oh well.
-        self.failUnlessEqual("(12 (abc 34))", found)
+        self.assertEqual("(12 (abc 34))", found)


def testRewriteOfRuleRefRootLabeled(self):
grammar = textwrap.dedent(
r"""
grammar T;
-            options {language=Python; output=AST;}
+            options {language=Python3; output=AST;}
a : ID INT INT -> ^(INT ^(ID INT));
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
@@ -1226,7 +1198,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r"""
tree grammar TP;
-            options {language=Python; output=AST; ASTLabelType=CommonTree; tokenVocab=T; rewrite=true;}
+            options {language=Python3; output=AST; ASTLabelType=CommonTree; tokenVocab=T; rewrite=true;}
s : ^(label=a ^(ID INT)) -> a ;
a : INT ;
""")
@@ -1238,14 +1210,14 @@ class T(testbase.ANTLRTest):
# emits whole tree when you ref the root since I can't know whether
# you want the children or not.  You might be returning a whole new
# tree.  Hmm...still seems weird.  oh well.
-        self.failUnlessEqual("(12 (abc 34))", found)
+        self.assertEqual("(12 (abc 34))", found)


def testRewriteOfRuleRefRootListLabeled(self):
grammar = textwrap.dedent(
r"""
grammar T;
-            options {language=Python; output=AST;}
+            options {language=Python3; output=AST;}
a : ID INT INT -> ^(INT ^(ID INT));
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
@@ -1255,7 +1227,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r"""
tree grammar TP;
-            options {language=Python; output=AST; ASTLabelType=CommonTree; tokenVocab=T; rewrite=true;}
+            options {language=Python3; output=AST; ASTLabelType=CommonTree; tokenVocab=T; rewrite=true;}
s : ^(label+=a ^(ID INT)) -> a ;
a : INT ;
""")
@@ -1267,14 +1239,14 @@ class T(testbase.ANTLRTest):
# emits whole tree when you ref the root since I can't know whether
# you want the children or not.  You might be returning a whole new
# tree.  Hmm...still seems weird.  oh well.
-        self.failUnlessEqual("(12 (abc 34))", found)
+        self.assertEqual("(12 (abc 34))", found)


def testRewriteOfRuleRefChild(self):
grammar = textwrap.dedent(
r"""
grammar T;
-            options {language=Python; output=AST;}
+            options {language=Python3; output=AST;}
a : ID INT -> ^(ID ^(INT INT));
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
@@ -1284,7 +1256,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r"""
tree grammar TP;
-            options {language=Python; output=AST; ASTLabelType=CommonTree; tokenVocab=T; rewrite=true;}
+            options {language=Python3; output=AST; ASTLabelType=CommonTree; tokenVocab=T; rewrite=true;}
s : ^(ID a) -> a ;
a : ^(INT INT) ;
""")
@@ -1293,14 +1265,14 @@ class T(testbase.ANTLRTest):
grammar, 'a',
treeGrammar, 's',
"abc 34")
-        self.failUnlessEqual("(34 34)", found)
+        self.assertEqual("(34 34)", found)


def testRewriteOfRuleRefLabel(self):
grammar = textwrap.dedent(
r"""
grammar T;
-            options {language=Python; output=AST;}
+            options {language=Python3; output=AST;}
a : ID INT -> ^(ID ^(INT INT));
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
@@ -1310,7 +1282,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r"""
tree grammar TP;
-            options {language=Python; output=AST; ASTLabelType=CommonTree; tokenVocab=T; rewrite=true;}
+            options {language=Python3; output=AST; ASTLabelType=CommonTree; tokenVocab=T; rewrite=true;}
s : ^(ID label=a) -> a ;
a : ^(INT INT) ;
""")
@@ -1319,14 +1291,14 @@ class T(testbase.ANTLRTest):
grammar, 'a',
treeGrammar, 's',
"abc 34")
-        self.failUnlessEqual("(34 34)", found)
+        self.assertEqual("(34 34)", found)


def testRewriteOfRuleRefListLabel(self):
grammar = textwrap.dedent(
r"""
grammar T;
-            options {language=Python; output=AST;}
+            options {language=Python3; output=AST;}
a : ID INT -> ^(ID ^(INT INT));
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
@@ -1336,7 +1308,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r"""
tree grammar TP;
-            options {language=Python; output=AST; ASTLabelType=CommonTree; tokenVocab=T; rewrite=true;}
+            options {language=Python3; output=AST; ASTLabelType=CommonTree; tokenVocab=T; rewrite=true;}
s : ^(ID label+=a) -> a ;
a : ^(INT INT) ;
""")
@@ -1345,7 +1317,7 @@ class T(testbase.ANTLRTest):
grammar, 'a',
treeGrammar, 's',
"abc 34")
-        self.failUnlessEqual("(34 34)", found)
+        self.assertEqual("(34 34)", found)



@@ -1354,7 +1326,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T19;
options {
-              language=Python;
+              language=Python3;
output=AST;
}
a : ID INT -> ^(ID["root"] ^(ID INT)) | INT -> ^(ID["root"] INT) ;
@@ -1367,7 +1339,7 @@ class T(testbase.ANTLRTest):
r'''
tree grammar TP19;
options {
-              language=Python;
+              language=Python3;
output=AST;
ASTLabelType=CommonTree;
tokenVocab=T19;
@@ -1385,7 +1357,7 @@ class T(testbase.ANTLRTest):
"abc 34"
)

-        self.failUnlessEqual("(root (ick 34))", found)
+        self.assertEqual("(root (ick 34))", found)


def testWildcardSingleNode(self):
@@ -1393,7 +1365,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T;
options {
-                language=Python;
+                language=Python3;
output=AST;
}
a : ID INT -> ^(ID["root"] INT);
@@ -1406,7 +1378,7 @@ class T(testbase.ANTLRTest):
r'''
tree grammar TP;
options {
-                language=Python;
+                language=Python3;
output=AST;
ASTLabelType=CommonTree;
tokenVocab=T;
@@ -1421,13 +1393,13 @@ class T(testbase.ANTLRTest):
"abc 34"
)

-        self.failUnlessEqual("34", found)
+        self.assertEqual("34", found)

def testWildcardUnlabeledSingleNode(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python; output=AST;}
+            options {language=Python3; output=AST;}
a : ID INT -> ^(ID INT);
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
@@ -1437,7 +1409,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r'''
tree grammar TP;
-            options {language=Python; output=AST; ASTLabelType=CommonTree; tokenVocab=T;}
+            options {language=Python3; output=AST; ASTLabelType=CommonTree; tokenVocab=T;}
s : ^(ID .) -> ID
;
''')
@@ -1446,14 +1418,14 @@ class T(testbase.ANTLRTest):
grammar, 'a',
treeGrammar, 's',
"abc 34")
-        self.assertEquals("abc", found)
+        self.assertEqual("abc", found)


def testWildcardGrabsSubtree(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python; output=AST;}
+            options {language=Python3; output=AST;}
a : ID x=INT y=INT z=INT -> ^(ID[\"root\"] ^($x $y $z));
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
@@ -1463,7 +1435,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r'''
tree grammar TP;
-            options {language=Python; output=AST; ASTLabelType=CommonTree; tokenVocab=T;}
+            options {language=Python3; output=AST; ASTLabelType=CommonTree; tokenVocab=T;}
s : ^(ID c=.) -> $c
;
''')
@@ -1472,14 +1444,14 @@ class T(testbase.ANTLRTest):
grammar, 'a',
treeGrammar, 's',
"abc 1 2 3")
-        self.assertEquals("(1 2 3)", found)
+        self.assertEqual("(1 2 3)", found)


def testWildcardGrabsSubtree2(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python; output=AST;}
+            options {language=Python3; output=AST;}
a : ID x=INT y=INT z=INT -> ID ^($x $y $z);
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
@@ -1489,7 +1461,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r'''
tree grammar TP;
-            options {language=Python; output=AST; ASTLabelType=CommonTree; tokenVocab=T;}
+            options {language=Python3; output=AST; ASTLabelType=CommonTree; tokenVocab=T;}
s : ID c=. -> $c
;
''')
@@ -1498,14 +1470,14 @@ class T(testbase.ANTLRTest):
grammar, 'a',
treeGrammar, 's',
"abc 1 2 3")
-        self.assertEquals("(1 2 3)", found)
+        self.assertEqual("(1 2 3)", found)


def testWildcardListLabel(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python; output=AST;}
+            options {language=Python3; output=AST;}
a : INT INT INT ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
@@ -1515,7 +1487,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r'''
tree grammar TP;
-            options {language=Python; output=AST; ASTLabelType=CommonTree; tokenVocab=T;}
+            options {language=Python3; output=AST; ASTLabelType=CommonTree; tokenVocab=T;}
s : (c+=.)+ -> $c+
;
''')
@@ -1524,14 +1496,14 @@ class T(testbase.ANTLRTest):
grammar, 'a',
treeGrammar, 's',
"1 2 3")
-        self.assertEquals("1 2 3", found)
+        self.assertEqual("1 2 3", found)


def testWildcardListLabel2(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python; output=AST; ASTLabelType=CommonTree;}
+            options {language=Python3; output=AST; ASTLabelType=CommonTree;}
a  : x=INT y=INT z=INT -> ^($x ^($y $z) ^($y $z));
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
@@ -1541,7 +1513,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r'''
tree grammar TP;
-            options {language=Python; output=AST; ASTLabelType=CommonTree; tokenVocab=T; rewrite=true;}
+            options {language=Python3; output=AST; ASTLabelType=CommonTree; tokenVocab=T; rewrite=true;}
s : ^(INT (c+=.)+) -> $c+
;
''')
@@ -1550,7 +1522,7 @@ class T(testbase.ANTLRTest):
grammar, 'a',
treeGrammar, 's',
"1 2 3")
-        self.assertEquals("(2 3) (2 3)", found)
+        self.assertEqual("(2 3) (2 3)", found)


def testRuleResultAsRoot(self):
@@ -1558,7 +1530,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T;
options {
-                language=Python;
+                language=Python3;
output=AST;
}
a : ID '=' INT -> ^('=' ID INT);
@@ -1572,7 +1544,7 @@ class T(testbase.ANTLRTest):
r'''
tree grammar TP;
options {
-                language=Python;
+                language=Python3;
output=AST;
rewrite=true;
ASTLabelType=CommonTree;
@@ -1586,7 +1558,7 @@ class T(testbase.ANTLRTest):
grammar, 'a',
treeGrammar, 'a',
"abc = 34")
-        self.assertEquals("(= 34 abc)", found)
+        self.assertEqual("(= 34 abc)", found)


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t052import.py b/runtime/Python3/tests/t052import.py
index 8924462..d6de6ef 100644
--- a/runtime/Python3/tests/t052import.py
+++ b/runtime/Python3/tests/t052import.py
@@ -18,7 +18,7 @@ class T(testbase.ANTLRTest):
def parserClass(self, base):
class TParser(base):
def __init__(self, *args, **kwargs):
-                base.__init__(self, *args, **kwargs)
+                super().__init__(*args, **kwargs)

self._output = ""

@@ -45,7 +45,7 @@ class T(testbase.ANTLRTest):
def lexerClass(self, base):
class TLexer(base):
def __init__(self, *args, **kwargs):
-                base.__init__(self, *args, **kwargs)
+                super().__init__(*args, **kwargs)

self._output = ""

@@ -74,10 +74,8 @@ class T(testbase.ANTLRTest):
parserName = self.writeInlineGrammar(slave)[0]
# slave parsers are imported as normal python modules
# to force reloading current version, purge module from sys.modules
-            try:
-                del sys.modules[parserName+'Parser']
-            except KeyError:
-                pass
+            if parserName + 'Parser' in sys.modules:
+                del sys.modules[parserName + 'Parser']

lexerCls, parserCls = self.compileInlineGrammar(grammar)

@@ -95,10 +93,8 @@ class T(testbase.ANTLRTest):
parserName = self.writeInlineGrammar(slave)[0]
# slave parsers are imported as normal python modules
# to force reloading current version, purge module from sys.modules
-            try:
-                del sys.modules[parserName+'Parser']
-            except KeyError:
-                pass
+            if parserName + 'Parser' in sys.modules:
+                del sys.modules[parserName + 'Parser']

lexerCls = self.compileInlineGrammar(grammar)

@@ -115,23 +111,12 @@ class T(testbase.ANTLRTest):
return lexer._output


-    # @Test public void testWildcardStillWorks() throws Exception {
-    #     ErrorQueue equeue = new ErrorQueue();
-    #     ErrorManager.setErrorListener(equeue);
-    #     String grammar =
-    #     "parser grammar S;\n" +
-    #     "a : B . C ;\n"; // not qualified ID
-    #     Grammar g = new Grammar(grammar);
-    #     assertEquals("unexpected errors: "+equeue, 0, equeue.errors.size());
-    #     }
-
-
def testDelegatorInvokesDelegateRule(self):
slave = textwrap.dedent(
r'''
parser grammar S1;
options {
-            language=Python;
+            language=Python3;
}
@members {
def capture(self, t):
@@ -146,7 +131,7 @@ class T(testbase.ANTLRTest):
r'''
grammar M1;
options {
-            language=Python;
+            language=Python3;
}
import S1;
s : a ;
@@ -160,28 +145,7 @@ class T(testbase.ANTLRTest):
input="b"
)

-        self.failUnlessEqual("S.a", found)
-
-
-        # @Test public void testDelegatorInvokesDelegateRuleWithReturnStruct() throws Exception {
-        #     // must generate something like:
-        #          // public int a(int x) throws RecognitionException { return gS.a(x); }
-        #        // in M.
-        #        String slave =
-        #        "parser grammar S;\n" +
-        #        "a : B {System.out.print(\"S.a\");} ;\n";
-        #        mkdir(tmpdir);
-        #        writeFile(tmpdir, "S.g", slave);
-        #        String master =
-        #        "grammar M;\n" +
-        #        "import S;\n" +
-        #        "s : a {System.out.println($a.text);} ;\n" +
-        #        "B : 'b' ;" + // defines B from inherited token space
-        #        "WS : (' '|'\\n') {skip();} ;\n" ;
-        #        String found = execParser("M.g", master, "MParser", "MLexer",
-        #                                    "s", "b", debug);
-        #        assertEquals("S.ab\n", found);
-        #        }
+        self.assertEqual("S.a", found)


def testDelegatorInvokesDelegateRuleWithArgs(self):
@@ -189,7 +153,7 @@ class T(testbase.ANTLRTest):
r'''
parser grammar S2;
options {
-            language=Python;
+            language=Python3;
}
@members {
def capture(self, t):
@@ -202,7 +166,7 @@ class T(testbase.ANTLRTest):
r'''
grammar M2;
options {
-            language=Python;
+            language=Python3;
}
import S2;
s : label=a[3] {self.capture($label.y);} ;
@@ -216,7 +180,7 @@ class T(testbase.ANTLRTest):
input="b"
)

-        self.failUnlessEqual("S.a1000", found)
+        self.assertEqual("S.a1000", found)


def testDelegatorAccessesDelegateMembers(self):
@@ -224,7 +188,7 @@ class T(testbase.ANTLRTest):
r'''
parser grammar S3;
options {
-            language=Python;
+            language=Python3;
}
@members {
def capture(self, t):
@@ -240,7 +204,7 @@ class T(testbase.ANTLRTest):
r'''
grammar M3;        // uses no rules from the import
options {
-            language=Python;
+            language=Python3;
}
import S3;
s : 'b' {self.gS3.foo();} ; // gS is import pointer
@@ -253,7 +217,7 @@ class T(testbase.ANTLRTest):
input="b"
)

-        self.failUnlessEqual("foo", found)
+        self.assertEqual("foo", found)


def testDelegatorInvokesFirstVersionOfDelegateRule(self):
@@ -261,7 +225,7 @@ class T(testbase.ANTLRTest):
r'''
parser grammar S4;
options {
-            language=Python;
+            language=Python3;
}
@members {
def capture(self, t):
@@ -275,7 +239,7 @@ class T(testbase.ANTLRTest):
r'''
parser grammar T4;
options {
-            language=Python;
+            language=Python3;
}
@members {
def capture(self, t):
@@ -288,7 +252,7 @@ class T(testbase.ANTLRTest):
r'''
grammar M4;
options {
-            language=Python;
+            language=Python3;
}
import S4,T4;
s : a ;
@@ -302,7 +266,7 @@ class T(testbase.ANTLRTest):
input="b"
)

-        self.failUnlessEqual("S.a", found)
+        self.assertEqual("S.a", found)


def testDelegatesSeeSameTokenType(self):
@@ -310,7 +274,7 @@ class T(testbase.ANTLRTest):
r'''
parser grammar S5; // A, B, C token type order
options {
-            language=Python;
+            language=Python3;
}
tokens { A; B; C; }
@members {
@@ -324,7 +288,7 @@ class T(testbase.ANTLRTest):
r'''
parser grammar T5;
options {
-            language=Python;
+            language=Python3;
}
tokens { C; B; A; } /// reverse order
@members {
@@ -338,7 +302,7 @@ class T(testbase.ANTLRTest):
r'''
grammar M5;
options {
-            language=Python;
+            language=Python3;
}
import S5,T5;
s : x y ; // matches AA, which should be "aa"
@@ -354,320 +318,7 @@ class T(testbase.ANTLRTest):
input="aa"
)

-        self.failUnlessEqual("S.x T.y", found)
-
-
-        # @Test public void testDelegatesSeeSameTokenType2() throws Exception {
-        #         ErrorQueue equeue = new ErrorQueue();
-        #         ErrorManager.setErrorListener(equeue);
-        #         String slave =
-        #                 "parser grammar S;\n" + // A, B, C token type order
-        #                 "tokens { A; B; C; }\n" +
-        #                 "x : A {System.out.println(\"S.x\");} ;\n";
-        #         mkdir(tmpdir);
-        #         writeFile(tmpdir, "S.g", slave);
-        #         String slave2 =
-        #                 "parser grammar T;\n" +
-        #                 "tokens { C; B; A; }\n" + // reverse order
-        #                 "y : A {System.out.println(\"T.y\");} ;\n";
-        #         mkdir(tmpdir);
-        #         writeFile(tmpdir, "T.g", slave2);
-
-        #         String master =
-        #                 "grammar M;\n" +
-        #                 "import S,T;\n" +
-        #                 "s : x y ;\n" + // matches AA, which should be "aa"
-        #                 "B : 'b' ;\n" + // another order: B, A, C
-        #                 "A : 'a' ;\n" +
-        #                 "C : 'c' ;\n" +
-        #                 "WS : (' '|'\\n') {skip();} ;\n" ;
-        #         writeFile(tmpdir, "M.g", master);
-        #         Tool antlr = newTool(new String[] {"-lib", tmpdir});
-        #         CompositeGrammar composite = new CompositeGrammar();
-        #         Grammar g = new Grammar(antlr,tmpdir+"/M.g",composite);
-        #         composite.setDelegationRoot(g);
-        #         g.parseAndBuildAST();
-        #         g.composite.assignTokenTypes();
-
-        #         String expectedTokenIDToTypeMap = "[A=4, B=5, C=6, WS=7]";
-        #         String expectedStringLiteralToTypeMap = "{}";
-        #         String expectedTypeToTokenList = "[A, B, C, WS]";
-
-        #         assertEquals(expectedTokenIDToTypeMap,
-        #                                  realElements(g.composite.tokenIDToTypeMap).toString());
-        #         assertEquals(expectedStringLiteralToTypeMap, g.composite.stringLiteralToTypeMap.toString());
-        #         assertEquals(expectedTypeToTokenList,
-        #                                  realElements(g.composite.typeToTokenList).toString());
-
-        #         assertEquals("unexpected errors: "+equeue, 0, equeue.errors.size());
-        # }
-
-        # @Test public void testCombinedImportsCombined() throws Exception {
-        #         // for now, we don't allow combined to import combined
-        #         ErrorQueue equeue = new ErrorQueue();
-        #         ErrorManager.setErrorListener(equeue);
-        #         String slave =
-        #                 "grammar S;\n" + // A, B, C token type order
-        #                 "tokens { A; B; C; }\n" +
-        #                 "x : 'x' INT {System.out.println(\"S.x\");} ;\n" +
-        #                 "INT : '0'..'9'+ ;\n" +
-        #                 "WS : (' '|'\\n') {skip();} ;\n";
-        #         mkdir(tmpdir);
-        #         writeFile(tmpdir, "S.g", slave);
-
-        #         String master =
-        #                 "grammar M;\n" +
-        #                 "import S;\n" +
-        #                 "s : x INT ;\n";
-        #         writeFile(tmpdir, "M.g", master);
-        #         Tool antlr = newTool(new String[] {"-lib", tmpdir});
-        #         CompositeGrammar composite = new CompositeGrammar();
-        #         Grammar g = new Grammar(antlr,tmpdir+"/M.g",composite);
-        #         composite.setDelegationRoot(g);
-        #         g.parseAndBuildAST();
-        #         g.composite.assignTokenTypes();
-
-        #         assertEquals("unexpected errors: "+equeue, 1, equeue.errors.size());
-        #         String expectedError = "error(161): "+tmpdir.toString().replaceFirst("\\-[0-9]+","")+"/M.g:2:8: combined grammar M cannot import combined grammar S";
-        #         assertEquals("unexpected errors: "+equeue, expectedError, equeue.errors.get(0).toString().replaceFirst("\\-[0-9]+",""));
-        # }
-
-        # @Test public void testSameStringTwoNames() throws Exception {
-        #         ErrorQueue equeue = new ErrorQueue();
-        #         ErrorManager.setErrorListener(equeue);
-        #         String slave =
-        #                 "parser grammar S;\n" +
-        #                 "tokens { A='a'; }\n" +
-        #                 "x : A {System.out.println(\"S.x\");} ;\n";
-        #         mkdir(tmpdir);
-        #         writeFile(tmpdir, "S.g", slave);
-        #         String slave2 =
-        #                 "parser grammar T;\n" +
-        #                 "tokens { X='a'; }\n" +
-        #                 "y : X {System.out.println(\"T.y\");} ;\n";
-        #         mkdir(tmpdir);
-        #         writeFile(tmpdir, "T.g", slave2);
-
-        #         String master =
-        #                 "grammar M;\n" +
-        #                 "import S,T;\n" +
-        #                 "s : x y ;\n" +
-        #                 "WS : (' '|'\\n') {skip();} ;\n" ;
-        #         writeFile(tmpdir, "M.g", master);
-        #         Tool antlr = newTool(new String[] {"-lib", tmpdir});
-        #         CompositeGrammar composite = new CompositeGrammar();
-        #         Grammar g = new Grammar(antlr,tmpdir+"/M.g",composite);
-        #         composite.setDelegationRoot(g);
-        #         g.parseAndBuildAST();
-        #         g.composite.assignTokenTypes();
-
-        #         String expectedTokenIDToTypeMap = "[A=4, WS=6, X=5]";
-        #         String expectedStringLiteralToTypeMap = "{'a'=4}";
-        #         String expectedTypeToTokenList = "[A, X, WS]";
-
-        #         assertEquals(expectedTokenIDToTypeMap,
-        #                                  realElements(g.composite.tokenIDToTypeMap).toString());
-        #         assertEquals(expectedStringLiteralToTypeMap, g.composite.stringLiteralToTypeMap.toString());
-        #         assertEquals(expectedTypeToTokenList,
-        #                                  realElements(g.composite.typeToTokenList).toString());
-
-        #         Object expectedArg = "X='a'";
-        #         Object expectedArg2 = "A";
-        #         int expectedMsgID = ErrorManager.MSG_TOKEN_ALIAS_CONFLICT;
-        #         GrammarSemanticsMessage expectedMessage =
-        #                 new GrammarSemanticsMessage(expectedMsgID, g, null, expectedArg, expectedArg2);
-        #         checkGrammarSemanticsError(equeue, expectedMessage);
-
-        #         assertEquals("unexpected errors: "+equeue, 1, equeue.errors.size());
-
-        #         String expectedError =
-        #                 "error(158): T.g:2:10: cannot alias X='a'; string already assigned to A";
-        #         assertEquals(expectedError, equeue.errors.get(0).toString());
-        # }
-
-        # @Test public void testSameNameTwoStrings() throws Exception {
-        #         ErrorQueue equeue = new ErrorQueue();
-        #         ErrorManager.setErrorListener(equeue);
-        #         String slave =
-        #                 "parser grammar S;\n" +
-        #                 "tokens { A='a'; }\n" +
-        #                 "x : A {System.out.println(\"S.x\");} ;\n";
-        #         mkdir(tmpdir);
-        #         writeFile(tmpdir, "S.g", slave);
-        #         String slave2 =
-        #                 "parser grammar T;\n" +
-        #                 "tokens { A='x'; }\n" +
-        #                 "y : A {System.out.println(\"T.y\");} ;\n";
-
-        #         writeFile(tmpdir, "T.g", slave2);
-
-        #         String master =
-        #                 "grammar M;\n" +
-        #                 "import S,T;\n" +
-        #                 "s : x y ;\n" +
-        #                 "WS : (' '|'\\n') {skip();} ;\n" ;
-        #         writeFile(tmpdir, "M.g", master);
-        #         Tool antlr = newTool(new String[] {"-lib", tmpdir});
-        #         CompositeGrammar composite = new CompositeGrammar();
-        #         Grammar g = new Grammar(antlr,tmpdir+"/M.g",composite);
-        #         composite.setDelegationRoot(g);
-        #         g.parseAndBuildAST();
-        #         g.composite.assignTokenTypes();
-
-        #         String expectedTokenIDToTypeMap = "[A=4, T__6=6, WS=5]";
-        #         String expectedStringLiteralToTypeMap = "{'a'=4, 'x'=6}";
-        #         String expectedTypeToTokenList = "[A, WS, T__6]";
-
-        #         assertEquals(expectedTokenIDToTypeMap,
-        #                                  realElements(g.composite.tokenIDToTypeMap).toString());
-        #         assertEquals(expectedStringLiteralToTypeMap, sortMapToString(g.composite.stringLiteralToTypeMap));
-        #         assertEquals(expectedTypeToTokenList,
-        #                                  realElements(g.composite.typeToTokenList).toString());
-
-        #         Object expectedArg = "A='x'";
-        #         Object expectedArg2 = "'a'";
-        #         int expectedMsgID = ErrorManager.MSG_TOKEN_ALIAS_REASSIGNMENT;
-        #         GrammarSemanticsMessage expectedMessage =
-        #                 new GrammarSemanticsMessage(expectedMsgID, g, null, expectedArg, expectedArg2);
-        #         checkGrammarSemanticsError(equeue, expectedMessage);
-
-        #         assertEquals("unexpected errors: "+equeue, 1, equeue.errors.size());
-
-        #         String expectedError =
-        #                 "error(159): T.g:2:10: cannot alias A='x'; token name already assigned to 'a'";
-        #         assertEquals(expectedError, equeue.errors.get(0).toString());
-        # }
-
-        # @Test public void testImportedTokenVocabIgnoredWithWarning() throws Exception {
-        #         ErrorQueue equeue = new ErrorQueue();
-        #         ErrorManager.setErrorListener(equeue);
-        #         String slave =
-        #                 "parser grammar S;\n" +
-        #                 "options {tokenVocab=whatever;}\n" +
-        #                 "tokens { A='a'; }\n" +
-        #                 "x : A {System.out.println(\"S.x\");} ;\n";
-        #         mkdir(tmpdir);
-        #         writeFile(tmpdir, "S.g", slave);
-
-        #         String master =
-        #                 "grammar M;\n" +
-        #                 "import S;\n" +
-        #                 "s : x ;\n" +
-        #                 "WS : (' '|'\\n') {skip();} ;\n" ;
-        #         writeFile(tmpdir, "M.g", master);
-        #         Tool antlr = newTool(new String[] {"-lib", tmpdir});
-        #         CompositeGrammar composite = new CompositeGrammar();
-        #         Grammar g = new Grammar(antlr,tmpdir+"/M.g",composite);
-        #         composite.setDelegationRoot(g);
-        #         g.parseAndBuildAST();
-        #         g.composite.assignTokenTypes();
-
-        #         Object expectedArg = "S";
-        #         int expectedMsgID = ErrorManager.MSG_TOKEN_VOCAB_IN_DELEGATE;
-        #         GrammarSemanticsMessage expectedMessage =
-        #                 new GrammarSemanticsMessage(expectedMsgID, g, null, expectedArg);
-        #         checkGrammarSemanticsWarning(equeue, expectedMessage);
-
-        #         assertEquals("unexpected errors: "+equeue, 0, equeue.errors.size());
-        #         assertEquals("unexpected errors: "+equeue, 1, equeue.warnings.size());
-
-        #         String expectedError =
-        #                 "warning(160): S.g:2:10: tokenVocab option ignored in imported grammar S";
-        #         assertEquals(expectedError, equeue.warnings.get(0).toString());
-        # }
-
-        # @Test public void testImportedTokenVocabWorksInRoot() throws Exception {
-        #         ErrorQueue equeue = new ErrorQueue();
-        #         ErrorManager.setErrorListener(equeue);
-        #         String slave =
-        #                 "parser grammar S;\n" +
-        #                 "tokens { A='a'; }\n" +
-        #                 "x : A {System.out.println(\"S.x\");} ;\n";
-        #         mkdir(tmpdir);
-        #         writeFile(tmpdir, "S.g", slave);
-
-        #         String tokens =
-        #                 "A=99\n";
-        #         writeFile(tmpdir, "Test.tokens", tokens);
-
-        #         String master =
-        #                 "grammar M;\n" +
-        #                 "options {tokenVocab=Test;}\n" +
-        #                 "import S;\n" +
-        #                 "s : x ;\n" +
-        #                 "WS : (' '|'\\n') {skip();} ;\n" ;
-        #         writeFile(tmpdir, "M.g", master);
-        #         Tool antlr = newTool(new String[] {"-lib", tmpdir});
-        #         CompositeGrammar composite = new CompositeGrammar();
-        #         Grammar g = new Grammar(antlr,tmpdir+"/M.g",composite);
-        #         composite.setDelegationRoot(g);
-        #         g.parseAndBuildAST();
-        #         g.composite.assignTokenTypes();
-
-        #         String expectedTokenIDToTypeMap = "[A=99, WS=101]";
-        #         String expectedStringLiteralToTypeMap = "{'a'=100}";
-        #         String expectedTypeToTokenList = "[A, 'a', WS]";
-
-        #         assertEquals(expectedTokenIDToTypeMap,
-        #                                  realElements(g.composite.tokenIDToTypeMap).toString());
-        #         assertEquals(expectedStringLiteralToTypeMap, g.composite.stringLiteralToTypeMap.toString());
-        #         assertEquals(expectedTypeToTokenList,
-        #                                  realElements(g.composite.typeToTokenList).toString());
-
-        #         assertEquals("unexpected errors: "+equeue, 0, equeue.errors.size());
-        # }
-
-        # @Test public void testSyntaxErrorsInImportsNotThrownOut() throws Exception {
-        #         ErrorQueue equeue = new ErrorQueue();
-        #         ErrorManager.setErrorListener(equeue);
-        #         String slave =
-        #                 "parser grammar S;\n" +
-        #                 "options {toke\n";
-        #         mkdir(tmpdir);
-        #         writeFile(tmpdir, "S.g", slave);
-
-        #         String master =
-        #                 "grammar M;\n" +
-        #                 "import S;\n" +
-        #                 "s : x ;\n" +
-        #                 "WS : (' '|'\\n') {skip();} ;\n" ;
-        #         writeFile(tmpdir, "M.g", master);
-        #         Tool antlr = newTool(new String[] {"-lib", tmpdir});
-        #         CompositeGrammar composite = new CompositeGrammar();
-        #         Grammar g = new Grammar(antlr,tmpdir+"/M.g",composite);
-        #         composite.setDelegationRoot(g);
-        #         g.parseAndBuildAST();
-        #         g.composite.assignTokenTypes();
-
-        #         // whole bunch of errors from bad S.g file
-        #         assertEquals("unexpected errors: "+equeue, 5, equeue.errors.size());
-        # }
-
-        # @Test public void testSyntaxErrorsInImportsNotThrownOut2() throws Exception {
-        #         ErrorQueue equeue = new ErrorQueue();
-        #         ErrorManager.setErrorListener(equeue);
-        #         String slave =
-        #                 "parser grammar S;\n" +
-        #                 ": A {System.out.println(\"S.x\");} ;\n";
-        #         mkdir(tmpdir);
-        #         writeFile(tmpdir, "S.g", slave);
-
-        #         String master =
-        #                 "grammar M;\n" +
-        #                 "import S;\n" +
-        #                 "s : x ;\n" +
-        #                 "WS : (' '|'\\n') {skip();} ;\n" ;
-        #         writeFile(tmpdir, "M.g", master);
-        #         Tool antlr = newTool(new String[] {"-lib", tmpdir});
-        #         CompositeGrammar composite = new CompositeGrammar();
-        #         Grammar g = new Grammar(antlr,tmpdir+"/M.g",composite);
-        #         composite.setDelegationRoot(g);
-        #         g.parseAndBuildAST();
-        #         g.composite.assignTokenTypes();
-
-        #         // whole bunch of errors from bad S.g file
-        #         assertEquals("unexpected errors: "+equeue, 3, equeue.errors.size());
-        # }
+        self.assertEqual("S.x T.y", found)


def testDelegatorRuleOverridesDelegate(self):
@@ -675,7 +326,7 @@ class T(testbase.ANTLRTest):
r'''
parser grammar S6;
options {
-            language=Python;
+            language=Python3;
}
@members {
def capture(self, t):
@@ -689,7 +340,7 @@ class T(testbase.ANTLRTest):
r'''
grammar M6;
options {
-            language=Python;
+            language=Python3;
}
import S6;
b : 'b'|'c' ;
@@ -702,58 +353,8 @@ class T(testbase.ANTLRTest):
input="c"
)

-        self.failUnlessEqual("S.a", found)
-
-
-    #     @Test public void testDelegatorRuleOverridesLookaheadInDelegate() throws Exception {
-    #             String slave =
-    #                     "parser grammar JavaDecl;\n" +
-    #                     "type : 'int' ;\n" +
-    #                     "decl : type ID ';'\n" +
-    #                     "     | type ID init ';' {System.out.println(\"JavaDecl: \"+$decl.text);}\n" +
-    #                     "     ;\n" +
-    #                     "init : '=' INT ;\n" ;
-    #             mkdir(tmpdir);
-    #             writeFile(tmpdir, "JavaDecl.g", slave);
-    #             String master =
-    #                     "grammar Java;\n" +
-    #                     "import JavaDecl;\n" +
-    #                     "prog : decl ;\n" +
-    #                     "type : 'int' | 'float' ;\n" +
-    #                     "\n" +
-    #                     "ID  : 'a'..'z'+ ;\n" +
-    #                     "INT : '0'..'9'+ ;\n" +
-    #                     "WS : (' '|'\\n') {skip();} ;\n" ;
-    #             // for float to work in decl, type must be overridden
-    #             String found = execParser("Java.g", master, "JavaParser", "JavaLexer",
-    #                                                               "prog", "float x = 3;", debug);
-    #             assertEquals("JavaDecl: floatx=3;\n", found);
-    #     }
-
-    # @Test public void testDelegatorRuleOverridesDelegates() throws Exception {
-    #     String slave =
-    #         "parser grammar S;\n" +
-    #         "a : b {System.out.println(\"S.a\");} ;\n" +
-    #         "b : B ;\n" ;
-    #     mkdir(tmpdir);
-    #     writeFile(tmpdir, "S.g", slave);
-
-    #     String slave2 =
-    #         "parser grammar T;\n" +
-    #         "tokens { A='x'; }\n" +
-    #         "b : B {System.out.println(\"T.b\");} ;\n";
-    #     writeFile(tmpdir, "T.g", slave2);
-
-    #     String master =
-    #         "grammar M;\n" +
-    #         "import S, T;\n" +
-    #         "b : 'b'|'c' {System.out.println(\"M.b\");}|B|A ;\n" +
-    #         "WS : (' '|'\\n') {skip();} ;\n" ;
-    #     String found = execParser("M.g", master, "MParser", "MLexer",
-    #                               "a", "c", debug);
-    #     assertEquals("M.b\n" +
-    #                  "S.a\n", found);
-    # }
+        self.assertEqual("S.a", found)
+

# LEXER INHERITANCE

@@ -762,7 +363,7 @@ class T(testbase.ANTLRTest):
r'''
lexer grammar S7;
options {
-            language=Python;
+            language=Python3;
}
@members {
def capture(self, t):
@@ -776,7 +377,7 @@ class T(testbase.ANTLRTest):
r'''
lexer grammar M7;
options {
-            language=Python;
+            language=Python3;
}
import S7;
B : 'b' ;
@@ -789,7 +390,7 @@ class T(testbase.ANTLRTest):
input="abc"
)

-        self.failUnlessEqual("S.A abc", found)
+        self.assertEqual("S.A abc", found)


def testLexerDelegatorRuleOverridesDelegate(self):
@@ -797,7 +398,7 @@ class T(testbase.ANTLRTest):
r'''
lexer grammar S8;
options {
-            language=Python;
+            language=Python3;
}
@members {
def capture(self, t):
@@ -810,7 +411,7 @@ class T(testbase.ANTLRTest):
r'''
lexer grammar M8;
options {
-            language=Python;
+            language=Python3;
}
import S8;
A : 'a' {self.capture("M.A ");} ;
@@ -823,380 +424,7 @@ class T(testbase.ANTLRTest):
input="a"
)

-        self.failUnlessEqual("M.A a", found)
-
-        # @Test public void testLexerDelegatorRuleOverridesDelegateLeavingNoRules() throws Exception {
-        #         // M.Tokens has nothing to predict tokens from S.  Should
-        #         // not include S.Tokens alt in this case?
-        #         String slave =
-        #                 "lexer grammar S;\n" +
-        #                 "A : 'a' {System.out.println(\"S.A\");} ;\n";
-        #         mkdir(tmpdir);
-        #         writeFile(tmpdir, "S.g", slave);
-        #         String master =
-        #                 "lexer grammar M;\n" +
-        #                 "import S;\n" +
-        #                 "A : 'a' {System.out.println(\"M.A\");} ;\n" +
-        #                 "WS : (' '|'\\n') {skip();} ;\n" ;
-        #         writeFile(tmpdir, "/M.g", master);
-
-        #         ErrorQueue equeue = new ErrorQueue();
-        #         ErrorManager.setErrorListener(equeue);
-        #         Tool antlr = newTool(new String[] {"-lib", tmpdir});
-        #         CompositeGrammar composite = new CompositeGrammar();
-        #         Grammar g = new Grammar(antlr,tmpdir+"/M.g",composite);
-        #         composite.setDelegationRoot(g);
-        #         g.parseAndBuildAST();
-        #         composite.assignTokenTypes();
-        #         composite.defineGrammarSymbols();
-        #         composite.createNFAs();
-        #         g.createLookaheadDFAs(false);
-
-        #         // predict only alts from M not S
-        #         String expectingDFA =
-        #                 ".s0-'a'->.s1\n" +
-        #                 ".s0-{'\\n', ' '}->:s3=>2\n" +
-        #                 ".s1-<EOT>->:s2=>1\n";
-        #         org.antlr.analysis.DFA dfa = g.getLookaheadDFA(1);
-        #         FASerializer serializer = new FASerializer(g);
-        #         String result = serializer.serialize(dfa.startState);
-        #         assertEquals(expectingDFA, result);
-
-        #         // must not be a "unreachable alt: Tokens" error
-        #         assertEquals("unexpected errors: "+equeue, 0, equeue.errors.size());
-        # }
-
-        # @Test public void testInvalidImportMechanism() throws Exception {
-        #         // M.Tokens has nothing to predict tokens from S.  Should
-        #         // not include S.Tokens alt in this case?
-        #         String slave =
-        #                 "lexer grammar S;\n" +
-        #                 "A : 'a' {System.out.println(\"S.A\");} ;\n";
-        #         mkdir(tmpdir);
-        #         writeFile(tmpdir, "S.g", slave);
-        #         String master =
-        #                 "tree grammar M;\n" +
-        #                 "import S;\n" +
-        #                 "a : A ;";
-        #         writeFile(tmpdir, "/M.g", master);
-
-        #         ErrorQueue equeue = new ErrorQueue();
-        #         ErrorManager.setErrorListener(equeue);
-        #         Tool antlr = newTool(new String[] {"-lib", tmpdir});
-        #         CompositeGrammar composite = new CompositeGrammar();
-        #         Grammar g = new Grammar(antlr,tmpdir+"/M.g",composite);
-        #         composite.setDelegationRoot(g);
-        #         g.parseAndBuildAST();
-
-        #         assertEquals("unexpected errors: "+equeue, 1, equeue.errors.size());
-        #         assertEquals("unexpected errors: "+equeue, 0, equeue.warnings.size());
-
-        #         String expectedError =
-        #                 "error(161): "+tmpdir.toString().replaceFirst("\\-[0-9]+","")+"/M.g:2:8: tree grammar M cannot import lexer grammar S";
-        #         assertEquals(expectedError, equeue.errors.get(0).toString().replaceFirst("\\-[0-9]+",""));
-        # }
-
-        # @Test public void testSyntacticPredicateRulesAreNotInherited() throws Exception {
-        #         // if this compiles, it means that synpred1_S is defined in S.java
-        #         // but not MParser.java.  MParser has its own synpred1_M which must
-        #         // be separate to compile.
-        #         String slave =
-        #                 "parser grammar S;\n" +
-        #                 "a : 'a' {System.out.println(\"S.a1\");}\n" +
-        #                 "  | 'a' {System.out.println(\"S.a2\");}\n" +
-        #                 "  ;\n" +
-        #                 "b : 'x' | 'y' {;} ;\n"; // preds generated but not need in DFA here
-        #         mkdir(tmpdir);
-        #         writeFile(tmpdir, "S.g", slave);
-        #         String master =
-        #                 "grammar M;\n" +
-        #                 "options {backtrack=true;}\n" +
-        #                 "import S;\n" +
-        #                 "start : a b ;\n" +
-        #                 "nonsense : 'q' | 'q' {;} ;" + // forces def of preds here in M
-        #                 "WS : (' '|'\\n') {skip();} ;\n" ;
-        #         String found = execParser("M.g", master, "MParser", "MLexer",
-        #                                                           "start", "ax", debug);
-        #         assertEquals("S.a1\n", found);
-        # }
-
-        # @Test public void testKeywordVSIDGivesNoWarning() throws Exception {
-        #         ErrorQueue equeue = new ErrorQueue();
-        #         ErrorManager.setErrorListener(equeue);
-        #         String slave =
-        #                 "lexer grammar S;\n" +
-        #                 "A : 'abc' {System.out.println(\"S.A\");} ;\n" +
-        #                 "ID : 'a'..'z'+ ;\n";
-        #         mkdir(tmpdir);
-        #         writeFile(tmpdir, "S.g", slave);
-        #         String master =
-        #                 "grammar M;\n" +
-        #                 "import S;\n" +
-        #                 "a : A {System.out.println(\"M.a\");} ;\n" +
-        #                 "WS : (' '|'\\n') {skip();} ;\n" ;
-        #         String found = execParser("M.g", master, "MParser", "MLexer",
-        #                                                           "a", "abc", debug);
-
-        #         assertEquals("unexpected errors: "+equeue, 0, equeue.errors.size());
-        #         assertEquals("unexpected warnings: "+equeue, 0, equeue.warnings.size());
-
-        #         assertEquals("S.A\nM.a\n", found);
-        # }
-
-        # @Test public void testWarningForUndefinedToken() throws Exception {
-        #         ErrorQueue equeue = new ErrorQueue();
-        #         ErrorManager.setErrorListener(equeue);
-        #         String slave =
-        #                 "lexer grammar S;\n" +
-        #                 "A : 'abc' {System.out.println(\"S.A\");} ;\n";
-        #         mkdir(tmpdir);
-        #         writeFile(tmpdir, "S.g", slave);
-        #         String master =
-        #                 "grammar M;\n" +
-        #                 "import S;\n" +
-        #                 "a : ABC A {System.out.println(\"M.a\");} ;\n" +
-        #                 "WS : (' '|'\\n') {skip();} ;\n" ;
-        #         // A is defined in S but M should still see it and not give warning.
-        #         // only problem is ABC.
-
-        #         rawGenerateAndBuildRecognizer("M.g", master, "MParser", "MLexer", debug);
-
-        #         assertEquals("unexpected errors: "+equeue, 0, equeue.errors.size());
-        #         assertEquals("unexpected warnings: "+equeue, 1, equeue.warnings.size());
-
-        #         String expectedError =
-        #                 "warning(105): "+tmpdir.toString().replaceFirst("\\-[0-9]+","")+"/M.g:3:5: no lexer rule corresponding to token: ABC";
-        #         assertEquals(expectedError, equeue.warnings.get(0).toString().replaceFirst("\\-[0-9]+",""));
-        # }
-
-        # /** Make sure that M can import S that imports T. */
-        # @Test public void test3LevelImport() throws Exception {
-        #         ErrorQueue equeue = new ErrorQueue();
-        #         ErrorManager.setErrorListener(equeue);
-        #         String slave =
-        #                 "parser grammar T;\n" +
-        #                 "a : T ;\n" ;
-        #         mkdir(tmpdir);
-        #         writeFile(tmpdir, "T.g", slave);
-        #         String slave2 =
-        #                 "parser grammar S;\n" + // A, B, C token type order
-        #                 "import T;\n" +
-        #                 "a : S ;\n" ;
-        #         mkdir(tmpdir);
-        #         writeFile(tmpdir, "S.g", slave2);
-
-        #         String master =
-        #                 "grammar M;\n" +
-        #                 "import S;\n" +
-        #                 "a : M ;\n" ;
-        #         writeFile(tmpdir, "M.g", master);
-        #         Tool antlr = newTool(new String[] {"-lib", tmpdir});
-        #         CompositeGrammar composite = new CompositeGrammar();
-        #         Grammar g = new Grammar(antlr,tmpdir+"/M.g",composite);
-        #         composite.setDelegationRoot(g);
-        #         g.parseAndBuildAST();
-        #         g.composite.assignTokenTypes();
-        #         g.composite.defineGrammarSymbols();
-
-        #         String expectedTokenIDToTypeMap = "[M=6, S=5, T=4]";
-        #         String expectedStringLiteralToTypeMap = "{}";
-        #         String expectedTypeToTokenList = "[T, S, M]";
-
-        #         assertEquals(expectedTokenIDToTypeMap,
-        #                                  realElements(g.composite.tokenIDToTypeMap).toString());
-        #         assertEquals(expectedStringLiteralToTypeMap, g.composite.stringLiteralToTypeMap.toString());
-        #         assertEquals(expectedTypeToTokenList,
-        #                                  realElements(g.composite.typeToTokenList).toString());
-
-        #         assertEquals("unexpected errors: "+equeue, 0, equeue.errors.size());
-
-        #         boolean ok =
-        #                 rawGenerateAndBuildRecognizer("M.g", master, "MParser", null, false);
-        #         boolean expecting = true; // should be ok
-        #         assertEquals(expecting, ok);
-        # }
-
-        # @Test public void testBigTreeOfImports() throws Exception {
-        #         ErrorQueue equeue = new ErrorQueue();
-        #         ErrorManager.setErrorListener(equeue);
-        #         String slave =
-        #                 "parser grammar T;\n" +
-        #                 "x : T ;\n" ;
-        #         mkdir(tmpdir);
-        #         writeFile(tmpdir, "T.g", slave);
-        #         slave =
-        #                 "parser grammar S;\n" +
-        #                 "import T;\n" +
-        #                 "y : S ;\n" ;
-        #         mkdir(tmpdir);
-        #         writeFile(tmpdir, "S.g", slave);
-
-        #         slave =
-        #                 "parser grammar C;\n" +
-        #                 "i : C ;\n" ;
-        #         mkdir(tmpdir);
-        #         writeFile(tmpdir, "C.g", slave);
-        #         slave =
-        #                 "parser grammar B;\n" +
-        #                 "j : B ;\n" ;
-        #         mkdir(tmpdir);
-        #         writeFile(tmpdir, "B.g", slave);
-        #         slave =
-        #                 "parser grammar A;\n" +
-        #                 "import B,C;\n" +
-        #                 "k : A ;\n" ;
-        #         mkdir(tmpdir);
-        #         writeFile(tmpdir, "A.g", slave);
-
-        #         String master =
-        #                 "grammar M;\n" +
-        #                 "import S,A;\n" +
-        #                 "a : M ;\n" ;
-        #         writeFile(tmpdir, "M.g", master);
-        #         Tool antlr = newTool(new String[] {"-lib", tmpdir});
-        #         CompositeGrammar composite = new CompositeGrammar();
-        #         Grammar g = new Grammar(antlr,tmpdir+"/M.g",composite);
-        #         composite.setDelegationRoot(g);
-        #         g.parseAndBuildAST();
-        #         g.composite.assignTokenTypes();
-        #         g.composite.defineGrammarSymbols();
-
-        #         String expectedTokenIDToTypeMap = "[A=8, B=6, C=7, M=9, S=5, T=4]";
-        #         String expectedStringLiteralToTypeMap = "{}";
-        #         String expectedTypeToTokenList = "[T, S, B, C, A, M]";
-
-        #         assertEquals(expectedTokenIDToTypeMap,
-        #                                  realElements(g.composite.tokenIDToTypeMap).toString());
-        #         assertEquals(expectedStringLiteralToTypeMap, g.composite.stringLiteralToTypeMap.toString());
-        #         assertEquals(expectedTypeToTokenList,
-        #                                  realElements(g.composite.typeToTokenList).toString());
-
-        #         assertEquals("unexpected errors: "+equeue, 0, equeue.errors.size());
-
-        #         boolean ok =
-        #                 rawGenerateAndBuildRecognizer("M.g", master, "MParser", null, false);
-        #         boolean expecting = true; // should be ok
-        #         assertEquals(expecting, ok);
-        # }
-
-        # @Test public void testRulesVisibleThroughMultilevelImport() throws Exception {
-        #         ErrorQueue equeue = new ErrorQueue();
-        #         ErrorManager.setErrorListener(equeue);
-        #         String slave =
-        #                 "parser grammar T;\n" +
-        #                 "x : T ;\n" ;
-        #         mkdir(tmpdir);
-        #         writeFile(tmpdir, "T.g", slave);
-        #         String slave2 =
-        #                 "parser grammar S;\n" + // A, B, C token type order
-        #                 "import T;\n" +
-        #                 "a : S ;\n" ;
-        #         mkdir(tmpdir);
-        #         writeFile(tmpdir, "S.g", slave2);
-
-        #         String master =
-        #                 "grammar M;\n" +
-        #                 "import S;\n" +
-        #                 "a : M x ;\n" ; // x MUST BE VISIBLE TO M
-        #         writeFile(tmpdir, "M.g", master);
-        #         Tool antlr = newTool(new String[] {"-lib", tmpdir});
-        #         CompositeGrammar composite = new CompositeGrammar();
-        #         Grammar g = new Grammar(antlr,tmpdir+"/M.g",composite);
-        #         composite.setDelegationRoot(g);
-        #         g.parseAndBuildAST();
-        #         g.composite.assignTokenTypes();
-        #         g.composite.defineGrammarSymbols();
-
-        #         String expectedTokenIDToTypeMap = "[M=6, S=5, T=4]";
-        #         String expectedStringLiteralToTypeMap = "{}";
-        #         String expectedTypeToTokenList = "[T, S, M]";
-
-        #         assertEquals(expectedTokenIDToTypeMap,
-        #                                  realElements(g.composite.tokenIDToTypeMap).toString());
-        #         assertEquals(expectedStringLiteralToTypeMap, g.composite.stringLiteralToTypeMap.toString());
-        #         assertEquals(expectedTypeToTokenList,
-        #                                  realElements(g.composite.typeToTokenList).toString());
-
-        #         assertEquals("unexpected errors: "+equeue, 0, equeue.errors.size());
-        # }
-
-        # @Test public void testNestedComposite() throws Exception {
-        #         // Wasn't compiling. http://www.antlr.org/jira/browse/ANTLR-438
-        #         ErrorQueue equeue = new ErrorQueue();
-        #         ErrorManager.setErrorListener(equeue);
-        #         String gstr =
-        #                 "lexer grammar L;\n" +
-        #                 "T1: '1';\n" +
-        #                 "T2: '2';\n" +
-        #                 "T3: '3';\n" +
-        #                 "T4: '4';\n" ;
-        #         mkdir(tmpdir);
-        #         writeFile(tmpdir, "L.g", gstr);
-        #         gstr =
-        #                 "parser grammar G1;\n" +
-        #                 "s: a | b;\n" +
-        #                 "a: T1;\n" +
-        #                 "b: T2;\n" ;
-        #         mkdir(tmpdir);
-        #         writeFile(tmpdir, "G1.g", gstr);
-
-        #         gstr =
-        #                 "parser grammar G2;\n" +
-        #                 "import G1;\n" +
-        #                 "a: T3;\n" ;
-        #         mkdir(tmpdir);
-        #         writeFile(tmpdir, "G2.g", gstr);
-        #         String G3str =
-        #                 "grammar G3;\n" +
-        #                 "import G2;\n" +
-        #                 "b: T4;\n" ;
-        #         mkdir(tmpdir);
-        #         writeFile(tmpdir, "G3.g", G3str);
-
-        #         Tool antlr = newTool(new String[] {"-lib", tmpdir});
-        #         CompositeGrammar composite = new CompositeGrammar();
-        #         Grammar g = new Grammar(antlr,tmpdir+"/G3.g",composite);
-        #         composite.setDelegationRoot(g);
-        #         g.parseAndBuildAST();
-        #         g.composite.assignTokenTypes();
-        #         g.composite.defineGrammarSymbols();
-
-        #         String expectedTokenIDToTypeMap = "[T1=4, T2=5, T3=6, T4=7]";
-        #         String expectedStringLiteralToTypeMap = "{}";
-        #         String expectedTypeToTokenList = "[T1, T2, T3, T4]";
-
-        #         assertEquals(expectedTokenIDToTypeMap,
-        #                                  realElements(g.composite.tokenIDToTypeMap).toString());
-        #         assertEquals(expectedStringLiteralToTypeMap, g.composite.stringLiteralToTypeMap.toString());
-        #         assertEquals(expectedTypeToTokenList,
-        #                                  realElements(g.composite.typeToTokenList).toString());
-
-        #         assertEquals("unexpected errors: "+equeue, 0, equeue.errors.size());
-
-        #         boolean ok =
-        #                 rawGenerateAndBuildRecognizer("G3.g", G3str, "G3Parser", null, false);
-        #         boolean expecting = true; // should be ok
-        #         assertEquals(expecting, ok);
-        # }
-
-        # @Test public void testHeadersPropogatedCorrectlyToImportedGrammars() throws Exception {
-        #         String slave =
-        #                 "parser grammar S;\n" +
-        #                 "a : B {System.out.print(\"S.a\");} ;\n";
-        #         mkdir(tmpdir);
-        #         writeFile(tmpdir, "S.g", slave);
-        #         String master =
-        #                 "grammar M;\n" +
-        #                 "import S;\n" +
-        #                 "@header{package mypackage;}\n" +
-        #                 "@lexer::header{package mypackage;}\n" +
-        #                 "s : a ;\n" +
-        #                 "B : 'b' ;" + // defines B from inherited token space
-        #                 "WS : (' '|'\\n') {skip();} ;\n" ;
-        #         boolean ok = antlr("M.g", "M.g", master, debug);
-        #         boolean expecting = true; // should be ok
-        #         assertEquals(expecting, ok);
-        # }
+        self.assertEqual("M.A a", found)


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t053hetero.py b/runtime/Python3/tests/t053hetero.py
index db3e9db..e85c038 100644
--- a/runtime/Python3/tests/t053hetero.py
+++ b/runtime/Python3/tests/t053hetero.py
@@ -9,7 +9,7 @@ class T(testbase.ANTLRTest):
def parserClass(self, base):
class TParser(base):
def __init__(self, *args, **kwargs):
-                base.__init__(self, *args, **kwargs)
+                super().__init__(*args, **kwargs)

self._output = ""

@@ -36,7 +36,7 @@ class T(testbase.ANTLRTest):
def lexerClass(self, base):
class TLexer(base):
def __init__(self, *args, **kwargs):
-                base.__init__(self, *args, **kwargs)
+                super().__init__(*args, **kwargs)

self._output = ""

@@ -69,7 +69,7 @@ class T(testbase.ANTLRTest):
parser = parserCls(tStream)
r = getattr(parser, grammarEntry)()

-        if r is not None:
+        if r:
return r.tree.toStringTree()

return ""
@@ -89,7 +89,7 @@ class T(testbase.ANTLRTest):
walker = walkerCls(nodes)
r = getattr(walker, treeEntry)()

-        if r is not None:
+        if r:
return r.tree.toStringTree()

return ""
@@ -102,7 +102,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T1;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
@header {
@@ -122,7 +122,7 @@ class T(testbase.ANTLRTest):
input="a"
)

-        self.failUnlessEqual("a<V>", found)
+        self.assertEqual("a<V>", found)


def testTokenCommonTree(self):
@@ -130,7 +130,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T;
options {
-                language=Python;
+                language=Python3;
output=AST;
}
a : ID<CommonTree> ;
@@ -142,7 +142,7 @@ class T(testbase.ANTLRTest):
grammar, 'a',
input="a")

-        self.failUnlessEqual("a", found)
+        self.assertEqual("a", found)


def testTokenWithQualifiedType(self):
@@ -150,7 +150,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T;
options {
-                language=Python;
+                language=Python3;
output=AST;
}
@members {
@@ -169,7 +169,7 @@ class T(testbase.ANTLRTest):
input="a"
)

-        self.failUnlessEqual("a<V>", found)
+        self.assertEqual("a<V>", found)


def testNamedType(self):
@@ -177,7 +177,7 @@ class T(testbase.ANTLRTest):
r"""
grammar $T;
options {
-                language=Python;
+                language=Python3;
output=AST;
}
@header {
@@ -192,7 +192,7 @@ class T(testbase.ANTLRTest):
""")

found = self.execParser(grammar, 'a', input="a")
-        self.assertEquals("a<V>", found)
+        self.assertEqual("a<V>", found)


def testTokenWithLabel(self):
@@ -200,7 +200,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T2;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
@header {
@@ -220,7 +220,7 @@ class T(testbase.ANTLRTest):
input="a"
)

-        self.failUnlessEqual("a<V>", found)
+        self.assertEqual("a<V>", found)


def testTokenWithListLabel(self):
@@ -228,7 +228,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T3;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
@header {
@@ -248,7 +248,7 @@ class T(testbase.ANTLRTest):
input="a"
)

-        self.failUnlessEqual("a<V>", found)
+        self.assertEqual("a<V>", found)


def testTokenRoot(self):
@@ -256,7 +256,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T4;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
@header {
@@ -276,7 +276,7 @@ class T(testbase.ANTLRTest):
input="a"
)

-        self.failUnlessEqual("a<V>", found)
+        self.assertEqual("a<V>", found)


def testTokenRootWithListLabel(self):
@@ -284,7 +284,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T5;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
@header {
@@ -304,7 +304,7 @@ class T(testbase.ANTLRTest):
input="a"
)

-        self.failUnlessEqual("a<V>", found)
+        self.assertEqual("a<V>", found)


def testString(self):
@@ -312,7 +312,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T6;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
@header {
@@ -332,7 +332,7 @@ class T(testbase.ANTLRTest):
input="begin"
)

-        self.failUnlessEqual("begin<V>", found)
+        self.assertEqual("begin<V>", found)


def testStringRoot(self):
@@ -340,7 +340,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T7;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
@header {
@@ -360,7 +360,7 @@ class T(testbase.ANTLRTest):
input="begin"
)

-        self.failUnlessEqual("begin<V>", found)
+        self.assertEqual("begin<V>", found)


# PARSERS -- REWRITE AST
@@ -370,7 +370,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T8;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
@header {
@@ -390,7 +390,7 @@ class T(testbase.ANTLRTest):
input="a"
)

-        self.failUnlessEqual("a<V>", found)
+        self.assertEqual("a<V>", found)


def testRewriteTokenWithArgs(self):
@@ -398,7 +398,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T9;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
@header {
@@ -418,18 +418,18 @@ class T(testbase.ANTLRTest):
y, z = 0, 0

else:
-                    raise TypeError("Invalid args \%r" \% (args,))
+                    raise TypeError("Invalid args {!r}".format(args))

-                CommonTree.__init__(self, token)
+                super().__init__(token)
self.x = x
self.y = y
self.z = z

def toString(self):
txt = ""
-                if self.token is not None:
+                if self.token:
txt += self.token.text
-                txt +="<V>;\%d\%d\%d" \% (self.x, self.y, self.z)
+                txt +="<V>;{0.x}{0.y}{0.z}".format(self)
return txt
__str__ = toString

@@ -444,7 +444,7 @@ class T(testbase.ANTLRTest):
input="a"
)

-        self.failUnlessEqual("<V>;421930 a<V>;9900", found)
+        self.assertEqual("<V>;421930 a<V>;9900", found)


def testRewriteTokenRoot(self):
@@ -452,7 +452,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T10;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
@header {
@@ -473,7 +473,7 @@ class T(testbase.ANTLRTest):
input="a 2"
)

-        self.failUnlessEqual("(a<V> 2)", found)
+        self.assertEqual("(a<V> 2)", found)


def testRewriteString(self):
@@ -481,7 +481,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T11;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
@header {
@@ -501,7 +501,7 @@ class T(testbase.ANTLRTest):
input="begin"
)

-        self.failUnlessEqual("begin<V>", found)
+        self.assertEqual("begin<V>", found)


def testRewriteStringRoot(self):
@@ -509,7 +509,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T12;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
@header {
@@ -530,14 +530,14 @@ class T(testbase.ANTLRTest):
input="begin 2"
)

-        self.failUnlessEqual("(begin<V> 2)", found)
+        self.assertEqual("(begin<V> 2)", found)

def testRewriteRuleResults(self):
grammar = textwrap.dedent(
r'''
grammar T;
options {
-                language=Python;
+                language=Python3;
output=AST;
}
tokens {LIST;}
@@ -549,7 +549,7 @@ class T(testbase.ANTLRTest):

class W(CommonTree):
def __init__(self, tokenType, txt):
-                    super(W, self).__init__(
+                    super().__init__(
CommonToken(type=tokenType, text=txt))

def toString(self):
@@ -567,14 +567,14 @@ class T(testbase.ANTLRTest):
grammar, 'a',
input="a,b,c")

-        self.failUnlessEqual("(LIST<W> a<V> b<V> c<V>)", found)
+        self.assertEqual("(LIST<W> a<V> b<V> c<V>)", found)

def testCopySemanticsWithHetero(self):
grammar = textwrap.dedent(
r'''
grammar T;
options {
-                language=Python;
+                language=Python3;
output=AST;
}
@header {
@@ -597,7 +597,7 @@ class T(testbase.ANTLRTest):
found = self.execParser(
grammar, 'a',
input="int a, b, c;")
-        self.failUnlessEqual("(int<V> a) (int<V> b) (int<V> c)", found)
+        self.assertEqual("(int<V> a) (int<V> b) (int<V> c)", found)

# TREE PARSERS -- REWRITE AST

@@ -606,7 +606,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T13;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
a : ID INT;
@@ -619,7 +619,7 @@ class T(testbase.ANTLRTest):
r'''
tree grammar TP13;
options {
-            language=Python;
+            language=Python3;
output=AST;
ASTLabelType=CommonTree;
tokenVocab=T13;
@@ -646,7 +646,7 @@ class T(testbase.ANTLRTest):
input="abc 34"
)

-        self.failUnlessEqual("34<V> abc<W>", found)
+        self.assertEqual("34<V> abc<W>", found)


def testTreeParserRewriteTree(self):
@@ -654,7 +654,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T14;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
a : ID INT;
@@ -667,7 +667,7 @@ class T(testbase.ANTLRTest):
r'''
tree grammar TP14;
options {
-            language=Python;
+            language=Python3;
output=AST;
ASTLabelType=CommonTree;
tokenVocab=T14;
@@ -694,7 +694,7 @@ class T(testbase.ANTLRTest):
input="abc 34"
)

-        self.failUnlessEqual("(34<V> abc<W>)", found)
+        self.assertEqual("(34<V> abc<W>)", found)


def testTreeParserRewriteImaginary(self):
@@ -702,7 +702,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T15;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
a : ID ;
@@ -715,7 +715,7 @@ class T(testbase.ANTLRTest):
r'''
tree grammar TP15;
options {
-            language=Python;
+            language=Python3;
output=AST;
ASTLabelType=CommonTree;
tokenVocab=T15;
@@ -724,7 +724,7 @@ class T(testbase.ANTLRTest):
@header {
class V(CommonTree):
def __init__(self, tokenType):
-                CommonTree.__init__(self, CommonToken(tokenType))
+                super().__init__(CommonToken(tokenType))

def toString(self):
return tokenNames[self.token.type] + "<V>"
@@ -742,7 +742,7 @@ class T(testbase.ANTLRTest):
input="abc"
)

-        self.failUnlessEqual("ROOT<V> abc", found)
+        self.assertEqual("ROOT<V> abc", found)


def testTreeParserRewriteImaginaryWithArgs(self):
@@ -750,7 +750,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T16;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
a : ID ;
@@ -763,7 +763,7 @@ class T(testbase.ANTLRTest):
r'''
tree grammar TP16;
options {
-            language=Python;
+            language=Python3;
output=AST;
ASTLabelType=CommonTree;
tokenVocab=T16;
@@ -772,7 +772,7 @@ class T(testbase.ANTLRTest):
@header {
class V(CommonTree):
def __init__(self, tokenType, x):
-                CommonTree.__init__(self, CommonToken(tokenType))
+                super().__init__(CommonToken(tokenType))
self.x = x

def toString(self):
@@ -790,7 +790,7 @@ class T(testbase.ANTLRTest):
input="abc"
)

-        self.failUnlessEqual("ROOT<V>;42 abc", found)
+        self.assertEqual("ROOT<V>;42 abc", found)


def testTreeParserRewriteImaginaryRoot(self):
@@ -798,7 +798,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T17;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
a : ID ;
@@ -811,7 +811,7 @@ class T(testbase.ANTLRTest):
r'''
tree grammar TP17;
options {
-            language=Python;
+            language=Python3;
output=AST;
ASTLabelType=CommonTree;
tokenVocab=T17;
@@ -820,7 +820,7 @@ class T(testbase.ANTLRTest):
@header {
class V(CommonTree):
def __init__(self, tokenType):
-                CommonTree.__init__(self, CommonToken(tokenType))
+                super().__init__(CommonToken(tokenType))

def toString(self):
return tokenNames[self.token.type] + "<V>"
@@ -837,7 +837,7 @@ class T(testbase.ANTLRTest):
input="abc"
)

-        self.failUnlessEqual("(ROOT<V> abc)", found)
+        self.assertEqual("(ROOT<V> abc)", found)


def testTreeParserRewriteImaginaryFromReal(self):
@@ -845,7 +845,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T18;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
a : ID ;
@@ -858,7 +858,7 @@ class T(testbase.ANTLRTest):
r'''
tree grammar TP18;
options {
-            language=Python;
+            language=Python3;
output=AST;
ASTLabelType=CommonTree;
tokenVocab=T18;
@@ -868,9 +868,9 @@ class T(testbase.ANTLRTest):
class V(CommonTree):
def __init__(self, tokenType, tree=None):
if tree is None:
-                    CommonTree.__init__(self, CommonToken(tokenType))
+                    super().__init__(CommonToken(tokenType))
else:
-                    CommonTree.__init__(self, tree)
+                    super().__init__(tree)
self.token.type = tokenType

def toString(self):
@@ -888,7 +888,7 @@ class T(testbase.ANTLRTest):
input="abc"
)

-        self.failUnlessEqual("ROOT<V>@1", found)
+        self.assertEqual("ROOT<V>@1", found)


def testTreeParserAutoHeteroAST(self):
@@ -896,7 +896,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T;
options {
-                language=Python;
+                language=Python3;
output=AST;
}
a : ID ';' ;
@@ -909,7 +909,7 @@ class T(testbase.ANTLRTest):
r'''
tree grammar TP;
options {
-                language=Python;
+                language=Python3;
output=AST;
ASTLabelType=CommonTree;
tokenVocab=T;
@@ -932,7 +932,7 @@ class T(testbase.ANTLRTest):
input="abc;"
)

-        self.failUnlessEqual("abc<V> ;<V>", found)
+        self.assertEqual("abc<V> ;<V>", found)


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t054main.py b/runtime/Python3/tests/t054main.py
index bb26510..5e2995f 100644
--- a/runtime/Python3/tests/t054main.py
+++ b/runtime/Python3/tests/t054main.py
@@ -1,4 +1,3 @@
-# -*- coding: utf-8 -*-

import unittest
import textwrap
@@ -6,7 +5,7 @@ import antlr3
import antlr3.tree
import testbase
import sys
-from StringIO import StringIO
+from io import StringIO

class T(testbase.ANTLRTest):
def setUp(self):
@@ -22,7 +21,7 @@ class T(testbase.ANTLRTest):
grammar = textwrap.dedent(
r"""lexer grammar T3;
options {
-              language = Python;
+              language = Python3;
}

@main {
@@ -38,13 +37,7 @@ class T(testbase.ANTLRTest):
stdout = StringIO()

lexerMod = self.compileInlineGrammar(grammar, returnModule=True)
-        try:
-            lexerMod.main(
-            ['lexer.py']
-            )
-            self.fail()
-        except RuntimeError:
-            pass
+        self.assertRaises(RuntimeError, lexerMod.main, ['lexer.py'])


def testLexerFromFile(self):
@@ -54,7 +47,7 @@ class T(testbase.ANTLRTest):
grammar = textwrap.dedent(
r"""lexer grammar T1;
options {
-              language = Python;
+              language = Python3;
}

ID: 'a'..'z'+;
@@ -70,7 +63,7 @@ class T(testbase.ANTLRTest):
stdout=stdout
)

-        self.failUnlessEqual(len(stdout.getvalue().splitlines()), 3)
+        self.assertEqual(len(stdout.getvalue().splitlines()), 3)


def testLexerFromStdIO(self):
@@ -79,7 +72,7 @@ class T(testbase.ANTLRTest):
grammar = textwrap.dedent(
r"""lexer grammar T2;
options {
-              language = Python;
+              language = Python3;
}

ID: 'a'..'z'+;
@@ -96,16 +89,16 @@ class T(testbase.ANTLRTest):
stdout=stdout
)

-        self.failUnlessEqual(len(stdout.getvalue().splitlines()), 3)
+        self.assertEqual(len(stdout.getvalue().splitlines()), 3)


def testLexerEncoding(self):
-        input = u"föö bär".encode('utf-8')
+        input = "föö bär"

grammar = textwrap.dedent(
r"""lexer grammar T3;
options {
-              language = Python;
+              language = Python3;
}

ID: ('a'..'z' | '\u00c0'..'\u00ff')+;
@@ -117,12 +110,12 @@ class T(testbase.ANTLRTest):

lexerMod = self.compileInlineGrammar(grammar, returnModule=True)
lexerMod.main(
-            ['lexer.py', '--encoding', 'utf-8'],
+            ['lexer.py'],
stdin=StringIO(input),
stdout=stdout
)

-        self.failUnlessEqual(len(stdout.getvalue().splitlines()), 3)
+        self.assertEqual(len(stdout.getvalue().splitlines()), 3)


def testCombined(self):
@@ -131,7 +124,7 @@ class T(testbase.ANTLRTest):
grammar = textwrap.dedent(
r"""grammar T4;
options {
-              language = Python;
+              language = Python3;
}

r returns [res]: (ID)+ EOF { $res = $text; };
@@ -151,7 +144,7 @@ class T(testbase.ANTLRTest):
)

stdout = stdout.getvalue()
-        self.failUnlessEqual(len(stdout.splitlines()), 1, stdout)
+        self.assertEqual(len(stdout.splitlines()), 1, stdout)


def testCombinedOutputAST(self):
@@ -160,7 +153,7 @@ class T(testbase.ANTLRTest):
grammar = textwrap.dedent(
r"""grammar T5;
options {
-              language = Python;
+              language = Python3;
output = AST;
}

@@ -182,14 +175,14 @@ class T(testbase.ANTLRTest):
)

stdout = stdout.getvalue().strip()
-        self.failUnlessEqual(stdout, "(+ foo bar)")
+        self.assertEqual(stdout, "(+ foo bar)")


def testTreeParser(self):
grammar = textwrap.dedent(
r'''grammar T6;
options {
-              language = Python;
+              language = Python3;
output = AST;
}

@@ -203,7 +196,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r'''tree grammar T6Walker;
options {
-            language=Python;
+            language=Python3;
ASTLabelType=CommonTree;
tokenVocab=T6;
}
@@ -223,14 +216,14 @@ class T(testbase.ANTLRTest):
)

stdout = stdout.getvalue().strip()
-        self.failUnlessEqual(stdout, "u'a + b'")
+        self.assertEqual(stdout, "'a + b'")


def testTreeParserRewrite(self):
grammar = textwrap.dedent(
r'''grammar T7;
options {
-              language = Python;
+              language = Python3;
output = AST;
}

@@ -244,7 +237,7 @@ class T(testbase.ANTLRTest):
treeGrammar = textwrap.dedent(
r'''tree grammar T7Walker;
options {
-              language=Python;
+              language=Python3;
ASTLabelType=CommonTree;
tokenVocab=T7;
output=AST;
@@ -266,7 +259,7 @@ class T(testbase.ANTLRTest):
)

stdout = stdout.getvalue().strip()
-        self.failUnlessEqual(stdout, "(+ (ARG a) (ARG b))")
+        self.assertEqual(stdout, "(+ (ARG a) (ARG b))")



@@ -275,7 +268,7 @@ class T(testbase.ANTLRTest):
r'''
parser grammar T8S;
options {
-              language=Python;
+              language=Python3;
}

a : B;
@@ -284,16 +277,14 @@ class T(testbase.ANTLRTest):
parserName = self.writeInlineGrammar(slave)[0]
# slave parsers are imported as normal python modules
# to force reloading current version, purge module from sys.modules
-        try:
+        if parserName + 'Parser' in sys.modules:
del sys.modules[parserName+'Parser']
-        except KeyError:
-            pass

master = textwrap.dedent(
r'''
grammar T8M;
options {
-              language=Python;
+              language=Python3;
}
import T8S;
s returns [res]: a { $res = $a.text };
@@ -311,7 +302,7 @@ class T(testbase.ANTLRTest):
)

stdout = stdout.getvalue().strip()
-        self.failUnlessEqual(stdout, "u'b'")
+        self.assertEqual(stdout, "'b'")


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t057autoAST.py b/runtime/Python3/tests/t057autoAST.py
index e5c1d35..1d35975 100644
--- a/runtime/Python3/tests/t057autoAST.py
+++ b/runtime/Python3/tests/t057autoAST.py
@@ -9,7 +9,7 @@ class TestAutoAST(testbase.ANTLRTest):
def parserClass(self, base):
class TParser(base):
def __init__(self, *args, **kwargs):
-                base.__init__(self, *args, **kwargs)
+                super().__init__(*args, **kwargs)

self._errors = []
self._output = ""
@@ -37,7 +37,7 @@ class TestAutoAST(testbase.ANTLRTest):
def lexerClass(self, base):
class TLexer(base):
def __init__(self, *args, **kwargs):
-                base.__init__(self, *args, **kwargs)
+                super().__init__(*args, **kwargs)

self._output = ""

@@ -71,15 +71,15 @@ class TestAutoAST(testbase.ANTLRTest):
r = getattr(parser, grammarEntry)()

if not expectErrors:
-            self.assertEquals(len(parser._errors), 0, parser._errors)
+            self.assertEqual(len(parser._errors), 0, parser._errors)

result = ""

-        if r is not None:
+        if r:
if hasattr(r, 'result'):
result += r.result

-            if r.tree is not None:
+            if r.tree:
result += r.tree.toStringTree()

if not expectErrors:
@@ -103,7 +103,7 @@ class TestAutoAST(testbase.ANTLRTest):
walker = walkerCls(nodes)
r = getattr(walker, treeEntry)()

-        if r is not None:
+        if r:
return r.tree.toStringTree()

return ""
@@ -113,382 +113,382 @@ class TestAutoAST(testbase.ANTLRTest):
grammar = textwrap.dedent(
r'''
grammar foo;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID INT ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;};
+            WS : (' '|'\n') {$channel=HIDDEN};
''')

found = self.execParser(grammar, "a", "abc 34")
-        self.assertEquals("abc 34", found);
+        self.assertEqual("abc 34", found);


def testTokenListInSingleAltBlock(self):
grammar = textwrap.dedent(
r'''
grammar foo;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : (ID INT) ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar,"a", "abc 34")
-        self.assertEquals("abc 34", found)
+        self.assertEqual("abc 34", found)


def testSimpleRootAtOuterLevel(self):
grammar = textwrap.dedent(
r'''
grammar foo;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID^ INT ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "abc 34")
-        self.assertEquals("(abc 34)", found)
+        self.assertEqual("(abc 34)", found)


def testSimpleRootAtOuterLevelReverse(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : INT ID^ ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "34 abc")
-        self.assertEquals("(abc 34)", found)
+        self.assertEqual("(abc 34)", found)


def testBang(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID INT! ID! INT ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "abc 34 dag 4532")
-        self.assertEquals("abc 4532", found)
+        self.assertEqual("abc 4532", found)


def testOptionalThenRoot(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ( ID INT )? ID^ ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a 1 b")
-        self.assertEquals("(b a 1)", found)
+        self.assertEqual("(b a 1)", found)


def testLabeledStringRoot(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : v='void'^ ID ';' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "void foo;")
-        self.assertEquals("(void foo ;)", found)
+        self.assertEqual("(void foo ;)", found)


def testWildcard(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : v='void'^ . ';' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "void foo;")
-        self.assertEquals("(void foo ;)", found)
+        self.assertEqual("(void foo ;)", found)


def testWildcardRoot(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : v='void' .^ ';' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "void foo;")
-        self.assertEquals("(foo void ;)", found)
+        self.assertEqual("(foo void ;)", found)


def testWildcardRootWithLabel(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : v='void' x=.^ ';' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "void foo;")
-        self.assertEquals("(foo void ;)", found)
+        self.assertEqual("(foo void ;)", found)


def testWildcardRootWithListLabel(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : v='void' x=.^ ';' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "void foo;")
-        self.assertEquals("(foo void ;)", found)
+        self.assertEqual("(foo void ;)", found)


def testWildcardBangWithListLabel(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : v='void' x=.! ';' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "void foo;")
-        self.assertEquals("void ;", found)
+        self.assertEqual("void ;", found)


def testRootRoot(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID^ INT^ ID ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a 34 c")
-        self.assertEquals("(34 a c)", found)
+        self.assertEqual("(34 a c)", found)


def testRootRoot2(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID INT^ ID^ ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a 34 c")
-        self.assertEquals("(c (34 a))", found)
+        self.assertEqual("(c (34 a))", found)


def testRootThenRootInLoop(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID^ (INT '*'^ ID)+ ;
ID  : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a 34 * b 9 * c")
-        self.assertEquals("(* (* (a 34) b 9) c)", found)
+        self.assertEqual("(* (* (a 34) b 9) c)", found)


def testNestedSubrule(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : 'void' (({pass}ID|INT) ID | 'null' ) ';' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "void a b;")
-        self.assertEquals("void a b ;", found)
+        self.assertEqual("void a b ;", found)


def testInvokeRule(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a  : type ID ;
type : {pass}'int' | 'float' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "int a")
-        self.assertEquals("int a", found)
+        self.assertEqual("int a", found)


def testInvokeRuleAsRoot(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a  : type^ ID ;
type : {pass}'int' | 'float' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "int a")
-        self.assertEquals("(int a)", found)
+        self.assertEqual("(int a)", found)


def testInvokeRuleAsRootWithLabel(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a  : x=type^ ID ;
type : {pass}'int' | 'float' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "int a")
-        self.assertEquals("(int a)", found)
+        self.assertEqual("(int a)", found)


def testInvokeRuleAsRootWithListLabel(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a  : x+=type^ ID ;
type : {pass}'int' | 'float' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "int a")
-        self.assertEquals("(int a)", found)
+        self.assertEqual("(int a)", found)


def testRuleRootInLoop(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID ('+'^ ID)* ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a+b+c+d")
-        self.assertEquals("(+ (+ (+ a b) c) d)", found)
+        self.assertEqual("(+ (+ (+ a b) c) d)", found)


def testRuleInvocationRuleRootInLoop(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID (op^ ID)* ;
op : {pass}'+' | '-' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a+b+c-d")
-        self.assertEquals("(- (+ (+ a b) c) d)", found)
+        self.assertEqual("(- (+ (+ a b) c) d)", found)


def testTailRecursion(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
s : a ;
a : atom ('exp'^ a)? ;
atom : INT ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "s", "3 exp 4 exp 5")
-        self.assertEquals("(exp 3 (exp 4 5))", found)
+        self.assertEqual("(exp 3 (exp 4 5))", found)


def testSet(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID|INT ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "abc")
-        self.assertEquals("abc", found)
+        self.assertEqual("abc", found)


def testSetRoot(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ('+' | '-')^ ID ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "+abc")
-        self.assertEquals("(+ abc)", found)
+        self.assertEqual("(+ abc)", found)


@testbase.broken(
@@ -497,136 +497,136 @@ class TestAutoAST(testbase.ANTLRTest):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : x=('+' | '-')^ ID ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "+abc")
-        self.assertEquals("(+ abc)", found)
+        self.assertEqual("(+ abc)", found)


def testSetAsRuleRootInLoop(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID (('+'|'-')^ ID)* ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a+b-c")
-        self.assertEquals("(- (+ a b) c)", found)
+        self.assertEqual("(- (+ a b) c)", found)


def testNotSet(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ~ID '+' INT ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "34+2")
-        self.assertEquals("34 + 2", found)
+        self.assertEqual("34 + 2", found)


def testNotSetWithLabel(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : x=~ID '+' INT ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "34+2")
-        self.assertEquals("34 + 2", found)
+        self.assertEqual("34 + 2", found)


def testNotSetWithListLabel(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : x=~ID '+' INT ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "34+2")
-        self.assertEquals("34 + 2", found)
+        self.assertEqual("34 + 2", found)


def testNotSetRoot(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ~'+'^ INT ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "34 55")
-        self.assertEquals("(34 55)", found)
+        self.assertEqual("(34 55)", found)


def testNotSetRootWithLabel(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ~'+'^ INT ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "34 55")
-        self.assertEquals("(34 55)", found)
+        self.assertEqual("(34 55)", found)


def testNotSetRootWithListLabel(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ~'+'^ INT ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "34 55")
-        self.assertEquals("(34 55)", found)
+        self.assertEqual("(34 55)", found)


def testNotSetRuleRootInLoop(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : INT (~INT^ INT)* ;
blort : '+' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "3+4+5")
-        self.assertEquals("(+ (+ 3 4) 5)", found)
+        self.assertEqual("(+ (+ 3 4) 5)", found)


@testbase.broken("FIXME: What happened to the semicolon?", AssertionError)
@@ -635,15 +635,15 @@ class TestAutoAST(testbase.ANTLRTest):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
-            a returns [result] : id=ID id=ID {$result = "2nd id="+$id.text+";";} ;
+            options {language=Python3;output=AST;}
+            a returns [result] : id=ID id=ID {$result = "2nd id="+$id.text+";"} ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a b")
-        self.assertEquals("2nd id=b;a b", found)
+        self.assertEqual("2nd id=b;a b", found)


def testTokenLabelReuse2(self):
@@ -651,15 +651,15 @@ class TestAutoAST(testbase.ANTLRTest):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
-            a returns [result]: id=ID id=ID^ {$result = "2nd id="+$id.text+',';} ;
+            options {language=Python3;output=AST;}
+            a returns [result]: id=ID id=ID^ {$result = "2nd id="+$id.text+','} ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a b")
-        self.assertEquals("2nd id=b,(b a)", found)
+        self.assertEqual("2nd id=b,(b a)", found)


def testTokenListLabelReuse(self):
@@ -668,16 +668,16 @@ class TestAutoAST(testbase.ANTLRTest):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
-            a returns [result] : ids+=ID ids+=ID {$result = "id list=["+",".join([t.text for t in $ids])+'],';} ;
+            options {language=Python3;output=AST;}
+            a returns [result] : ids+=ID ids+=ID {$result = "id list=[{}],".format(",".join([t.text for t in $ids]))} ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a b")
expecting = "id list=[a,b],a b"
-        self.assertEquals(expecting, found)
+        self.assertEqual(expecting, found)


def testTokenListLabelReuse2(self):
@@ -686,53 +686,53 @@ class TestAutoAST(testbase.ANTLRTest):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
-            a returns [result] : ids+=ID^ ids+=ID {$result = "id list=["+",".join([t.text for t in $ids])+'],';} ;
+            options {language=Python3;output=AST;}
+            a returns [result] : ids+=ID^ ids+=ID {$result = "id list=[{}],".format(",".join([t.text for t in $ids]))} ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a b")
expecting = "id list=[a,b],(a b)"
-        self.assertEquals(expecting, found)
+        self.assertEqual(expecting, found)


def testTokenListLabelRuleRoot(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : id+=ID^ ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a")
-        self.assertEquals("a", found)
+        self.assertEqual("a", found)


def testTokenListLabelBang(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : id+=ID! ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a")
-        self.assertEquals("", found)
+        self.assertEqual("", found)


def testRuleListLabel(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a returns [result]: x+=b x+=b {
t=$x[1]
$result = "2nd x="+t.toStringTree()+',';
@@ -740,47 +740,47 @@ class TestAutoAST(testbase.ANTLRTest):
b : ID;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a b")
-        self.assertEquals("2nd x=b,a b", found)
+        self.assertEqual("2nd x=b,a b", found)


def testRuleListLabelRuleRoot(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a returns [result] : ( x+=b^ )+ {
$result = "x="+$x[1].toStringTree()+',';
} ;
b : ID;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a b")
-        self.assertEquals("x=(b a),(b a)", found)
+        self.assertEqual("x=(b a),(b a)", found)


def testRuleListLabelBang(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a returns [result] : x+=b! x+=b {
$result = "1st x="+$x[0].toStringTree()+',';
} ;
b : ID;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a b")
-        self.assertEquals("1st x=a,b", found)
+        self.assertEqual("1st x=a,b", found)


def testComplicatedMelange(self):
@@ -788,187 +788,187 @@ class TestAutoAST(testbase.ANTLRTest):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : A b=B b=B c+=C c+=C D {s = $D.text} ;
A : 'a' ;
B : 'b' ;
C : 'c' ;
D : 'd' ;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a b b c c d")
-        self.assertEquals("a b b c c d", found)
+        self.assertEqual("a b b c c d", found)


def testReturnValueWithAST(self):
grammar = textwrap.dedent(
r'''
grammar foo;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a returns [result] : ID b { $result = str($b.i) + '\n';} ;
b returns [i] : INT {$i=int($INT.text);} ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "abc 34")
-        self.assertEquals("34\nabc 34", found)
+        self.assertEqual("34\nabc 34", found)


def testSetLoop(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options { language=Python;output=AST; }
+            options { language=Python3;output=AST; }
r : (INT|ID)+ ;
ID : 'a'..'z' + ;
INT : '0'..'9' +;
-            WS: (' ' | '\n' | '\\t')+ {$channel = HIDDEN;};
+            WS: (' ' | '\n' | '\\t')+ {$channel = HIDDEN};
''')

found = self.execParser(grammar, "r", "abc 34 d")
-        self.assertEquals("abc 34 d", found)
+        self.assertEqual("abc 34 d", found)


def testExtraTokenInSimpleDecl(self):
grammar = textwrap.dedent(
r'''
grammar foo;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
decl : type^ ID '='! INT ';'! ;
type : 'int' | 'float' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found, errors = self.execParser(grammar, "decl", "int 34 x=1;",
expectErrors=True)
-        self.assertEquals(["line 1:4 extraneous input u'34' expecting ID"],
-                          errors)
-        self.assertEquals("(int x 1)", found) # tree gets correct x and 1 tokens
+        self.assertEqual(["line 1:4 extraneous input '34' expecting ID"],
+                         errors)
+        self.assertEqual("(int x 1)", found) # tree gets correct x and 1 tokens


def testMissingIDInSimpleDecl(self):
grammar = textwrap.dedent(
r'''
grammar foo;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {EXPR;}
decl : type^ ID '='! INT ';'! ;
type : 'int' | 'float' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found, errors = self.execParser(grammar, "decl", "int =1;",
expectErrors=True)
-        self.assertEquals(["line 1:4 missing ID at u'='"], errors)
-        self.assertEquals("(int <missing ID> 1)", found) # tree gets invented ID token
+        self.assertEqual(["line 1:4 missing ID at '='"], errors)
+        self.assertEqual("(int <missing ID> 1)", found) # tree gets invented ID token


def testMissingSetInSimpleDecl(self):
grammar = textwrap.dedent(
r'''
grammar foo;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {EXPR;}
decl : type^ ID '='! INT ';'! ;
type : 'int' | 'float' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found, errors = self.execParser(grammar, "decl", "x=1;",
expectErrors=True)
-        self.assertEquals(["line 1:0 mismatched input u'x' expecting set None"], errors)
-        self.assertEquals("(<error: x> x 1)", found) # tree gets invented ID token
+        self.assertEqual(["line 1:0 mismatched input 'x' expecting set None"], errors)
+        self.assertEqual("(<error: x> x 1)", found) # tree gets invented ID token


def testMissingTokenGivesErrorNode(self):
grammar = textwrap.dedent(
r'''
grammar foo;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID INT ; // follow is EOF
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found, errors = self.execParser(grammar, "a", "abc", expectErrors=True)
-        self.assertEquals(["line 1:3 missing INT at '<EOF>'"], errors)
-        self.assertEquals("abc <missing INT>", found)
+        self.assertEqual(["line 1:3 missing INT at '<EOF>'"], errors)
+        self.assertEqual("abc <missing INT>", found)


def testMissingTokenGivesErrorNodeInInvokedRule(self):
grammar = textwrap.dedent(
r'''
grammar foo;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : b ;
b : ID INT ; // follow should see EOF
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found, errors = self.execParser(grammar, "a", "abc", expectErrors=True)
-        self.assertEquals(["line 1:3 mismatched input '<EOF>' expecting INT"], errors)
-        self.assertEquals("<mismatched token: <EOF>, resync=abc>", found)
+        self.assertEqual(["line 1:3 mismatched input '<EOF>' expecting INT"], errors)
+        self.assertEqual("<mismatched token: <EOF>, resync=abc>", found)


def testExtraTokenGivesErrorNode(self):
grammar = textwrap.dedent(
r'''
grammar foo;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : b c ;
b : ID ;
c : INT ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found, errors = self.execParser(grammar, "a", "abc ick 34",
expectErrors=True)
-        self.assertEquals(["line 1:4 extraneous input u'ick' expecting INT"],
+        self.assertEqual(["line 1:4 extraneous input 'ick' expecting INT"],
errors)
-        self.assertEquals("abc 34", found)
+        self.assertEqual("abc 34", found)


def testMissingFirstTokenGivesErrorNode(self):
grammar = textwrap.dedent(
r'''
grammar foo;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID INT ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found, errors = self.execParser(grammar, "a", "34", expectErrors=True)
-        self.assertEquals(["line 1:0 missing ID at u'34'"], errors)
-        self.assertEquals("<missing ID> 34", found)
+        self.assertEqual(["line 1:0 missing ID at '34'"], errors)
+        self.assertEqual("<missing ID> 34", found)


def testMissingFirstTokenGivesErrorNode2(self):
grammar = textwrap.dedent(
r'''
grammar foo;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : b c ;
b : ID ;
c : INT ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found, errors = self.execParser(grammar, "a", "34", expectErrors=True)
@@ -976,29 +976,29 @@ class TestAutoAST(testbase.ANTLRTest):
# finds an error at the first token, 34, and re-syncs.
# re-synchronizing does not consume a token because 34 follows
# ref to rule b (start of c). It then matches 34 in c.
-        self.assertEquals(["line 1:0 missing ID at u'34'"], errors)
-        self.assertEquals("<missing ID> 34", found)
+        self.assertEqual(["line 1:0 missing ID at '34'"], errors)
+        self.assertEqual("<missing ID> 34", found)


def testNoViableAltGivesErrorNode(self):
grammar = textwrap.dedent(
r'''
grammar foo;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : b | c ;
b : ID ;
c : INT ;
ID : 'a'..'z'+ ;
S : '*' ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found, errors = self.execParser(grammar, "a", "*", expectErrors=True)
-        self.assertEquals(["line 1:0 no viable alternative at input u'*'"],
-                          errors)
-        self.assertEquals("<unexpected: [@0,0:0=u'*',<6>,1:0], resync=*>",
-                          found)
+        self.assertEqual(["line 1:0 no viable alternative at input '*'"],
+                         errors)
+        self.assertEqual("<unexpected: [@0,0:0='*',<6>,1:0], resync=*>",
+                         found)


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t058rewriteAST.py b/runtime/Python3/tests/t058rewriteAST.py
index 15036f4..a8f007a 100644
--- a/runtime/Python3/tests/t058rewriteAST.py
+++ b/runtime/Python3/tests/t058rewriteAST.py
@@ -9,7 +9,7 @@ class TestRewriteAST(testbase.ANTLRTest):
def parserClass(self, base):
class TParser(base):
def __init__(self, *args, **kwargs):
-                base.__init__(self, *args, **kwargs)
+                super().__init__(*args, **kwargs)

self._errors = []
self._output = ""
@@ -37,7 +37,7 @@ class TestRewriteAST(testbase.ANTLRTest):
def lexerClass(self, base):
class TLexer(base):
def __init__(self, *args, **kwargs):
-                base.__init__(self, *args, **kwargs)
+                super().__init__(*args, **kwargs)

self._output = ""

@@ -71,15 +71,15 @@ class TestRewriteAST(testbase.ANTLRTest):
r = getattr(parser, grammarEntry)()

if not expectErrors:
-            self.assertEquals(len(parser._errors), 0, parser._errors)
+            self.assertEqual(len(parser._errors), 0, parser._errors)

result = ""

-        if r is not None:
+        if r:
if hasattr(r, 'result'):
result += r.result

-            if r.tree is not None:
+            if r.tree:
result += r.tree.toStringTree()

if not expectErrors:
@@ -103,7 +103,7 @@ class TestRewriteAST(testbase.ANTLRTest):
walker = walkerCls(nodes)
r = getattr(walker, treeEntry)()

-        if r is not None:
+        if r:
return r.tree.toStringTree()

return ""
@@ -113,60 +113,60 @@ class TestRewriteAST(testbase.ANTLRTest):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID INT -> ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "abc 34")
-        self.assertEquals("", found)
+        self.assertEqual("", found)


def testSingleToken(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID -> ID;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "abc")
-        self.assertEquals("abc", found)
+        self.assertEqual("abc", found)


def testSingleTokenToNewNode(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID -> ID["x"];
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "abc")
-        self.assertEquals("x", found)
+        self.assertEqual("x", found)


def testSingleTokenToNewNodeRoot(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID -> ^(ID["x"] INT);
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "abc")
-        self.assertEquals("(x INT)", found)
+        self.assertEqual("(x INT)", found)


def testSingleTokenToNewNode2(self):
@@ -174,122 +174,122 @@ class TestRewriteAST(testbase.ANTLRTest):
grammar = textwrap.dedent(
r'''
grammar TT;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID -> ID[ ];
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "abc")
-        self.assertEquals("ID", found)
+        self.assertEqual("ID", found)


def testSingleCharLiteral(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : 'c' -> 'c';
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "c")
-        self.assertEquals("c", found)
+        self.assertEqual("c", found)


def testSingleStringLiteral(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : 'ick' -> 'ick';
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "ick")
-        self.assertEquals("ick", found)
+        self.assertEqual("ick", found)


def testSingleRule(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : b -> b;
b : ID ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "abc")
-        self.assertEquals("abc", found)
+        self.assertEqual("abc", found)


def testReorderTokens(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID INT -> INT ID;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "abc 34")
-        self.assertEquals("34 abc", found)
+        self.assertEqual("34 abc", found)


def testReorderTokenAndRule(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : b INT -> INT b;
b : ID ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "abc 34")
-        self.assertEquals("34 abc", found)
+        self.assertEqual("34 abc", found)


def testTokenTree(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID INT -> ^(INT ID);
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "abc 34")
-        self.assertEquals("(34 abc)", found)
+        self.assertEqual("(34 abc)", found)


def testTokenTreeAfterOtherStuff(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : 'void' ID INT -> 'void' ^(INT ID);
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "void abc 34")
-        self.assertEquals("void (34 abc)", found)
+        self.assertEqual("void (34 abc)", found)


def testNestedTokenTreeWithOuterLoop(self):
@@ -297,238 +297,238 @@ class TestRewriteAST(testbase.ANTLRTest):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {DUH;}
a : ID INT ID INT -> ^( DUH ID ^( DUH INT) )+ ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a 1 b 2")
-        self.assertEquals("(DUH a (DUH 1)) (DUH b (DUH 2))", found)
+        self.assertEqual("(DUH a (DUH 1)) (DUH b (DUH 2))", found)


def testOptionalSingleToken(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID -> ID? ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "abc")
-        self.assertEquals("abc", found)
+        self.assertEqual("abc", found)


def testClosureSingleToken(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID ID -> ID* ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a b")
-        self.assertEquals("a b", found)
+        self.assertEqual("a b", found)


def testPositiveClosureSingleToken(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID ID -> ID+ ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a b")
-        self.assertEquals("a b", found)
+        self.assertEqual("a b", found)


def testOptionalSingleRule(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : b -> b?;
b : ID ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "abc")
-        self.assertEquals("abc", found)
+        self.assertEqual("abc", found)


def testClosureSingleRule(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : b b -> b*;
b : ID ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a b")
-        self.assertEquals("a b", found)
+        self.assertEqual("a b", found)


def testClosureOfLabel(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : x+=b x+=b -> $x*;
b : ID ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a b")
-        self.assertEquals("a b", found)
+        self.assertEqual("a b", found)


def testOptionalLabelNoListLabel(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : (x=ID)? -> $x?;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a")
-        self.assertEquals("a", found)
+        self.assertEqual("a", found)


def testPositiveClosureSingleRule(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : b b -> b+;
b : ID ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a b")
-        self.assertEquals("a b", found)
+        self.assertEqual("a b", found)


def testSinglePredicateT(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID -> {True}? ID -> ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "abc")
-        self.assertEquals("abc", found)
+        self.assertEqual("abc", found)


def testSinglePredicateF(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID -> {False}? ID -> ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "abc")
-        self.assertEquals("", found)
+        self.assertEqual("", found)


def testMultiplePredicate(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID INT -> {False}? ID
-> {True}? INT
->
;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a 2")
-        self.assertEquals("2", found)
+        self.assertEqual("2", found)


def testMultiplePredicateTrees(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID INT -> {False}? ^(ID INT)
-> {True}? ^(INT ID)
-> ID
;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a 2")
-        self.assertEquals("(2 a)", found)
+        self.assertEqual("(2 a)", found)


def testSimpleTree(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : op INT -> ^(op INT);
op : '+'|'-' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "-34")
-        self.assertEquals("(- 34)", found)
+        self.assertEqual("(- 34)", found)


def testSimpleTree2(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : op INT -> ^(INT op);
op : '+'|'-' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "+ 34")
-        self.assertEquals("(34 +)", found)
+        self.assertEqual("(34 +)", found)



@@ -536,108 +536,108 @@ class TestRewriteAST(testbase.ANTLRTest):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : 'var' (ID ':' type ';')+ -> ^('var' ^(':' ID type)+) ;
type : 'int' | 'float' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "var a:int; b:float;")
-        self.assertEquals("(var (: a int) (: b float))", found)
+        self.assertEqual("(var (: a int) (: b float))", found)


def testImaginaryTokenCopy(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {VAR;}
a : ID (',' ID)*-> ^(VAR ID)+ ;
type : 'int' | 'float' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a,b,c")
-        self.assertEquals("(VAR a) (VAR b) (VAR c)", found)
+        self.assertEqual("(VAR a) (VAR b) (VAR c)", found)


def testTokenUnreferencedOnLeftButDefined(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {VAR;}
a : b -> ID ;
b : ID ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a")
-        self.assertEquals("ID", found)
+        self.assertEqual("ID", found)


def testImaginaryTokenCopySetText(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {VAR;}
a : ID (',' ID)*-> ^(VAR["var"] ID)+ ;
type : 'int' | 'float' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a,b,c")
-        self.assertEquals("(var a) (var b) (var c)", found)
+        self.assertEqual("(var a) (var b) (var c)", found)


def testImaginaryTokenNoCopyFromToken(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {BLOCK;}
a : lc='{' ID+ '}' -> ^(BLOCK[$lc] ID+) ;
type : 'int' | 'float' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "{a b c}")
-        self.assertEquals("({ a b c)", found)
+        self.assertEqual("({ a b c)", found)


def testImaginaryTokenNoCopyFromTokenSetText(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {BLOCK;}
a : lc='{' ID+ '}' -> ^(BLOCK[$lc,"block"] ID+) ;
type : 'int' | 'float' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "{a b c}")
-        self.assertEquals("(block a b c)", found)
+        self.assertEqual("(block a b c)", found)


def testMixedRewriteAndAutoAST(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {BLOCK;}
a : b b^ ; // 2nd b matches only an INT; can make it root
b : ID INT -> INT ID
@@ -645,36 +645,36 @@ class TestRewriteAST(testbase.ANTLRTest):
;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a 1 2")
-        self.assertEquals("(2 1 a)", found)
+        self.assertEqual("(2 1 a)", found)


def testSubruleWithRewrite(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {BLOCK;}
a : b b ;
b : (ID INT -> INT ID | INT INT -> INT+ )
;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a 1 2 3")
-        self.assertEquals("1 a 2 3", found)
+        self.assertEqual("1 a 2 3", found)


def testSubruleWithRewrite2(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {TYPE;}
a : b b ;
b : 'int'
@@ -685,18 +685,18 @@ class TestRewriteAST(testbase.ANTLRTest):
;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "int a; int b=3;")
-        self.assertEquals("(TYPE int a) (TYPE int b 3)", found)
+        self.assertEqual("(TYPE int a) (TYPE int b 3)", found)


def testNestedRewriteShutsOffAutoAST(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {BLOCK;}
a : b b ;
b : ID ( ID (last=ID -> $last)+ ) ';' // get last ID
@@ -704,77 +704,77 @@ class TestRewriteAST(testbase.ANTLRTest):
;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a b c d; 42")
-        self.assertEquals("d 42", found)
+        self.assertEqual("d 42", found)


def testRewriteActions(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : atom -> ^({self.adaptor.create(INT,"9")} atom) ;
atom : INT ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "3")
-        self.assertEquals("(9 3)", found)
+        self.assertEqual("(9 3)", found)


def testRewriteActions2(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : atom -> {self.adaptor.create(INT,"9")} atom ;
atom : INT ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "3")
-        self.assertEquals("9 3", found)
+        self.assertEqual("9 3", found)


def testRefToOldValue(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {BLOCK;}
a : (atom -> atom) (op='+' r=atom -> ^($op $a $r) )* ;
atom : INT ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "3+4+5")
-        self.assertEquals("(+ (+ 3 4) 5)", found)
+        self.assertEqual("(+ (+ 3 4) 5)", found)


def testCopySemanticsForRules(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {BLOCK;}
a : atom -> ^(atom atom) ; // NOT CYCLE! (dup atom)
atom : INT ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "3")
-        self.assertEquals("(3 3)", found)
+        self.assertEqual("(3 3)", found)


def testCopySemanticsForRules2(self):
@@ -782,15 +782,15 @@ class TestRewriteAST(testbase.ANTLRTest):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : type ID (',' ID)* ';' -> ^(type ID)+ ;
type : 'int' ;
ID : 'a'..'z'+ ;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "int a,b,c;")
-        self.assertEquals("(int a) (int b) (int c)", found)
+        self.assertEqual("(int a) (int b) (int c)", found)


def testCopySemanticsForRules3(self):
@@ -799,16 +799,16 @@ class TestRewriteAST(testbase.ANTLRTest):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : modifier? type ID (',' ID)* ';' -> ^(type modifier? ID)+ ;
type : 'int' ;
modifier : 'public' ;
ID : 'a'..'z'+ ;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "public int a,b,c;")
-        self.assertEquals("(int public a) (int public b) (int public c)", found)
+        self.assertEqual("(int public a) (int public b) (int public c)", found)


def testCopySemanticsForRules3Double(self):
@@ -817,16 +817,16 @@ class TestRewriteAST(testbase.ANTLRTest):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : modifier? type ID (',' ID)* ';' -> ^(type modifier? ID)+ ^(type modifier? ID)+ ;
type : 'int' ;
modifier : 'public' ;
ID : 'a'..'z'+ ;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "public int a,b,c;")
-        self.assertEquals("(int public a) (int public b) (int public c) (int public a) (int public b) (int public c)", found)
+        self.assertEqual("(int public a) (int public b) (int public c) (int public a) (int public b) (int public c)", found)


def testCopySemanticsForRules4(self):
@@ -835,112 +835,112 @@ class TestRewriteAST(testbase.ANTLRTest):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {MOD;}
a : modifier? type ID (',' ID)* ';' -> ^(type ^(MOD modifier)? ID)+ ;
type : 'int' ;
modifier : 'public' ;
ID : 'a'..'z'+ ;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "public int a,b,c;")
-        self.assertEquals("(int (MOD public) a) (int (MOD public) b) (int (MOD public) c)", found)
+        self.assertEqual("(int (MOD public) a) (int (MOD public) b) (int (MOD public) c)", found)


def testCopySemanticsLists(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {MOD;}
a : ID (',' ID)* ';' -> ID+ ID+ ;
ID : 'a'..'z'+ ;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a,b,c;")
-        self.assertEquals("a b c a b c", found)
+        self.assertEqual("a b c a b c", found)


def testCopyRuleLabel(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {BLOCK;}
a : x=b -> $x $x;
b : ID ;
ID : 'a'..'z'+ ;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a")
-        self.assertEquals("a a", found)
+        self.assertEqual("a a", found)


def testCopyRuleLabel2(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {BLOCK;}
a : x=b -> ^($x $x);
b : ID ;
ID : 'a'..'z'+ ;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a")
-        self.assertEquals("(a a)", found)
+        self.assertEqual("(a a)", found)


def testQueueingOfTokens(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : 'int' ID (',' ID)* ';' -> ^('int' ID+) ;
op : '+'|'-' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "int a,b,c;")
-        self.assertEquals("(int a b c)", found)
+        self.assertEqual("(int a b c)", found)


def testCopyOfTokens(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : 'int' ID ';' -> 'int' ID 'int' ID ;
op : '+'|'-' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "int a;")
-        self.assertEquals("int a int a", found)
+        self.assertEqual("int a int a", found)


def testTokenCopyInLoop(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : 'int' ID (',' ID)* ';' -> ^('int' ID)+ ;
op : '+'|'-' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "int a,b,c;")
-        self.assertEquals("(int a) (int b) (int c)", found)
+        self.assertEqual("(int a) (int b) (int c)", found)


def testTokenCopyInLoopAgainstTwoOthers(self):
@@ -948,56 +948,56 @@ class TestRewriteAST(testbase.ANTLRTest):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : 'int' ID ':' INT (',' ID ':' INT)* ';' -> ^('int' ID INT)+ ;
op : '+'|'-' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "int a:1,b:2,c:3;")
-        self.assertEquals("(int a 1) (int b 2) (int c 3)", found)
+        self.assertEqual("(int a 1) (int b 2) (int c 3)", found)


def testListRefdOneAtATime(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID+ -> ID ID ID ; // works if 3 input IDs
op : '+'|'-' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a b c")
-        self.assertEquals("a b c", found)
+        self.assertEqual("a b c", found)


def testSplitListWithLabels(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {VAR;}
a : first=ID others+=ID* -> $first VAR $others+ ;
op : '+'|'-' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a b c")
-        self.assertEquals("a VAR b c", found)
+        self.assertEqual("a VAR b c", found)


def testComplicatedMelange(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {BLOCK;}
a : A A b=B B b=B c+=C C c+=C D {s=$D.text} -> A+ B+ C+ D ;
type : 'int' | 'float' ;
@@ -1005,201 +1005,201 @@ class TestRewriteAST(testbase.ANTLRTest):
B : 'b' ;
C : 'c' ;
D : 'd' ;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a a b b b c c c d")
-        self.assertEquals("a a b b b c c c d", found)
+        self.assertEqual("a a b b b c c c d", found)


def testRuleLabel(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {BLOCK;}
a : x=b -> $x;
b : ID ;
ID : 'a'..'z'+ ;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a")
-        self.assertEquals("a", found)
+        self.assertEqual("a", found)


def testAmbiguousRule(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID a -> a | INT ;
ID : 'a'..'z'+ ;
INT: '0'..'9'+ ;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar,
"a", "abc 34")
-        self.assertEquals("34", found)
+        self.assertEqual("34", found)


def testRuleListLabel(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {BLOCK;}
a : x+=b x+=b -> $x+;
b : ID ;
ID : 'a'..'z'+ ;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a b")
-        self.assertEquals("a b", found)
+        self.assertEqual("a b", found)


def testRuleListLabel2(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {BLOCK;}
a : x+=b x+=b -> $x $x*;
b : ID ;
ID : 'a'..'z'+ ;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a b")
-        self.assertEquals("a b", found)
+        self.assertEqual("a b", found)


def testOptional(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {BLOCK;}
a : x=b (y=b)? -> $x $y?;
b : ID ;
ID : 'a'..'z'+ ;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a")
-        self.assertEquals("a", found)
+        self.assertEqual("a", found)


def testOptional2(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {BLOCK;}
a : x=ID (y=b)? -> $x $y?;
b : ID ;
ID : 'a'..'z'+ ;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a b")
-        self.assertEquals("a b", found)
+        self.assertEqual("a b", found)


def testOptional3(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {BLOCK;}
a : x=ID (y=b)? -> ($x $y)?;
b : ID ;
ID : 'a'..'z'+ ;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a b")
-        self.assertEquals("a b", found)
+        self.assertEqual("a b", found)


def testOptional4(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {BLOCK;}
a : x+=ID (y=b)? -> ($x $y)?;
b : ID ;
ID : 'a'..'z'+ ;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a b")
-        self.assertEquals("a b", found)
+        self.assertEqual("a b", found)


def testOptional5(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {BLOCK;}
a : ID -> ID? ; // match an ID to optional ID
b : ID ;
ID : 'a'..'z'+ ;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a")
-        self.assertEquals("a", found)
+        self.assertEqual("a", found)


def testArbitraryExprType(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {BLOCK;}
a : x+=b x+=b -> {CommonTree(None)};
b : ID ;
ID : 'a'..'z'+ ;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "a b")
-        self.assertEquals("", found)
+        self.assertEqual("", found)


def testSet(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a: (INT|ID)+ -> INT+ ID+ ;
INT: '0'..'9'+;
ID : 'a'..'z'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "2 a 34 de")
-        self.assertEquals("2 34 a de", found)
+        self.assertEqual("2 34 a de", found)


def testSet2(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a: (INT|ID) -> INT? ID? ;
INT: '0'..'9'+;
ID : 'a'..'z'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "2")
-        self.assertEquals("2", found)
+        self.assertEqual("2", found)


@testbase.broken("http://www.antlr.org:8888/browse/ANTLR-162",
@@ -1208,32 +1208,32 @@ class TestRewriteAST(testbase.ANTLRTest):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : x=(INT|ID) -> $x ;
INT: '0'..'9'+;
ID : 'a'..'z'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "2")
-        self.assertEquals("2", found)
+        self.assertEqual("2", found)


def testRewriteAction(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens { FLOAT; }
r
: INT -> {CommonTree(CommonToken(type=FLOAT, text=$INT.text+".0"))}
;
INT : '0'..'9'+;
-            WS: (' ' | '\n' | '\t')+ {$channel = HIDDEN;};
+            WS: (' ' | '\n' | '\t')+ {$channel = HIDDEN};
''')

found = self.execParser(grammar, "r", "25")
-        self.assertEquals("25.0", found)
+        self.assertEqual("25.0", found)


def testOptionalSubruleWithoutRealElements(self):
@@ -1242,7 +1242,7 @@ class TestRewriteAST(testbase.ANTLRTest):
grammar = textwrap.dedent(
r"""
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {PARMS;}

modulo
@@ -1250,11 +1250,11 @@ class TestRewriteAST(testbase.ANTLRTest):
;
parms : '#'|ID;
ID : ('a'..'z' | 'A'..'Z')+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
""")

found = self.execParser(grammar, "modulo", "modulo abc (x y #)")
-        self.assertEquals("(modulo abc (PARMS x y #))", found)
+        self.assertEqual("(modulo abc (PARMS x y #))", found)


## C A R D I N A L I T Y  I S S U E S
@@ -1263,91 +1263,79 @@ class TestRewriteAST(testbase.ANTLRTest):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {BLOCK;}
a : ID ID INT INT INT -> (ID INT)+;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

-        try:
-            self.execParser(grammar, "a", "a b 3 4 5")
-            self.fail()
-        except antlr3.tree.RewriteCardinalityException:
-            pass
+        self.assertRaises(antlr3.tree.RewriteCardinalityException,
+                          self.execParser, grammar, "a", "a b 3 4 5")


def testCardinality2(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID+ -> ID ID ID ; // only 2 input IDs
op : '+'|'-' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

-        try:
-            self.execParser(grammar, "a", "a b")
-            self.fail()
-        except antlr3.tree.RewriteCardinalityException:
-            pass
+        self.assertRaises(antlr3.tree.RewriteCardinalityException,
+                          self.execParser, grammar, "a", "a b")


def testCardinality3(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID? INT -> ID INT ;
op : '+'|'-' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

-        try:
-            self.execParser(grammar, "a", "3")
-            self.fail()
-        except antlr3.tree.RewriteEmptyStreamException:
-            pass
+        self.assertRaises(antlr3.tree.RewriteEmptyStreamException,
+                          self.execParser, grammar, "a", "3")


def testLoopCardinality(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID? INT -> ID+ INT ;
op : '+'|'-' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

-        try:
-            self.execParser(grammar, "a", "3")
-            self.fail()
-        except antlr3.tree.RewriteEarlyExitException:
-            pass
+        self.assertRaises(antlr3.tree.RewriteEarlyExitException,
+                          self.execParser, grammar, "a", "3")


def testWildcard(self):
grammar = textwrap.dedent(
r'''
grammar T;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID c=. -> $c;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found = self.execParser(grammar, "a", "abc 34")
-        self.assertEquals("34", found)
+        self.assertEqual("34", found)


# E R R O R S
@@ -1356,20 +1344,20 @@ class TestRewriteAST(testbase.ANTLRTest):
grammar = textwrap.dedent(
r'''
grammar foo;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {EXPR;}
decl : type ID '=' INT ';' -> ^(EXPR type ID INT) ;
type : 'int' | 'float' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found, errors = self.execParser(grammar, "decl", "int 34 x=1;",
expectErrors=True)
-        self.assertEquals(["line 1:4 extraneous input u'34' expecting ID"],
-                          errors)
-        self.assertEquals("(EXPR int x 1)", found) # tree gets correct x and 1 tokens
+        self.assertEqual(["line 1:4 extraneous input '34' expecting ID"],
+                         errors)
+        self.assertEqual("(EXPR int x 1)", found) # tree gets correct x and 1 tokens


#@testbase.broken("FIXME", AssertionError)
@@ -1377,77 +1365,77 @@ class TestRewriteAST(testbase.ANTLRTest):
grammar = textwrap.dedent(
r'''
grammar foo;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {EXPR;}
decl : type ID '=' INT ';' -> ^(EXPR type ID INT) ;
type : 'int' | 'float' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found, errors = self.execParser(grammar, "decl", "int =1;",
expectErrors=True)
-        self.assertEquals(["line 1:4 missing ID at u'='"], errors)
-        self.assertEquals("(EXPR int <missing ID> 1)", found) # tree gets invented ID token
+        self.assertEqual(["line 1:4 missing ID at '='"], errors)
+        self.assertEqual("(EXPR int <missing ID> 1)", found) # tree gets invented ID token


def testMissingSetInSimpleDecl(self):
grammar = textwrap.dedent(
r'''
grammar foo;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
tokens {EXPR;}
decl : type ID '=' INT ';' -> ^(EXPR type ID INT) ;
type : 'int' | 'float' ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found, errors = self.execParser(grammar, "decl", "x=1;",
expectErrors=True)
-        self.assertEquals(["line 1:0 mismatched input u'x' expecting set None"],
-                          errors);
-        self.assertEquals("(EXPR <error: x> x 1)", found) # tree gets invented ID token
+        self.assertEqual(["line 1:0 mismatched input 'x' expecting set None"],
+                         errors);
+        self.assertEqual("(EXPR <error: x> x 1)", found) # tree gets invented ID token


def testMissingTokenGivesErrorNode(self):
grammar = textwrap.dedent(
r'''
grammar foo;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID INT -> ID INT ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found, errors = self.execParser(grammar, "a", "abc",
expectErrors=True)
-        self.assertEquals(["line 1:3 missing INT at '<EOF>'"], errors)
+        self.assertEqual(["line 1:3 missing INT at '<EOF>'"], errors)
# doesn't do in-line recovery for sets (yet?)
-        self.assertEquals("abc <missing INT>", found)
+        self.assertEqual("abc <missing INT>", found)


def testExtraTokenGivesErrorNode(self):
grammar = textwrap.dedent(
r'''
grammar foo;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : b c -> b c;
b : ID -> ID ;
c : INT -> INT ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found, errors = self.execParser(grammar, "a", "abc ick 34",
expectErrors=True)
-        self.assertEquals(["line 1:4 extraneous input u'ick' expecting INT"],
-                          errors)
-        self.assertEquals("abc 34", found)
+        self.assertEqual(["line 1:4 extraneous input 'ick' expecting INT"],
+                         errors)
+        self.assertEqual("abc 34", found)


#@testbase.broken("FIXME", AssertionError)
@@ -1455,16 +1443,16 @@ class TestRewriteAST(testbase.ANTLRTest):
grammar = textwrap.dedent(
r'''
grammar foo;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : ID INT -> ID INT ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found, errors = self.execParser(grammar, "a", "34", expectErrors=True)
-        self.assertEquals(["line 1:0 missing ID at u'34'"], errors)
-        self.assertEquals("<missing ID> 34", found)
+        self.assertEqual(["line 1:0 missing ID at '34'"], errors)
+        self.assertEqual("<missing ID> 34", found)


#@testbase.broken("FIXME", AssertionError)
@@ -1472,45 +1460,45 @@ class TestRewriteAST(testbase.ANTLRTest):
grammar = textwrap.dedent(
r'''
grammar foo;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : b c -> b c;
b : ID -> ID ;
c : INT -> INT ;
ID : 'a'..'z'+ ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found, errors = self.execParser(grammar, "a", "34", expectErrors=True)
# finds an error at the first token, 34, and re-syncs.
# re-synchronizing does not consume a token because 34 follows
# ref to rule b (start of c). It then matches 34 in c.
-        self.assertEquals(["line 1:0 missing ID at u'34'"], errors)
-        self.assertEquals("<missing ID> 34", found)
+        self.assertEqual(["line 1:0 missing ID at '34'"], errors)
+        self.assertEqual("<missing ID> 34", found)


def testNoViableAltGivesErrorNode(self):
grammar = textwrap.dedent(
r'''
grammar foo;
-            options {language=Python;output=AST;}
+            options {language=Python3;output=AST;}
a : b -> b | c -> c;
b : ID -> ID ;
c : INT -> INT ;
ID : 'a'..'z'+ ;
S : '*' ;
INT : '0'..'9'+;
-            WS : (' '|'\n') {$channel=HIDDEN;} ;
+            WS : (' '|'\n') {$channel=HIDDEN} ;
''')

found, errors = self.execParser(grammar, "a", "*", expectErrors=True)
# finds an error at the first token, 34, and re-syncs.
# re-synchronizing does not consume a token because 34 follows
# ref to rule b (start of c). It then matches 34 in c.
-        self.assertEquals(["line 1:0 no viable alternative at input u'*'"],
-                          errors);
-        self.assertEquals("<unexpected: [@0,0:0=u'*',<6>,1:0], resync=*>",
-                          found)
+        self.assertEqual(["line 1:0 no viable alternative at input '*'"],
+                         errors);
+        self.assertEqual("<unexpected: [@0,0:0='*',<6>,1:0], resync=*>",
+                         found)


if __name__ == '__main__':
diff --git a/runtime/Python3/tests/t059debug.py b/runtime/Python3/tests/t059debug.py
index 1b620d1..2214d18 100644
--- a/runtime/Python3/tests/t059debug.py
+++ b/runtime/Python3/tests/t059debug.py
@@ -12,7 +12,7 @@ import time

class Debugger(threading.Thread):
def __init__(self, port):
-        super(Debugger, self).__init__()
+        super().__init__()
self.events = []
self.success = False
self.port = port
@@ -26,7 +26,9 @@ class Debugger(threading.Thread):
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
s.connect(('127.0.0.1', self.port))
break
-            except socket.error, exc:
+            except socket.error as exc:
+                if s:
+                    s.close()
if exc.args[0] != errno.ECONNREFUSED:
raise
time.sleep(0.1)
@@ -38,15 +40,15 @@ class Debugger(threading.Thread):
s.setblocking(1)
s.settimeout(10.0)

-        output = s.makefile('w', 0)
-        input = s.makefile('r', 0)
+        output = s.makefile('wb', 0)
+        input = s.makefile('rb', 0)

try:
# handshake
l = input.readline().strip()
-            assert l == 'ANTLR 2'
+            self.assertEqual(l, 'ANTLR 2')
l = input.readline().strip()
-            assert l.startswith('grammar "')
+            self.assertTrue(l.startswith('grammar "'))

output.write('ACK\n')
output.flush()
@@ -64,10 +66,10 @@ class Debugger(threading.Thread):

except socket.timeout:
self.events.append(['timeout'])
-        except socket.error, exc:
+        except socket.error as exc:
self.events.append(['socketerror', exc.args])
-
-        s.close()
+        finally:
+            s.close()


class T(testbase.ANTLRTest):
@@ -102,11 +104,11 @@ class T(testbase.ANTLRTest):
r'''
grammar T;
options {
-            language=Python;
+            language=Python3;
}
a : ID EOF;
ID : 'a'..'z'+ ;
-        WS : (' '|'\n') {$channel=HIDDEN;} ;
+        WS : (' '|'\n') {$channel=HIDDEN} ;
''')

listener = antlr3.debug.RecordDebugEventListener()
@@ -139,11 +141,11 @@ class T(testbase.ANTLRTest):
r'''
grammar T;
options {
-            language=Python;
+            language=Python3;
}
a : ID EOF;
ID : 'a'..'z'+ ;
-        WS : (' '|'\n') {$channel=HIDDEN;} ;
+        WS : (' '|'\n') {$channel=HIDDEN} ;
''')

debugger = self.execParser(
@@ -174,11 +176,11 @@ class T(testbase.ANTLRTest):
r'''
grammar T;
options {
-            language=Python;
+            language=Python3;
}
a : ID EOF;
ID : 'a'..'z'+ ;
-        WS : (' '|'\n') {$channel=HIDDEN;} ;
+        WS : (' '|'\n') {$channel=HIDDEN} ;
''')

debugger = self.execParser(
@@ -219,11 +221,11 @@ class T(testbase.ANTLRTest):
r'''
grammar T;
options {
-            language=Python;
+            language=Python3;
}
a : {True}? ID EOF;
ID : 'a'..'z'+ ;
-        WS : (' '|'\n') {$channel=HIDDEN;} ;
+        WS : (' '|'\n') {$channel=HIDDEN} ;
''')

debugger = self.execParser(
@@ -257,12 +259,12 @@ class T(testbase.ANTLRTest):
r'''
grammar T;
options {
-            language=Python;
+            language=Python3;
}
a : ID ( ID | INT )+ EOF;
ID : 'a'..'z'+ ;
INT : '0'..'9'+ ;
-        WS : (' '|'\n') {$channel=HIDDEN;} ;
+        WS : (' '|'\n') {$channel=HIDDEN} ;
''')

debugger = self.execParser(
@@ -332,12 +334,12 @@ class T(testbase.ANTLRTest):
r'''
grammar T;
options {
-            language=Python;
+            language=Python3;
}
a : ID ( ID | INT )* EOF;
ID : 'a'..'z'+ ;
INT : '0'..'9'+ ;
-        WS : (' '|'\n') {$channel=HIDDEN;} ;
+        WS : (' '|'\n') {$channel=HIDDEN} ;
''')

debugger = self.execParser(
@@ -407,12 +409,12 @@ class T(testbase.ANTLRTest):
r'''
grammar T;
options {
-            language=Python;
+            language=Python3;
}
a : ID ( ID | INT ) EOF;
ID : 'a'..'z'+ ;
INT : '0'..'9'+ ;
-        WS : (' '|'\n') {$channel=HIDDEN;} ;
+        WS : (' '|'\n') {$channel=HIDDEN} ;
''')

debugger = self.execParser(
@@ -449,14 +451,14 @@ class T(testbase.ANTLRTest):
r'''
grammar T;
options {
-            language=Python;
+            language=Python3;
}
a : ID ( b | c ) EOF;
b : ID;
c : INT;
ID : 'a'..'z'+ ;
INT : '0'..'9'+ ;
-        WS : (' '|'\n') {$channel=HIDDEN;} ;
+        WS : (' '|'\n') {$channel=HIDDEN} ;
''')

debugger = self.execParser(
@@ -506,7 +508,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T;
options {
-            language=Python;
+            language=Python3;
}
a : ID ( b | c ) EOF;
b : ID;
@@ -514,7 +516,7 @@ class T(testbase.ANTLRTest):
ID : 'a'..'z'+ ;
INT : '0'..'9'+ ;
BANG : '!' ;
-        WS : (' '|'\n') {$channel=HIDDEN;} ;
+        WS : (' '|'\n') {$channel=HIDDEN} ;
''')

debugger = self.execParser(
@@ -558,14 +560,14 @@ class T(testbase.ANTLRTest):
r'''
grammar T;
options {
-            language=Python;
+            language=Python3;
}
a : b | c;
b : ID;
c : INT;
ID : 'a'..'z'+ ;
INT : '0'..'9'+ ;
-        WS : (' '|'\n') {$channel=HIDDEN;} ;
+        WS : (' '|'\n') {$channel=HIDDEN} ;
''')

debugger = self.execParser(
@@ -602,13 +604,13 @@ class T(testbase.ANTLRTest):
r'''
grammar T;
options {
-            language=Python;
+            language=Python3;
}
a : b;
b : ID;
ID : 'a'..'z'+ ;
INT : '0'..'9'+ ;
-        WS : (' '|'\n') {$channel=HIDDEN;} ;
+        WS : (' '|'\n') {$channel=HIDDEN} ;
''')

debugger = self.execParser(
@@ -642,13 +644,13 @@ class T(testbase.ANTLRTest):
r'''
grammar T;
options {
-            language=Python;
+            language=Python3;
}
a : ( b );
b : ID;
ID : 'a'..'z'+ ;
INT : '0'..'9'+ ;
-        WS : (' '|'\n') {$channel=HIDDEN;} ;
+        WS : (' '|'\n') {$channel=HIDDEN} ;
''')

debugger = self.execParser(
@@ -684,7 +686,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T;
options {
-            language=Python;
+            language=Python3;
}
a : ( b | c ) EOF;
b : ID* INT;
@@ -692,7 +694,7 @@ class T(testbase.ANTLRTest):
ID : 'a'..'z'+ ;
INT : '0'..'9'+ ;
BANG : '!';
-        WS : (' '|'\n') {$channel=HIDDEN;} ;
+        WS : (' '|'\n') {$channel=HIDDEN} ;
''')

debugger = self.execParser(
@@ -756,7 +758,7 @@ class T(testbase.ANTLRTest):
r'''
grammar T;
options {
-            language=Python;
+            language=Python3;
output=AST;
}
a : ( b | c ) EOF!;
@@ -765,7 +767,7 @@ class T(testbase.ANTLRTest):
ID : 'a'..'z'+ ;
INT : '0'..'9'+ ;
BANG : '!';
-        WS : (' '|'\n') {$channel=HIDDEN;} ;
+        WS : (' '|'\n') {$channel=HIDDEN} ;
''')

listener = antlr3.debug.RecordDebugEventListener()
diff --git a/runtime/Python3/tests/t060leftrecursion.py b/runtime/Python3/tests/t060leftrecursion.py
index 0c064b6..05b5bc0 100644
--- a/runtime/Python3/tests/t060leftrecursion.py
+++ b/runtime/Python3/tests/t060leftrecursion.py
@@ -11,7 +11,7 @@ import testbase
#     def parserClass(self, base):
#         class TParser(base):
#             def __init__(self, *args, **kwargs):
-#                 base.__init__(self, *args, **kwargs)
+#                 super().__init__(*args, **kwargs)

#                 self._output = ""

@@ -53,9 +53,9 @@ import testbase
#             if build_ast:
#               found += r.tree.toStringTree()

-#             self.assertEquals(
+#             self.assertEqual(
#                 expecting, found,
-#                 "%r != %r (for input %r)" % (expecting, found, input))
+#                 "{!r} != {!r} (for input {!r})".format(expecting, found, input))


#     def testSimple(self):
@@ -63,7 +63,7 @@ import testbase
#             r"""
#             grammar T;
#             options {
-#                 language=Python;
+#                 language=Python3;
#             }
#             s : a { self.capture($a.text) } ;
#             a : a ID
@@ -75,7 +75,7 @@ import testbase

#         found = self.execParser(grammar, 's', 'a b c')
#         expecting = "abc"
-#         self.assertEquals(expecting, found)
+#         self.assertEqual(expecting, found)


#     def testSemPred(self):
@@ -83,7 +83,7 @@ import testbase
#             r"""
#             grammar T;
#             options {
-#                 language=Python;
+#                 language=Python3;
#             }
#             s : a { self.capture($a.text) } ;
#             a : a {True}? ID
@@ -95,14 +95,14 @@ import testbase

#         found = self.execParser(grammar, "s", "a b c")
#         expecting = "abc"
-#         self.assertEquals(expecting, found)
+#         self.assertEqual(expecting, found)

#     def testTernaryExpr(self):
#         grammar = textwrap.dedent(
#             r"""
#             grammar T;
#             options {
-#                 language=Python;
+#                 language=Python3;
#                 output=AST;
#             }
#             e : e '*'^ e
@@ -134,7 +134,7 @@ import testbase
#             r"""
#             grammar T;
#             options {
-#                 language=Python;
+#                 language=Python3;
#                 output=AST;
#             }
#             declarator
@@ -171,7 +171,7 @@ import testbase
#             r"""
#             grammar T;
#             options {
-#                 language=Python;
+#                 language=Python3;
#                 output=AST;
#             }
#             declarator
@@ -208,7 +208,7 @@ import testbase
#             r"""
#             grammar T;
#             options {
-#                 language=Python;
+#                 language=Python3;
#                 output=AST;
#             }
#             e : e '.'^ ID
@@ -248,7 +248,7 @@ import testbase
#             r"""
#             grammar T;
#             options {
-#                 language=Python;
+#                 language=Python3;
#                 output=AST;
#             }
#             e : e '.' ID                   -> ^('.' e ID)
@@ -285,7 +285,7 @@ import testbase
#             r"""
#             grammar T;
#             options {
-#                 language=Python;
+#                 language=Python3;
#                 output=AST;
#             }
#             e
@@ -327,7 +327,7 @@ import testbase
#             r"""
#             grammar T;
#             options {
-#                 language=Python;
+#                 language=Python3;
#                 output=AST;
#             }
#             expressionList
@@ -420,7 +420,7 @@ import testbase
#             r"""
#             grammar T;
#             options {
-#                 language=Python;
+#                 language=Python3;
#             }
#             s : e { self.capture($e.v) } ;
#             e returns [v, ignored]
@@ -444,10 +444,10 @@ import testbase
#             r"""
#             grammar T;
#             options {
-#                 language=Python;
+#                 language=Python3;
#                 output=AST;
#             }
-#             s : e { self.capture("v=\%s, " \% $e.v) } ;
+#             s : e { self.capture("v={}, ".format($e.v)) } ;
#             e returns [v, ignored]
#               : e '*'^ b=e {$v *= $b.v;}
#               | e '+'^ b=e {$v += $b.v;}
diff --git a/runtime/Python3/tests/testbase.py b/runtime/Python3/tests/testbase.py
index 19c7fec..b2a9223 100644
--- a/runtime/Python3/tests/testbase.py
+++ b/runtime/Python3/tests/testbase.py
@@ -1,21 +1,22 @@
-import unittest
-import imp
-import os
+from distutils.errors import *
import errno
-import sys
import glob
+import hashlib
+import imp
+import inspect
+import os
import re
-import tempfile
import shutil
-import inspect
-import hashlib
-from distutils.errors import *
+import sys
+import tempfile
+import unittest
+
import antlr3

def unlink(path):
try:
os.unlink(path)
-    except OSError, exc:
+    except OSError as exc:
if exc.errno != errno.ENOENT:
raise

@@ -35,7 +36,7 @@ testbasedir = os.path.join(
class BrokenTest(unittest.TestCase.failureException):
def __repr__(self):
name, reason = self.args
-        return '%s: %s: %s works now' % (
+        return '{}: {}: {} works now'.format(
(self.__class__.__name__, name, reason))


@@ -67,27 +68,24 @@ if 'CLASSPATH' not in os.environ:
baseDir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', '..'))
libDir = os.path.join(baseDir, 'lib')

-    jar = os.path.join(libDir, 'ST-4.0.1.jar')
+    jar = os.path.join(libDir, 'ST-4.0.5.jar')
if not os.path.isfile(jar):
raise DistutilsFileError(
-            "Missing file '%s'. Grap it from a distribution package."
-            % jar,
+            "Missing file '{}'. Grab it from a distribution package.".format(jar)
)
cp.append(jar)

-    jar = os.path.join(libDir, 'antlr-2.7.7.jar')
+    jar = os.path.join(libDir, 'antlr-3.4.1-SNAPSHOT.jar')
if not os.path.isfile(jar):
raise DistutilsFileError(
-            "Missing file '%s'. Grap it from a distribution package."
-            % jar,
+            "Missing file '{}'. Grab it from a distribution package.".format(jar)
)
cp.append(jar)

-    jar = os.path.join(libDir, 'junit-4.2.jar')
+    jar = os.path.join(libDir, 'antlr-runtime-3.4.jar')
if not os.path.isfile(jar):
raise DistutilsFileError(
-            "Missing file '%s'. Grap it from a distribution package."
-            % jar,
+            "Missing file '{}'. Grab it from a distribution package.".format(jar)
)
cp.append(jar)

@@ -101,7 +99,7 @@ else:

class ANTLRTest(unittest.TestCase):
def __init__(self, *args, **kwargs):
-        unittest.TestCase.__init__(self, *args, **kwargs)
+        super().__init__(*args, **kwargs)

self.moduleName = os.path.splitext(os.path.basename(sys.modules[self.__module__].__file__))[0]
self.className = self.__class__.__name__
@@ -114,17 +112,6 @@ class ANTLRTest(unittest.TestCase):
self.grammarType = None


-    def assertListEqual(self, a, b):
-        if a == b:
-            return
-
-        import difflib
-        a = [str(l) + '\n' for l in a]
-        b = [str(l) + '\n' for l in b]
-
-        raise AssertionError(''.join(difflib.unified_diff(a, b)))
-
-
@property
def baseDir(self):
if self._baseDir is None:
@@ -157,7 +144,7 @@ class ANTLRTest(unittest.TestCase):


def _invokeantlr(self, dir, file, options, javaOptions=''):
-        cmd = 'cd %s; java %s %s org.antlr.Tool -o . %s %s 2>&1' % (
+        cmd = 'cd {}; java {} {} org.antlr.Tool -o . {} {} 2>&1'.format(
dir, javaOptions, classpath, options, file
)
fp = os.popen(cmd)
@@ -170,13 +157,12 @@ class ANTLRTest(unittest.TestCase):
failed = True

rc = fp.close()
-        if rc is not None:
+        if rc:
failed = True

if failed:
raise GrammarCompileError(
-                "Failed to compile grammar '%s':\n%s\n\n" % (file, cmd)
-                + output
+                "Failed to compile grammar '{}':\n{}\n\n{}".format(file, cmd, output)
)


@@ -196,15 +182,13 @@ class ANTLRTest(unittest.TestCase):
grammarPath = os.path.join(os.path.dirname(os.path.abspath(__file__)), grammarName)

# get type and name from first grammar line
-        grammar = open(grammarPath, 'r').read()
+        with open(grammarPath, 'r') as fp:
+            grammar = fp.read()
m = re.match(r'\s*((lexer|parser|tree)\s+|)grammar\s+(\S+);', grammar, re.MULTILINE)
-        assert m is not None, grammar
-        self.grammarType = m.group(2)
-        if self.grammarType is None:
-            self.grammarType = 'combined'
+        self.assertIsNotNone(m, grammar)
+        self.grammarType = m.group(2) or 'combined'

-        if self.grammarType is None:
-            assert self.grammarType in ('lexer', 'parser', 'tree', 'combined'), self.grammarType
+        self.assertIn(self.grammarType, ('lexer', 'parser', 'tree', 'combined'))

# don't try to rebuild grammar, if it already failed
if grammarName in compileErrorCache:
@@ -242,11 +226,8 @@ class ANTLRTest(unittest.TestCase):

#         if failed:
#             raise GrammarCompileError(
-        #                 "antlr -depend failed with code %s on grammar '%s':\n\n"
-        #                 % (rc, grammarName)
-        #                 + cmd
-        #                 + "\n"
-        #                 + output
+        #                 "antlr -depend failed with code {} on grammar '{}':\n\n{}\n{}".format(
+        #                     rc, grammarName, cmd, output)
#                 )

#         # add dependencies to my .stg files
@@ -300,12 +281,10 @@ class ANTLRTest(unittest.TestCase):


def __load_module(self, name):
-        modFile, modPathname, modDescription \
-                 = imp.find_module(name, [self.baseDir])
+        modFile, modPathname, modDescription = imp.find_module(name, [self.baseDir])

-        return imp.load_module(
-            name, modFile, modPathname, modDescription
-            )
+        with modFile:
+            return imp.load_module(name, modFile, modPathname, modDescription)


def getLexer(self, *args, **kwargs):
@@ -358,26 +337,23 @@ class ANTLRTest(unittest.TestCase):
# to avoid class name reuse. This kinda sucks. Need to find a way so
# tests can use the same grammar name without messing up the namespace.
# Well, first I should figure out what the exact problem is...
-        id = hashlib.md5(self.baseDir).hexdigest()[-8:]
+        id = hashlib.md5(self.baseDir.encode('utf-8')).hexdigest()[-8:]
grammar = grammar.replace('$TP', 'TP' + id)
grammar = grammar.replace('$T', 'T' + id)

# get type and name from first grammar line
m = re.match(r'\s*((lexer|parser|tree)\s+|)grammar\s+(\S+);', grammar, re.MULTILINE)
-        assert m is not None, grammar
-        grammarType = m.group(2)
-        if grammarType is None:
-            grammarType = 'combined'
+        self.assertIsNotNone(m, grammar)
+        grammarType = m.group(2) or 'combined'
grammarName = m.group(3)

-        assert grammarType in ('lexer', 'parser', 'tree', 'combined'), grammarType
+        self.assertIn(grammarType, ('lexer', 'parser', 'tree', 'combined'))

grammarPath = os.path.join(self.baseDir, grammarName + '.g')

# dump temp grammar file
-        fp = open(grammarPath, 'w')
-        fp.write(grammar)
-        fp.close()
+        with open(grammarPath, 'w') as fp:
+            fp.write(grammar)

return grammarName, grammarPath, grammarType

@@ -386,9 +362,8 @@ class ANTLRTest(unittest.TestCase):
testDir = os.path.dirname(os.path.abspath(__file__))
path = os.path.join(self.baseDir, name)

-        fp = open(path, 'w')
-        fp.write(contents)
-        fp.close()
+        with open(path, 'w') as fp:
+            fp.write(contents)

return path


